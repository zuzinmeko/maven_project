<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Introduction to ContainerJFR: JDK Flight Recorder for containers</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/PPHmWvkzro8/" /><category term="Containers" /><category term="Java" /><category term="Kubernetes" /><category term="Open source" /><category term="ContainerJFR" /><category term="Java flight recorder" /><category term="monitor java" /><category term="OpenJDK" /><category term="profile java" /><author><name>Andrew Azores</name></author><id>https://developers.redhat.com/blog/?p=798277</id><updated>2021-01-25T08:00:18Z</updated><published>2021-01-25T08:00:18Z</published><content type="html">&lt;p&gt;OpenJDK has long been a top pick for real-world applications and workloads, chosen for its blend of performance, compatibility, reliability, and observability. For many years, JDK Flight Recorder (JFR) and JDK Mission Control (JMC) have contributed to OpenJDK&amp;#8217;s success. Until recently, both were commercial features, however, available only for certain users and workloads.&lt;/p&gt; &lt;p&gt;In 2018, JDK Mission Control and JDK Flight Recorder were open-sourced. JDK Flight Recorder is now built into the Java Virtual Machine (JVM) for later releases of OpenJDK 8 and all versions from OpenJDK 11 onward. Open-sourcing these tools brings their power—always-on, near-zero overhead production profiling and monitoring, application-specific custom events, and unified-core JDK analytical tooling—to all JDK users. On the downside, JDK Mission Control and JDK Flight Recorder have emerged into a world rapidly moving toward containerization, which is not the paradigm that they were designed for.&lt;/p&gt; &lt;p&gt;The desktop-only JDK Mission Control application requires developers and administrators to access flight recordings on the local disk. Otherwise, one resorts to a complex and potentially insecure setup to connect directly to applications over Java Management Extensions (JMX) in the cloud. Similarly, the bare-metal-focused JDK Flight Recorder allows JVMs to dump recordings into the local filesystem, but not when the application runs inside a container. In that case, the filesystem is not easily accessible from the outside world, and it isn&amp;#8217;t possible to retrieve and analyze recordings.&lt;/p&gt; &lt;p&gt;This article introduces &lt;a target="_blank" rel="nofollow" href="https://github.com/rh-jmc-team/container-jfr"&gt;ContainerJFR&lt;/a&gt;, a young project on the way to becoming a Red Hat product. ContainerJFR seeks to bridge the gaps between JDK Flight Recorder in the cloud and end-users at their workstations.&lt;/p&gt; &lt;h2&gt;Manual ContainerJFR installation and setup&lt;/h2&gt; &lt;p&gt;Installing ContainerJFR manually is straightforward using the available images on &lt;a target="_blank" rel="nofollow" href="https://quay.io/repository/rh-jmc-team/container-jfr"&gt;Quay.io&lt;/a&gt;. Run the following for a basic installation and product demonstration:&lt;/p&gt; &lt;pre&gt;$ podman run -it --rm -p 8181 -e CONTAINER_JFR_WEB_HOST=0.0.0.0 quay.io/rh-jmc-team/container-jfr:latest &lt;/pre&gt; &lt;p&gt;For a more full-fledged demonstration, you can clone the ContainerJFR repository and run its &lt;code&gt;smoketest.sh&lt;/code&gt;. The following sets up a few containers in a Podman pod for testing and demonstration:&lt;/p&gt; &lt;pre&gt;$ git clone &lt;a target="_blank" rel="nofollow" href="https://github.com/rh-jmc-team/container-jfr"&gt;https://github.com/rh-jmc-team/container-jfr&lt;/a&gt; $ cd container-jfr $ sh smoketest.sh &lt;/pre&gt; &lt;p&gt;ContainerJFR&amp;#8217;s credentials, in this case, are &lt;code&gt;smoketest:smoketest&lt;/code&gt;. The other application’s credentials are &lt;code&gt;admin:adminpass123&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;Deploying ContainerJFR on Red Hat OpenShift&lt;/h2&gt; &lt;p&gt;If you have access to &lt;a href="https://developers.redhat.com/products/openshift/getting-started"&gt;Red Hat OpenShift&lt;/a&gt; or another Kubernetes cluster, you can use the &lt;a target="_blank" rel="nofollow" href="https://github.com/rh-jmc-team/container-jfr-operator"&gt;ContainerJFR Operator&lt;/a&gt; to deploy ContainerJFR on your cluster:&lt;/p&gt; &lt;pre&gt;$ git clone &lt;a target="_blank" rel="nofollow" href="https://github.com/rh-jmc-team/container-jfr-operator"&gt;https://github.com/rh-jmc-team/container-jfr-operator&lt;/a&gt; $ cd container-jfr-operator $ oc login # ensure you are logged in to your running OpenShift cluster first $ make deploy # to directly deploy the Operator in your cluster along with a ContainerJFR CR, required ServiceAccount and Role/RoleBindings, etc. $ make catalog # alternative to make deploy. This will add a custom CatalogSource to your cluster, allowing you to install the Operator from your Administrator view’s OperatorHub panel &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: If you don’t already have access to an OpenShift or Kubernetes cluster, try &lt;a href="https://developers.redhat.com/products/codeready-containers/overview"&gt;Red Hat CodeReady Containers&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Figure 1 shows ContainerJFR in the OpenShift OperatorHub after we&amp;#8217;ve issued a &lt;code&gt;$ make catalog&lt;/code&gt; to add a custom catalog source.&lt;/p&gt; &lt;div id="attachment_799477" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/operatorhub.png"&gt;&lt;img aria-describedby="caption-attachment-799477" class="wp-image-799477 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/operatorhub-1024x516.png" alt="The OpenShift OperatorHub with the ContainerJFR Operator." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/operatorhub-1024x516.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/operatorhub-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/operatorhub-768x387.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799477" class="wp-caption-text"&gt;Figure 1: ContainerJFR in the OpenShift OperatorHub.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Figure 2 shows a ContainerJFR instance installed in the default namespace.&lt;/p&gt; &lt;div id="attachment_799537" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/installed-operator-1.png"&gt;&lt;img aria-describedby="caption-attachment-799537" class="wp-image-799537 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/installed-operator-1-1024x214.png" alt="The ContainerJFR Operator has been installed." width="640" height="134" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/installed-operator-1-1024x214.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/installed-operator-1-300x63.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/installed-operator-1-768x160.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799537" class="wp-caption-text"&gt;Figure 2: ContainerJFR installed in a project namespace.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;After you&amp;#8217;ve installed ContainerJFR, create a custom resource for it, as shown in Figure 3. Choose any name you like and leave the &lt;b&gt;minimal&lt;/b&gt; setting on&lt;strong&gt; false&lt;/strong&gt; for now.&lt;/p&gt; &lt;div id="attachment_799457" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/create-containerjfr-cr.png"&gt;&lt;img aria-describedby="caption-attachment-799457" class="wp-image-799457 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/create-containerjfr-cr-1024x433.png" alt="The dialog to create a ContainerJFR custom resource." width="640" height="271" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/create-containerjfr-cr-1024x433.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/create-containerjfr-cr-300x127.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/create-containerjfr-cr-768x325.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/create-containerjfr-cr.png 1337w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799457" class="wp-caption-text"&gt;Figure 3: Create and configure the ContainerJFR custom resource.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;After a short time, the Operator finishes deploying ContainerJFR and its services. You can use any view that shows the exposed route URLs to see the ContainerJFR web client. Figure 4 shows ContainerJFR in OpenShift&amp;#8217;s Topology view.&lt;/p&gt; &lt;div id="attachment_799437" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/topology-view.png"&gt;&lt;img aria-describedby="caption-attachment-799437" class="wp-image-799437 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/topology-view-1024x517.png" alt="ContainerJFR seen from the OpenShift developer console in the Topology view." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/topology-view-1024x517.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/topology-view-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/topology-view-768x388.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799437" class="wp-caption-text"&gt;Figure 4: ContainerJFR in the OpenShift Topology view.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Next, we&amp;#8217;ll take a look at ContainerJFR&amp;#8217;s major features, and I&amp;#8217;ll show you how to configure them for your container-managed OpenJDK applications.&lt;/p&gt; &lt;h2&gt;Discovery with ContainerJFR&lt;/h2&gt; &lt;p&gt;ContainerJFR is a containerized JVM that runs as a “sidecar” alongside your OpenJDK applications. Depending on the runtime environment, it automatically selects the best strategy for discovering your JMX-enabled applications. For applications running with &lt;code&gt;docker-compose&lt;/code&gt; or &lt;code&gt;podman-compose&lt;/code&gt;, ContainerJFR would use the &lt;a target="_blank" rel="nofollow" href="https://docs.oracle.com/javase/10/management/java-discovery-protocol.htm"&gt;Java Discovery Protocol&lt;/a&gt; (JDP). For applications running on Kubernetes or OpenShift, it would use endpoints. These are only examples of the platform implementations ContainerJFR currently provides. It is easily extensible if you need customized support for a different container platform.&lt;/p&gt; &lt;h3&gt;Java Management Extensions&lt;/h3&gt; &lt;p&gt;Ensure that your applications have JMX enabled and that the JMX port is published and reachable by ContainerJFR. In practical terms, this means passing the following JVM flags when you start the application:&lt;/p&gt; &lt;pre&gt;-Dcom.sun.management.jmxremote.port=9091 -Dcom.sun.management.jmxremote.rmi.port=9091 &lt;/pre&gt; &lt;p&gt;Then, expose the port using whatever mechanism your container platform uses. In OpenShift or Kubernetes, you would create a service for your deployment and then add an exposed port to the service. By default, ContainerJFR uses port 9091 for JMX, but you can use any port number given the port is named &lt;code&gt;jfr-jmx&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Figure 5 shows ContainerJFR with two sample applications in the OpenShift Topology view.&lt;/p&gt; &lt;div id="attachment_799547" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/topology-with-apps.png"&gt;&lt;img aria-describedby="caption-attachment-799547" class="wp-image-799547 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/topology-with-apps-1024x517.png" alt="The OpenShift Topology view shows ContainerJFR and two sample applications." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/topology-with-apps-1024x517.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/topology-with-apps-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/topology-with-apps-768x388.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799547" class="wp-caption-text"&gt;Figure 5: ContainerJFR with two sample applications.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Java Discovery Protocol&lt;/h3&gt; &lt;p&gt;If you are running with Podman or Docker, or if you are running a local JVM process directly on your host machine, you should also enable Java Discovery Protocol (JDP):&lt;/p&gt; &lt;pre&gt;-Dcom.sun.management.jmxremote.autodiscovery=true &lt;/pre&gt; &lt;h2&gt;Event templates in ContainerJFR&lt;/h2&gt; &lt;p&gt;ContainerJFR supports JDK Flight Recorder event templates, which pre-set the event types and configuration properties to be supported. Using event templates simplifies the task of capturing meaningful data for your applications. ContainerJFR also includes a view that displays all of the event types registered with the JDK Flight Recorder framework for a target JVM. This view is useful when creating or modifying your own event templates.&lt;/p&gt; &lt;p&gt;The Event Templates view in Figure 7 displays pre-set event templates that you can download to your local machine to examine or modify. After you&amp;#8217;ve modified a template, you can upload it for reuse. You can also create recordings from templates.&lt;/p&gt; &lt;div id="attachment_799587" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-templates.png"&gt;&lt;img aria-describedby="caption-attachment-799587" class="wp-image-799587 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-templates-1024x517.png" alt="The Event Templates view in ContainerJFR." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-templates-1024x517.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-templates-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-templates-768x388.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799587" class="wp-caption-text"&gt;Figure 7: Event templates in ContainerJFR.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The Event Types view in Figure 8 displays all of the event types registered with the selected target JVM. You can use this view to search for events by category, keyword, or provider.&lt;/p&gt; &lt;div id="attachment_799567" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-types.png"&gt;&lt;img aria-describedby="caption-attachment-799567" class="wp-image-799567 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-types-1024x517.png" alt="The Event Types view in ContainerJFR." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-types-1024x517.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-types-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-types-768x388.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799567" class="wp-caption-text"&gt;Figure 8: Event types in ContainerJFR.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Editing templates&lt;/h3&gt; &lt;p&gt;You can use ContainerJFR to download a template from a target JVM to your local machine, then open and inspect the template XML document with your favorite text editor. You can even import and edit the template using JDK Mission Control. Figure 9 shows the dialog to download an event template.&lt;/p&gt; &lt;div id="attachment_799607" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-799607" class="size-large wp-image-799607" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-template-download-1024x243.png" alt="The dialog to download an event template." width="640" height="152" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-template-download-1024x243.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-template-download-300x71.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-template-download-768x182.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-template-download.png 1599w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-799607" class="wp-caption-text"&gt;Figure 9: Download an event template to your local disk.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Custom templates&lt;/h3&gt; &lt;p&gt;After you have created a custom template or modified an existing one, you can re-upload it to ContainerJFR, where it will be retained for future use. You will be able to apply the template whenever you create new recordings across your JVM applications.&lt;/p&gt; &lt;p&gt;You can open and edit event templates using any plaintext editor. Another option is to use JDK Mission Control&amp;#8217;s graphical template editor to import, edit, and export a template. Figure 10 shows an event template in a plaintext editor.&lt;/p&gt; &lt;div id="attachment_799617" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-in-editor.png"&gt;&lt;img aria-describedby="caption-attachment-799617" class="wp-image-799617 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-in-editor-1024x556.png" alt="An event template in a plaintext editor." width="640" height="348" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-in-editor-1024x556.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-in-editor-300x163.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-in-editor-768x417.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799617" class="wp-caption-text"&gt;Figure 10: Use any editor to modify an event template in XML format.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;When you upload a new or modified template, ContainerJFR validates it, as shown in Figure 11.&lt;/p&gt; &lt;div id="attachment_799627" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-to-upload.png"&gt;&lt;img aria-describedby="caption-attachment-799627" class="wp-image-799627 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-to-upload-1024x456.png" alt="An event template ready for upload." width="640" height="285" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-to-upload-1024x456.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-to-upload-300x133.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-to-upload-768x342.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799627" class="wp-caption-text"&gt;Figure 11: Templates are validated when the server receives them.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Figure 12 shows all of the available templates for a ContainerJFR instance.&lt;/p&gt; &lt;div id="attachment_799637" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-uploaded.png"&gt;&lt;img aria-describedby="caption-attachment-799637" class="wp-image-799637 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-uploaded-1024x233.png" alt="A list of templates available for later use." width="640" height="146" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-uploaded-1024x233.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-uploaded-300x68.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-uploaded-768x175.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799637" class="wp-caption-text"&gt;Figure 12: A list of templates available for later use.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;All of these features also work with JDK Flight Recorder’s Custom Events API. You can create application-specific event types while developing your application, then create a custom event template including these events, and tailor your own continuous production recordings.&lt;/p&gt; &lt;h2&gt;Recordings in ContainerJFR&lt;/h2&gt; &lt;p&gt;ContainerJFR offers several ways to capture and preserve recordings, including custom recordings, snapshots, and archives.&lt;/p&gt; &lt;h3&gt;Custom recordings&lt;/h3&gt; &lt;p&gt;Figure 13 shows the configuration properties to be defined when you set up a new custom recording.&lt;/p&gt; &lt;div id="attachment_799647" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/create-custom-recording.png"&gt;&lt;img aria-describedby="caption-attachment-799647" class="wp-image-799647 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/create-custom-recording-1024x517.png" alt="The dialog to create a custom recording." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/create-custom-recording-1024x517.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/create-custom-recording-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/create-custom-recording-768x388.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799647" class="wp-caption-text"&gt;Figure 13: Creating a custom recording.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;First is the name of the recording, which ContainerJFR uses to enforce uniqueness per target. You will also configure the duration before the recording is automatically stopped or if it should run continuously until it is manually stopped. You will need to configure the event specifier string or template for the events you want the recording to capture. Advanced properties include “to disk,&amp;#8221; “max size,&amp;#8221; and “max age.&amp;#8221; See the &lt;a&gt;JDK Flight Recorder documentation&lt;/a&gt; to learn more about these properties.&lt;/p&gt; &lt;h3&gt;Snapshots&lt;/h3&gt; &lt;p&gt;Figure 14 shows the dialog to create a new snapshot recording. A &lt;i&gt;snapshot&lt;/i&gt; is an overview of all of the information captured by other recordings.&lt;/p&gt; &lt;div id="attachment_799677" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/snapshot-recording.png"&gt;&lt;img aria-describedby="caption-attachment-799677" class="wp-image-799677 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/snapshot-recording-1024x291.png" alt="The view to create a snapshot recording." width="640" height="182" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/snapshot-recording-1024x291.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/snapshot-recording-300x85.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/snapshot-recording-768x218.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799677" class="wp-caption-text"&gt;Figure 14: Create a snapshot recording with one click.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;If you have multiple custom recordings running in a target at once, you could use a snapshot to create a new recording file at that point in time. The snapshot contains the merged data from all of your other recordings. Snapshots can also be useful for preserving data from a single, continuous recording at a particular point in time.&lt;/p&gt; &lt;h3&gt;Data flow&lt;/h3&gt; &lt;p&gt;When you create a recording, you ask ContainerJFR to send instructions to your target JVM to start a flight recording. No data is transferred outside of your application at this point, only the name, state, and start time of your recordings, along with other basic metadata. The recording lives only in the memory of your target application, within its container.&lt;/p&gt; &lt;div id="attachment_799657" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/recording-list.png"&gt;&lt;img aria-describedby="caption-attachment-799657" class="wp-image-799657 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/recording-list-1024x517.png" alt="The view shows a list of recordings." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/recording-list-1024x517.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/recording-list-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/recording-list-768x388.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799657" class="wp-caption-text"&gt;Figure 15: ContainerJFR displays all of the recordings present in a selected target JVM.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Archives&lt;/h3&gt; &lt;p&gt;&lt;i&gt;Archiving&lt;/i&gt; streams a snapshot of a recording out of your application and into ContainerJFR. ContainerJFR immediately writes the snapshot to its local disk (or a persistent volume in OpenShift or Kubernetes) and drops it from memory. Even if your application is scaled down or otherwise goes away, you will still be able to access the recording for analysis. If you accidentally delete a &lt;code&gt;.jfr&lt;/code&gt; file, you can re-upload it from your workstation’s local disk into the archives. This also works if you remove ContainerJFR from the cluster and re-install it later.&lt;/p&gt; &lt;p&gt;The archived recording list in Figure 16 displays all of the recordings saved to ContainerJFR&amp;#8217;s persistent storage, which is common across all target JVMs.&lt;/p&gt; &lt;div id="attachment_799667" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/archived-list.png"&gt;&lt;img aria-describedby="caption-attachment-799667" class="wp-image-799667 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/archived-list-1024x517.png" alt="The view shows a list of archived recordings." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/archived-list-1024x517.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/archived-list-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/archived-list-768x388.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799667" class="wp-caption-text"&gt;Figure 16: Recordings saved to ContainerJFR&amp;#8217;s persistent storage.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Automated analysis with ContainerJFR&lt;/h2&gt; &lt;p&gt;ContainerJFR lets you run an automated analysis on your flight recordings within your cloud deployment without ever needing to transfer data to your local machine or outside of the cluster. You can use this feature to check your applications&amp;#8217; health from a hotel with a slow connection or an airport using only your phone or tablet.&lt;/p&gt; &lt;p&gt;Expanding the list of active and archived recordings in Figure 17 reveals an automated analysis generated within the cluster.&lt;/p&gt; &lt;div id="attachment_799687" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/automated-report.png"&gt;&lt;img aria-describedby="caption-attachment-799687" class="wp-image-799687 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/automated-report-1024x517.png" alt="An automated analysis report." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/automated-report-1024x517.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/automated-report-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/automated-report-768x388.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799687" class="wp-caption-text"&gt;Figure 17: An automated analysis report for active and archived recordings.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;When you expand a recording, ContainerJFR uses its JDK Mission Control back end to generate an automated analysis report, alerting you to any apparent or probable issues with your application. You can also save reports in HTML format for future reference.&lt;/p&gt; &lt;h3&gt;Using Grafana for analysis&lt;/h3&gt; &lt;p&gt;If the automated analysis report doesn’t contain enough information for you, or if it points out a problem that you want to inspect more closely, you can send the recording to the &lt;a target="_blank" rel="nofollow" href="https://github.com/rh-jmc-team/jfr-datasource"&gt;jfr-datasource&lt;/a&gt; exporter within the ContainerJFR pod. From there, you can view the data using &lt;a target="_blank" rel="nofollow" href="https://grafana.com"&gt;Grafana&lt;/a&gt;. Figure 18 shows the recording list item action menu, which you can use to send a recording to the Grafana dashboard.&lt;/p&gt; &lt;div id="attachment_799697" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/view-in-grafana.png"&gt;&lt;img aria-describedby="caption-attachment-799697" class="wp-image-799697 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/view-in-grafana-1024x263.png" alt="The Grafana action view." width="640" height="164" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/view-in-grafana-1024x263.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/view-in-grafana-300x77.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/view-in-grafana-768x197.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799697" class="wp-caption-text"&gt;Figure 18: Send a recording to the Grafana dashboard for further analysis.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;ContainerJFR provides a pre-configured dashboard with time-series data, but you are encouraged to create your own dashboards with the metrics that matter to you. Note, again, that none of your data leaves the cluster. The &lt;code&gt;jfr-datasource&lt;/code&gt; that provides the translation from a &lt;code&gt;.jfr&lt;/code&gt; file to Grafana metrics is hidden within the ContainerJFR pod, and the Grafana dashboard instance is secured with generated credentials (stored in an OpenShift or Kubernetes secret) before being exposed to the outside world. It is easy to retrieve those generated credentials using the following commands:&lt;/p&gt; &lt;pre&gt;$ oc get secret containerjfr-grafana-basic -o json | jq -crM .data.GF_SECURITY_ADMIN_USER | base64 -d $ oc get secret containerjfr-grafana-basic -o json | jq -crM .data.GF_SECURITY_ADMIN_PASSWORD | base64 -d &lt;/pre&gt; &lt;p&gt;Once you have the credentials, you can plug them into the Grafana dashboard&amp;#8217;s login page and start viewing your metrics, as shown in Figure 19.&lt;/p&gt; &lt;div id="attachment_799717" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/grafana-dashboard-1.png"&gt;&lt;img aria-describedby="caption-attachment-799717" class="wp-image-799717 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/grafana-dashboard-1-1024x517.png" alt="Viewing metrics in the Grafana dashboard." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/grafana-dashboard-1-1024x517.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/grafana-dashboard-1-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/grafana-dashboard-1-768x388.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799717" class="wp-caption-text"&gt;Figure 19: The preconfigured Grafana dashboard gives more detailed insights into your application&amp;#8217;s performance (batteries included and installed).&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Using JDK Mission Control for analysis&lt;/h3&gt; &lt;p&gt;Finally, if you need even more detail, you can download a recording file from ContainerJFR to your local disk and open it with the full-featured offline JDK Mission Control desktop application. This is the only scenario where your recording actually leaves the cluster.&lt;/p&gt; &lt;div id="attachment_799727" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/jmc.png"&gt;&lt;img aria-describedby="caption-attachment-799727" class="wp-image-799727 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/jmc-1024x556.png" alt="The JDK Mission Control dashboard." width="640" height="348" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/jmc-1024x556.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/jmc-300x163.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/jmc-768x417.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799727" class="wp-caption-text"&gt;Figure 20: Use the JDK Mission Control desktop application for a deep-dive into the data collected from your cloud applications.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The JDK Mission Control desktop application offers a wealth of features and capabilities, but I will leave that discussion for another article.&lt;/p&gt; &lt;h2&gt;Secure authentication with ContainerJFR&lt;/h2&gt; &lt;p&gt;JDK Flight Recorder captures a tremendous amount of data with no significant runtime overhead. Keeping the data secure and ensuring its integrity is vital. As shown in Figure 21, ContainerJFR does not require your application to open its JMX connections to the world—only to connections from inside your OpenShift namespace or your Docker or Podman network.&lt;/p&gt; &lt;div id="attachment_852077" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/graph0.png"&gt;&lt;img aria-describedby="caption-attachment-852077" class="wp-image-852077 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/graph0-1024x867.png" alt="A graph illustrating ContainerJFR deployment and relations between components." width="640" height="542" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/graph0-1024x867.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/graph0-300x254.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/graph0-768x650.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/graph0.png 1137w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-852077" class="wp-caption-text"&gt;Figure 21: Overview of a secure ContainerJFR deployment.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Once ContainerJFR has received a copy of your Java Flight Recorder data—which it does only upon your instruction—that data is accessible only through secured API requests. The secured API requests support JMX authentication to connect to your application and another authentication layer to connect to ContainerJFR.&lt;/p&gt; &lt;p&gt;When running in OpenShift, all sensitive API requests require a user account token for authentication, as shown in Figure 22. Note that requests from the client to ContainerJFR over HTTP or WebSocket and requests from ContainerJFR to targets over JMX all support and enable the Secure Socket Layer or Transport Layer Security (SSL/TLS) protocol by default.&lt;/p&gt; &lt;div id="attachment_799597" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/cjfr-login.png"&gt;&lt;img aria-describedby="caption-attachment-799597" class="wp-image-799597 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/cjfr-login-1024x517.png" alt="The ContainerJFR login page on OpenShift." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/cjfr-login-1024x517.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/cjfr-login-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/cjfr-login-768x388.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799597" class="wp-caption-text"&gt;Figure 22: ContainerJFR uses the OpenShift cluster&amp;#8217;s authentication server for user authentication.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Future plans for ContainerJFR&lt;/h2&gt; &lt;p&gt;ContainerJFR is still a young project, and the worlds of containers and monitoring are always expanding, so there is a lot on our horizon. In the future, we hope to make the following changes and improvements to ContainerJFR:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Implement better and more flexible ways for ContainerJFR to identify, group, and label target applications. One example is the ability to examine OpenShift or Kubernetes labels and annotations.&lt;/li&gt; &lt;li&gt;Add support for batched operations, used to manage recordings across a group of targets with a single request.&lt;/li&gt; &lt;li&gt;Add a Trigger feature to allow recordings to be automatically started and stopped on a target or group of targets when a predefined event occurs. For example, when a new target appears, automatically start a recording with a predefined template.&lt;/li&gt; &lt;li&gt;Embed Grafana views and other visualizations directly into the ContainerJFR web client.&lt;/li&gt; &lt;li&gt;Provide integration or deep linking to the desktop JDK Mission Control application.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Visit the &lt;a target="_blank" rel="nofollow" href="https://github.com/rh-jmc-team/container-jfr"&gt;ContainerJFR repository&lt;/a&gt; for future updates.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F25%2Fintroduction-to-containerjfr-jdk-flight-recorder-for-containers%2F&amp;#38;linkname=Introduction%20to%20ContainerJFR%3A%20JDK%20Flight%20Recorder%20for%20containers" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F25%2Fintroduction-to-containerjfr-jdk-flight-recorder-for-containers%2F&amp;#38;linkname=Introduction%20to%20ContainerJFR%3A%20JDK%20Flight%20Recorder%20for%20containers" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F25%2Fintroduction-to-containerjfr-jdk-flight-recorder-for-containers%2F&amp;#38;linkname=Introduction%20to%20ContainerJFR%3A%20JDK%20Flight%20Recorder%20for%20containers" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F25%2Fintroduction-to-containerjfr-jdk-flight-recorder-for-containers%2F&amp;#38;linkname=Introduction%20to%20ContainerJFR%3A%20JDK%20Flight%20Recorder%20for%20containers" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F25%2Fintroduction-to-containerjfr-jdk-flight-recorder-for-containers%2F&amp;#38;linkname=Introduction%20to%20ContainerJFR%3A%20JDK%20Flight%20Recorder%20for%20containers" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F25%2Fintroduction-to-containerjfr-jdk-flight-recorder-for-containers%2F&amp;#38;linkname=Introduction%20to%20ContainerJFR%3A%20JDK%20Flight%20Recorder%20for%20containers" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F25%2Fintroduction-to-containerjfr-jdk-flight-recorder-for-containers%2F&amp;#38;linkname=Introduction%20to%20ContainerJFR%3A%20JDK%20Flight%20Recorder%20for%20containers" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F25%2Fintroduction-to-containerjfr-jdk-flight-recorder-for-containers%2F&amp;#038;title=Introduction%20to%20ContainerJFR%3A%20JDK%20Flight%20Recorder%20for%20containers" data-a2a-url="https://developers.redhat.com/blog/2021/01/25/introduction-to-containerjfr-jdk-flight-recorder-for-containers/" data-a2a-title="Introduction to ContainerJFR: JDK Flight Recorder for containers"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/25/introduction-to-containerjfr-jdk-flight-recorder-for-containers/"&gt;Introduction to ContainerJFR: JDK Flight Recorder for containers&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/PPHmWvkzro8" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;OpenJDK has long been a top pick for real-world applications and workloads, chosen for its blend of performance, compatibility, reliability, and observability. For many years, JDK Flight Recorder (JFR) and JDK Mission Control (JMC) have contributed to OpenJDK&amp;#8217;s success. Until recently, both were commercial features, however, available only for certain users and workloads. In 2018, [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/25/introduction-to-containerjfr-jdk-flight-recorder-for-containers/"&gt;Introduction to ContainerJFR: JDK Flight Recorder for containers&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/01/25/introduction-to-containerjfr-jdk-flight-recorder-for-containers/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">798277</post-id><dc:creator>Andrew Azores</dc:creator><dc:date>2021-01-25T08:00:18Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/01/25/introduction-to-containerjfr-jdk-flight-recorder-for-containers/</feedburner:origLink></entry><entry><title>Knowledge meets machine learning for smarter decisions, Part 2</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/PKjN8oeydLw/" /><category term="Big Data" /><category term="Java" /><category term="Machine Learning" /><category term="Python" /><category term="AI/ML" /><category term="DMN" /><category term="Drools" /><category term="JPMML" /><category term="machine learning model" /><author><name>Donato Marrazzo</name></author><id>https://developers.redhat.com/blog/?p=815677</id><updated>2021-01-22T08:00:34Z</updated><published>2021-01-22T08:00:34Z</published><content type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/products/red-hat-decision-manager/overview"&gt;Red Hat Decision Manager&lt;/a&gt; helps organizations introduce the benefits of &lt;a href="https://developers.redhat.com/topics/ai-ml"&gt;artificial intelligence&lt;/a&gt; to their daily operations. It is based on Drools, a popular open source project known for its powerful rules engine.&lt;/p&gt; &lt;p&gt;In &lt;a href="https://developers.redhat.com/blog/2021/01/14/knowledge-meets-machine-learning-for-smarter-decisions-part-1/"&gt;Part 1 of this article&lt;/a&gt;, we built a machine learning algorithm and stored it in a &lt;a target="_blank" rel="nofollow" href="http://dmg.org/pmml/v4-1/GeneralStructure.html"&gt;Predictive Model Markup Language&lt;/a&gt; (PMML) file. In Part 2, we&amp;#8217;ll combine the machine learning logic with deterministic knowledge defined using a &lt;a target="_blank" rel="nofollow" href="https://www.omg.org/dmn/"&gt;Decision Model and Notation (DMN) model&lt;/a&gt;. DMN is a recent standard introduced by the Object Management Group. It provides a common notation to capture an application&amp;#8217;s decision logic so that business users can understand it.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: Examples in this article build on the discussion in Part 1. If you have not already done so, please &lt;a href="https://developers.redhat.com/blog/2021/01/14/knowledge-meets-machine-learning-for-smarter-decisions-part-1/"&gt;read the first half of this article&lt;/a&gt; before continuing.&lt;/p&gt; &lt;h2&gt;The PMML advantage&lt;/h2&gt; &lt;p&gt;The end goal of a machine learning algorithm is to predict a value given a certain input. As I discussed in Part 1, there are many different machine learning algorithms, and each one has its own structure, training options, and logical execution. Most of the time, end users don&amp;#8217;t need to know &lt;i&gt;how&lt;/i&gt; an algorithm obtains its results; we only need to know that the results are accurate.&lt;/p&gt; &lt;p&gt;PMML hides the implementation details. It also gives us a common-language descriptor that we can use to combine predictive models created with different tools. The &lt;a target="_blank" rel="nofollow" href="https://pypi.org/project/sklearn-pmml-model/"&gt;sklearn-pmml-model&lt;/a&gt; project integrates PMML with &lt;code&gt;scikit-learn&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;PMML also separates the machine learning domain from the knowledge engineering domain. This separation makes it easier for specialists to manage each domain&amp;#8217;s details, then use the common-language descriptor to integrate them.&lt;/p&gt; &lt;h3&gt;JPMML&lt;/h3&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/jpmml/jpmml-transpiler"&gt;JPMML&lt;/a&gt; is a well established &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt; implementation of PMML provided by &lt;a target="_blank" rel="nofollow" href="https://openscoring.io/"&gt;Openscoring.io&lt;/a&gt;. Drools and Red Hat Decision Manager use JPMML for PMML execution inside the same process that executes the DMN logic, making the whole execution extremely efficient.&lt;/p&gt; &lt;p&gt;Drools and JPMML are released with different open source licenses, and JPMML is not packaged with the Drools binaries nor with Red Hat Decision Manager. As a user, you will need to download the JPMML libraries and place them in the &lt;code&gt;lib&lt;/code&gt; folder of the KIE Server and Business Central repository associated with your Red Hat Decision Manager instance.&lt;/p&gt; &lt;p&gt;Our &lt;a target="_blank" rel="nofollow" href="https://github.com/dmarrazzo/rhdm-dmn-pmml-order"&gt;example project&amp;#8217;s source code&lt;/a&gt; comes with a Maven configuration that copies all the project dependencies to the dependency folder. Here is the command to download the dependencies:&lt;/p&gt; &lt;pre&gt;mvn dependency:copy-dependencies &lt;/pre&gt; &lt;p&gt;You will need to copy the following libraries:&lt;/p&gt; &lt;pre&gt;pmml-evaluator-1.4.9.jar pmml-agent-1.4.11.jar pmml-model-1.4.11.jar pmml-evaluator-extension-1.4.9.jar kie-dmn-jpmml-7.33.0.Final-redhat-00003.jar &lt;/pre&gt; &lt;p&gt;The last entry is a Drools library that enables JPMML within the DMN runtime.&lt;/p&gt; &lt;h3&gt;Using PMML and DMN with machine learning&lt;/h3&gt; &lt;p&gt;The only drawback to using PMML is that it’s more focused on data science than machine learning. As a result, the specification doesn&amp;#8217;t include all of the available machine learning algorithms. You can still use DMN combined with machine learning, but it might be less comfortable in terms of user experience.&lt;/p&gt; &lt;p&gt;In fact, DMN can use externally-defined functions to execute Java code. This approach lets you leverage machine learning implementations that are not included with the specification, whether they are Java libraries or other technologies. It&amp;#8217;s even possible to call a remote evaluation that isolates the machine learning execution in a separate microservice.&lt;/p&gt; &lt;h2&gt;Knowledge engineering meets machine learning&lt;/h2&gt; &lt;p&gt;A machine learning algorithm delivers a prediction. How to handle the result is a &lt;i&gt;decision&lt;/i&gt;, which is based on the &lt;i&gt;knowledge context&lt;/i&gt;. The simple case study I introduced in Part 1 includes a reference price table for different product types. The table changes over time as prices are adjusted, and those changes influence the decision outcome.&lt;/p&gt; &lt;p&gt;Now, let&amp;#8217;s say that we want to introduce a business requirement that supply orders must be directed to a manager for any expense exceeding $1,500. The policy will let us know upfront what to do with larger expense requests, but how should we implement it?&lt;/p&gt; &lt;p&gt;We could train the algorithm to reject any order over $1,500, but that would be a bad choice. We shouldn&amp;#8217;t rely on a prediction when we have access to certainty. To say it differently, if you have a clear policy, use knowledge engineering, not machine learning.&lt;/p&gt; &lt;h2&gt;The example project&lt;/h2&gt; &lt;p&gt;To use PMML in a decision, we have to import it in Business Central (also known as Decision Central). The diagram in Figure 1 shows how the output from &lt;code&gt;scikit-learn&lt;/code&gt; feeds into Red Hat Decision Manager and Decision Central.&lt;/p&gt; &lt;div id="attachment_815687" style="width: 619px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa263e78039f.png"&gt;&lt;img aria-describedby="caption-attachment-815687" class="wp-image-815687 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa263e78039f.png" alt="A block diagram showing how output from Figure 1: Output from Scikit-learn feeds Red Hat Decision Manager. feeds the Decision Manager project" width="609" height="241" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa263e78039f.png 609w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa263e78039f-300x119.png 300w" sizes="(max-width: 609px) 100vw, 609px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-815687" class="wp-caption-text"&gt;Figure 1: Output from Scikit-learn feeds Red Hat Decision Manager.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;We can import the &lt;a target="_blank" rel="nofollow" href="https://github.com/dmarrazzo/rhdm-dmn-pmml-order"&gt;GitHub repository for this project&lt;/a&gt; directly into Decision Central: The PMML file is already imported, and the DMN file includes it by reference.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: If you need a quick introduction to DMN, see &lt;em&gt;&lt;a target="_blank" rel="nofollow" href="http://learn-dmn-in-15-minutes.com/"&gt;Learn DMN in 15 minutes&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt; &lt;h3&gt;The DMN logic&lt;/h3&gt; &lt;p&gt;For this example, we&amp;#8217;ve tried to keep the DMN logic minimal to focus on the PMML integration, but a few features are worth exploring. To start, consider the decision requirement diagram in Figure 2.&lt;/p&gt; &lt;div id="attachment_815697" style="width: 467px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2641fede87.png"&gt;&lt;img aria-describedby="caption-attachment-815697" class="wp-image-815697 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2641fede87.png" alt="A block diagram showing how an order moves from input to approval." width="457" height="478" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2641fede87.png 457w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2641fede87-287x300.png 287w" sizes="(max-width: 457px) 100vw, 457px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-815697" class="wp-caption-text"&gt;Figure 2: A decision requirement diagram for automatic approval.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Figure 3 is a closer look at the &lt;code&gt;OrderInfo&lt;/code&gt; datatype.&lt;/p&gt; &lt;div id="attachment_815707" style="width: 283px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa26429a6449.png"&gt;&lt;img aria-describedby="caption-attachment-815707" class="wp-image-815707 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa26429a6449.png" alt="The OrderInfo data type includes productType, price, category, and urgency." width="273" height="361" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa26429a6449.png 273w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa26429a6449-227x300.png 227w" sizes="(max-width: 273px) 100vw, 273px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-815707" class="wp-caption-text"&gt;Figure 3: The structure of the OrderInfo data type.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Notice the following:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The input data categories are product type, price, category, and urgency.&lt;/li&gt; &lt;li&gt;The Target Price is computed and used with the other data to get a Prediction.&lt;/li&gt; &lt;li&gt;A Prediction triggers a machine learning call (ML call). The box with the clipped corner is the business knowledge model and represents the machine learning algorithm&amp;#8217;s execution.&lt;/li&gt; &lt;li&gt;Finally, Auto Approve is based on the Prediction plus additional logic.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The Target Price decision shown in Figure 4 captures the company policy for asset reference prices with a simple decision table.&lt;/p&gt; &lt;div id="attachment_815727" style="width: 479px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2643375095.png"&gt;&lt;img aria-describedby="caption-attachment-815727" class="wp-image-815727 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2643375095.png" alt="The decision table captures the product type and target price for each request." width="469" height="348" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2643375095.png 469w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2643375095-300x223.png 300w" sizes="(max-width: 469px) 100vw, 469px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-815727" class="wp-caption-text"&gt;Figure 4: The decision table for Target Price.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The Prediction decision node, shown in Figure 5, calls the machine learning execution (ML call). This node might seem complex. Really, it translates the category and urgency of a decision to numbers. The machine learning algorithm returns a prediction of &lt;i&gt;true&lt;/i&gt; (&lt;code&gt;probability(true)&lt;/code&gt;) when the probability is over the threshold of 0.5.&lt;/p&gt; &lt;div id="attachment_815747" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa264471075d.png"&gt;&lt;img aria-describedby="caption-attachment-815747" class="wp-image-815747" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa264471075d.png" alt="The Prediction node translates the category and urgency of a decision to numbers." width="640" height="578" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa264471075d.png 894w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa264471075d-300x271.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa264471075d-768x694.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-815747" class="wp-caption-text"&gt;Figure 5: The implementation of the Prediction decision node.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;The business knowledge model&lt;/h3&gt; &lt;p&gt;The project&amp;#8217;s business knowledge model is straightforward, as shown in Figure 6.&lt;/p&gt; &lt;div id="attachment_815757" style="width: 463px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2645597879.png"&gt;&lt;img aria-describedby="caption-attachment-815757" class="wp-image-815757 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2645597879.png" alt="When a user chooses the PMML document and model from a drop-down list, PMML introspection automatically infers the input parameters." width="453" height="268" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2645597879.png 453w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2645597879-300x177.png 300w" sizes="(max-width: 453px) 100vw, 453px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-815757" class="wp-caption-text"&gt;Figure 6: The business knowledge model calls the machine learning model.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;A user chooses the PMML document and model from a drop-down list. The PMML introspection automatically infers the input parameters.&lt;/p&gt; &lt;h3&gt;Invoking the machine learning algorithm&lt;/h3&gt; &lt;p&gt;From a decision expert&amp;#8217;s perspective, invoking a machine learning algorithm is simple: The information contract is defined by the PMML file and automatically imported. If a decision expert needs to understand a rule&amp;#8217;s semantics (for example, that “low” urgency translates to 0), they can speak to the data scientists.&lt;/p&gt; &lt;p&gt;For a slightly less obvious rule, consider how the model result is mapped in DMN. We can find those lines in the PMML file:&lt;/p&gt; &lt;pre&gt;       &amp;#60;Output&amp;#62;            &amp;#60;OutputField name="probability(false)" optype="continuous" dataType="double" feature="probability" value="false"/&amp;#62;            &amp;#60;OutputField name="probability(true)" optype="continuous" dataType="double" feature="probability" value="true"/&amp;#62;        &amp;#60;/Output&amp;#62; &lt;/pre&gt; &lt;p&gt;They are translated in the following &lt;a target="_blank" rel="nofollow" href="https://docs.camunda.org/manual/7.14/reference/dmn/feel/"&gt;Friendly Enough Expression Language&lt;/a&gt; (FEEL) context:&lt;/p&gt; &lt;pre&gt;{    “probability(true)” : &lt;i&gt;number&lt;/i&gt;,   “probability(false)”: &lt;i&gt;number&lt;/i&gt; } &lt;/pre&gt; &lt;p&gt;The top node is used to make the final decision of whether or not to auto-approve an order. Remember from Part 1 that this decision includes a simple company policy: &lt;i&gt;Automatic approval can happen when the expense is less than $1,500&lt;/i&gt;. Here is how to implement that policy with a FEEL expression:&lt;/p&gt; &lt;pre&gt;&lt;b&gt;if&lt;/b&gt; order info.price &amp;#60; 1500 &lt;b&gt;then&lt;/b&gt;    Prediction &lt;b&gt;else&lt;/b&gt;   &lt;b&gt;false&lt;/b&gt; &lt;/pre&gt; &lt;p&gt;Figure 7 shows the decision lifecycle at a high level. Note that the design phase is split between Python and Decision Central. The runtime is the KIE Server (also known as Decision Central).&lt;/p&gt; &lt;div id="attachment_815767" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2647888bf2.png"&gt;&lt;img aria-describedby="caption-attachment-815767" class="wp-image-815767 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2647888bf2-1024x213.png" alt="A block diagram showing the toolchain progression from Scikit-learn to Decision Central, to Kie Server." width="640" height="133" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2647888bf2-1024x213.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2647888bf2-300x62.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2647888bf2-768x160.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2647888bf2.png 1159w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-815767" class="wp-caption-text"&gt;Figure 7: The toolchain progresses from Scikit-learn to Decision Central, to Kie Server.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Trust automatic decisions&lt;/h2&gt; &lt;p&gt;The more critical a decision is, the more you need to trust the system that determines its outcome. A suboptimal product suggestion might be acceptable, but what about a decision to reject a loan or decisions concerning medical findings? Additionally, ethics and legislation expect accountability in we use personal data is used to make decisions. (As an example, see the European Union&amp;#8217;s &lt;a target="_blank" rel="nofollow" href="https://gdpr-info.eu/"&gt;General Data Protection Regulation&lt;/a&gt;.)&lt;/p&gt; &lt;h3&gt;Inspection&lt;/h3&gt; &lt;p&gt;When an automatic decision-making system is introduced in an enterprise context, it is crucial to keep it under control by monitoring the decisions made over time. You should be able to use tools in your decision-management technology to investigate specific cases and highlight the features that influenced any given decision.&lt;/p&gt; &lt;p&gt;With Red Hat Decision Manager, users can use the common monitoring stack from Prometheus and Grafana to track decisions. By analyzing DMN execution results, you can inspect your intermediate outcomes and correlate them with the enterprise policy captured in a specific decision node.&lt;/p&gt; &lt;p&gt;Machine learning algorithms are more opaque: You get the input data and the output. In this sense, a machine learning model is a black box, providing no clues about how it works. An expert will understand from the algorithm parameters how it behaves, but most business users don&amp;#8217;t have access to that information.&lt;/p&gt; &lt;h3&gt;Using the knowledge context&lt;/h3&gt; &lt;p&gt;In our order approval example, the knowledge-based elements are key to understanding the final decision. If you can see that the price of a phone is far from the reference price in the model, you can use that information to interpret the decision outcome for your request. Our model is simple, so the conclusion is obvious. Surrounding a machine learning algorithm with a knowledge context is even more valuable for complex models. Having the context helps end users better understand decision outcomes.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: In the future, Red Hat Decision Manager&amp;#8217;s development team will extend its inspection features to better cope with the &lt;a target="_blank" rel="nofollow" href="https://blog.kie.org/2020/06/trusty-ai-introduction.html"&gt;TrustyAI&lt;/a&gt; challenge.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;In this two-part article, we have seen that artificial intelligence is more than just machine learning. By combining multiple techniques, we can increase the intelligence of a machine learning model. Moreover, this approach could increase an organization&amp;#8217;s overall confidence in machine learning outcomes. Business users and end users benefit from the transparency provided by a knowledge context.&lt;/p&gt; &lt;p&gt;We crafted a machine learning model for our example project, which we then consumed from a DMN model. The result was an &amp;#8220;AI-augmented&amp;#8221; decision. However, we only scratched the surface of what is possible with artificial intelligence. If you want to go further, I suggest this free course from Harvard University: &lt;a target="_blank" rel="nofollow" href="https://cs50.harvard.edu/ai/2020/"&gt;CS50&amp;#8217;s Introduction to Artificial Intelligence with Python&lt;/a&gt;. The Python example we used in this article is based on a similar example from the course.&lt;/p&gt; &lt;p&gt;I also found the &lt;a target="_blank" rel="nofollow" href="https://www.linkedin.com/learning/learning-xai-explainable-artificial-intelligence"&gt;explainable AI (XAI) course&lt;/a&gt; on LinkedIn Learning (formerly Lynda) very useful.&lt;/p&gt; &lt;h2&gt;Acknowledgments&lt;/h2&gt; &lt;p&gt;A special thanks to my colleagues in the engineering team: Edson Tirelli, Matteo Mortari, and Gabriele Cardosi, for their suggestions and ideas to improve this article. Gabriele also wrote the &amp;#8220;PMML advantage&amp;#8221; section for this article.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F22%2Fknowledge-meets-machine-learning-for-smarter-decisions-part-2%2F&amp;#38;linkname=Knowledge%20meets%20machine%20learning%20for%20smarter%20decisions%2C%20Part%202" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F22%2Fknowledge-meets-machine-learning-for-smarter-decisions-part-2%2F&amp;#38;linkname=Knowledge%20meets%20machine%20learning%20for%20smarter%20decisions%2C%20Part%202" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F22%2Fknowledge-meets-machine-learning-for-smarter-decisions-part-2%2F&amp;#38;linkname=Knowledge%20meets%20machine%20learning%20for%20smarter%20decisions%2C%20Part%202" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F22%2Fknowledge-meets-machine-learning-for-smarter-decisions-part-2%2F&amp;#38;linkname=Knowledge%20meets%20machine%20learning%20for%20smarter%20decisions%2C%20Part%202" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F22%2Fknowledge-meets-machine-learning-for-smarter-decisions-part-2%2F&amp;#38;linkname=Knowledge%20meets%20machine%20learning%20for%20smarter%20decisions%2C%20Part%202" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F22%2Fknowledge-meets-machine-learning-for-smarter-decisions-part-2%2F&amp;#38;linkname=Knowledge%20meets%20machine%20learning%20for%20smarter%20decisions%2C%20Part%202" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F22%2Fknowledge-meets-machine-learning-for-smarter-decisions-part-2%2F&amp;#38;linkname=Knowledge%20meets%20machine%20learning%20for%20smarter%20decisions%2C%20Part%202" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F22%2Fknowledge-meets-machine-learning-for-smarter-decisions-part-2%2F&amp;#038;title=Knowledge%20meets%20machine%20learning%20for%20smarter%20decisions%2C%20Part%202" data-a2a-url="https://developers.redhat.com/blog/2021/01/22/knowledge-meets-machine-learning-for-smarter-decisions-part-2/" data-a2a-title="Knowledge meets machine learning for smarter decisions, Part 2"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/22/knowledge-meets-machine-learning-for-smarter-decisions-part-2/"&gt;Knowledge meets machine learning for smarter decisions, Part 2&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/PKjN8oeydLw" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Red Hat Decision Manager helps organizations introduce the benefits of artificial intelligence to their daily operations. It is based on Drools, a popular open source project known for its powerful rules engine. In Part 1 of this article, we built a machine learning algorithm and stored it in a Predictive Model Markup Language (PMML) file. [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/22/knowledge-meets-machine-learning-for-smarter-decisions-part-2/"&gt;Knowledge meets machine learning for smarter decisions, Part 2&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/01/22/knowledge-meets-machine-learning-for-smarter-decisions-part-2/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">815677</post-id><dc:creator>Donato Marrazzo</dc:creator><dc:date>2021-01-22T08:00:34Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/01/22/knowledge-meets-machine-learning-for-smarter-decisions-part-2/</feedburner:origLink></entry><entry><title>Introducing the Red Hat build of Eclipse Vert.x 4.0</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/PcEgqD9cg-M/" /><category term="Containers" /><category term="Java" /><category term="Kubernetes" /><category term="Modern App Dev" /><category term="distributed tracing" /><category term="Jkube" /><category term="openshift" /><category term="reactive programming" /><category term="vert.x" /><author><name>Syed M Shaaf</name></author><id>https://developers.redhat.com/blog/?p=855807</id><updated>2021-01-21T08:00:28Z</updated><published>2021-01-21T08:00:28Z</published><content type="html">&lt;p&gt;If you are interested in reactive, non-blocking, and asynchronous Java development, you are likely familiar with &lt;a target="_blank" rel="nofollow" href="https://vertx.io/"&gt;Eclipse Vert.x&lt;/a&gt;. The project started in 2011 and successfully moved to the Eclipse Foundation in 2013. Since then, Vert.x has undergone nine years of rigorous development and grown into a thriving community. It is one of the most widely used reactive frameworks, with support for multiple extensions, including extensions for messaging or streaming with &lt;a href="https://developers.redhat.com/topics/kafka-kubernetes"&gt;Kafka&lt;/a&gt; or Artemis, developing applications with gRPC and GraphQL, and &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/articles/3348731"&gt;so much more&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_build_of_eclipse_vert.x/4.0/html/release_notes_for_eclipse_vert.x_4.0/index"&gt;Red Hat build of Eclipse Vert.x 4.0&lt;/a&gt; is now generally available. This release improves Vert.x&amp;#8217;s core APIs and handling. Developers who migrate can expect enhancements to futures and promises, distributed tracing, and deployment on &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt;. In this article, I introduce these updates and offer tips for migrating and deploying your Eclipse Vert.x 4.0 applications on OpenShift.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: Please see the &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_build_of_eclipse_vert.x/4.0/html/eclipse_vert.x_4.0_migration_guide/"&gt;Red Hat build of Eclipse Vert.x 4.0 migration guide&lt;/a&gt; for a detailed introduction to migrating from Vert.x 3.x to Vert.x 4.0.&lt;/p&gt; &lt;h2&gt;The &amp;#60;Future&amp;#62; is here!&lt;/h2&gt; &lt;p&gt;&lt;code&gt;Future&lt;/code&gt; is an &lt;code&gt;AsyncResult&amp;#60;T&amp;#62;&lt;/code&gt; that you can use to create asynchronous operations in Vert.x 4.0. Every asynchronous method returns a &lt;code&gt;Future&lt;/code&gt; object, &lt;code&gt;success&lt;/code&gt; or &lt;code&gt;failure&lt;/code&gt;, as the result of a call:&lt;/p&gt; &lt;pre&gt;FileSystem fs = vertx.fileSystem(); Future&amp;#60;FileProps&amp;#62; future = fs.props("/my_file.txt"); future.onComplete((AsyncResult&amp;#60;FileProps&amp;#62; ar) -&amp;#62; { if (ar.succeeded()) { FileProps props = ar.result(); System.out.println("File size = " + props.size()); } else { System.out.println("Failure: " + ar.cause().getMessage()); } }); &lt;/pre&gt; &lt;p&gt;If you prefer to use callbacks and get a &lt;code&gt;Handler&lt;/code&gt; back, Vert.x 4.0 still implements &lt;code&gt;props&lt;/code&gt;, as shown here:&lt;/p&gt; &lt;pre&gt;&lt;a target="_blank" rel="nofollow" href="https://vertx.io/docs/apidocs/io/vertx/core/file/FileSystem.html"&gt;FileSystem&lt;/a&gt; props(&lt;a target="_blank" rel="nofollow" href="https://docs.oracle.com/javase/7/docs/api/java/lang/String.html?is-external=true"&gt;String&lt;/a&gt; path,&lt;a target="_blank" rel="nofollow" href="https://vertx.io/docs/apidocs/io/vertx/core/Handler.html"&gt;Handler&lt;/a&gt;&amp;#60;&lt;a target="_blank" rel="nofollow" href="https://vertx.io/docs/apidocs/io/vertx/core/AsyncResult.html"&gt;AsyncResult&lt;/a&gt;&amp;#60;&lt;a target="_blank" rel="nofollow" href="https://vertx.io/docs/apidocs/io/vertx/core/file/FileProps.html"&gt;FileProps&lt;/a&gt;&amp;#62;&amp;#62; handler) &lt;/pre&gt; &lt;p&gt;Developers migrating from Vert.x 3.x to Vert.x 4.0 can also use &lt;code&gt;Future&lt;/code&gt; with callbacks:&lt;/p&gt; &lt;pre&gt;WebClient client = WebClient.create(vertx); HttpRequest request = client.get("/resource"); Future&amp;#60;HttpResponse&amp;#62; response = request.send(); response.onComplete(ar -&amp;#62; { if (ar.succeeded()) { HttpResponse response = ar.result(); } else { Throwable failure = ar.cause(); } }); &lt;/pre&gt; &lt;p&gt;Error handling is more straightforward with futures than with callbacks. You don&amp;#8217;t need to track yourself back into each callback, and you can handle a failure just once, at the end of a composition. Futures also let you compose asynchronous events in parallel or sequentially. All in all, this feature greatly simplifies application programming with Vert.x.&lt;/p&gt; &lt;h2&gt;Promises&lt;/h2&gt; &lt;p&gt;A &lt;i&gt;promise&lt;/i&gt; represents the writable side of an action that may or may not have yet occurred. Each promise has a &lt;a target="_blank" rel="nofollow" href="https://vertx.io/docs/apidocs/io/vertx/core/Promise.html#future--"&gt;future()&lt;/a&gt; method, which returns a &lt;code&gt;Future&lt;/code&gt; for the given promise. You can use promises and futures together to get a notification of completion. The following example shows &lt;code&gt;HttpServerVerticle&lt;/code&gt; using a promise.&lt;/p&gt; &lt;pre&gt;package com.example.starter; import io.vertx.core.AbstractVerticle; import io.vertx.core.Promise; public class MainVerticle extends AbstractVerticle { @Override public void start(Promise&amp;#60;Void&amp;#62; startPromise) throws Exception { vertx.createHttpServer().requestHandler(req -&amp;#62; { req.response() .putHeader("content-type", "text/plain") .end("Hello from Vert.x!"); }).listen(8888, http -&amp;#62; { if (http.succeeded()) { startPromise.complete(); System.out.println("HTTP server started on port 8888"); } else { startPromise.fail(http.cause()); } }); } } &lt;/pre&gt; &lt;p&gt;In this case, the method returns the &lt;a target="_blank" rel="nofollow" href="https://vertx.io/docs/apidocs/io/vertx/core/Future.html"&gt;Future&lt;/a&gt; associated with a promise. We use the &lt;code&gt;Future&lt;/code&gt; to send a notification when the promise has been completed and retrieve its value. Furthermore, a promise extends &lt;code&gt;Handler&amp;#60;AsyncResult&amp;#60;T&amp;#62;&amp;#62; &lt;/code&gt;so that we can use it as a callback.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: Before migrating your applications to Eclipse Vert.x 4.0, check for deprecations and removals. The compiler will generate a warning when you use a deprecated API.&lt;/p&gt; &lt;h2&gt;Distributed tracing&lt;/h2&gt; &lt;p&gt;Many components in a modern, distributed software application have their own operations lifecycle. The challenge is to trace various events and correlate that information across components. Tracing lets us understand the state of the system and how well the system adheres to key performance indicator metrics (KPIs). To find out how many people are getting help in a disaster-rescue effort, for example, we must correlate and trace data in a distributed software system. We can use that information to evaluate whether the software is meeting our business requirements.&lt;/p&gt; &lt;p&gt;Distributed tracing lets us visualize and understand the chain of events and flows in an interaction between software applications. For distributed tracing in microservices environments, we can use Vert.x 4.0 with &lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/en/topics/microservices/what-is-jaeger"&gt;Jaeger&lt;/a&gt;, an &lt;a target="_blank" rel="nofollow" href="https://opentracing.io"&gt;OpenTracing&lt;/a&gt; client that is part of the Cloud Native Computing Foundation.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: See the Red Hat OpenShift &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.6/jaeger/jaeger_install/rhbjaeger-deploying.html"&gt;guide to configuring and deploying Jaeger&lt;/a&gt; for instructions to install Jaeger.&lt;/p&gt; &lt;p&gt;Once we have Jaeger installed, we can use the following Vert.x components to log traces:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;HTTP server and HTTP client&lt;/li&gt; &lt;li&gt;Eclipse Vert.x SQL client&lt;/li&gt; &lt;li&gt;Eclipse Vert.x Kafka client&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Each of these components implements the following &lt;code&gt;TracingPolicy&lt;/code&gt;:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://vertx.io/docs/apidocs/io/vertx/core/tracing/TracingPolicy.html#PROPAGATE"&gt;PROPAGATE&lt;/a&gt;: The component reports a span in the active trace.&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://vertx.io/docs/apidocs/io/vertx/core/tracing/TracingPolicy.html#ALWAYS"&gt;ALWAYS&lt;/a&gt;: The component reports a span in the active trace or creates a new active trace.&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://vertx.io/docs/apidocs/io/vertx/core/tracing/TracingPolicy.html#IGNORE"&gt;IGNORE&lt;/a&gt;: Ignores tracing for the component in question.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Here&amp;#8217;s an example of a simple tracing policy implementation:&lt;/p&gt; &lt;pre&gt;HttpServer server = vertx.createHttpServer(new HttpServerOptions() .setTracingPolicy(TracingPolicy.IGNORE) ); &lt;/pre&gt; &lt;p&gt;See the &lt;a target="_blank" rel="nofollow" href="https://github.com/vert-x3/vertx-examples/tree/4.x/opentracing-examples"&gt;Vert.x Opentracing examples&lt;/a&gt; repository for a more detailed tracing example with Vert.x and Jaeger.&lt;/p&gt; &lt;h2&gt;Metering labels for OpenShift&lt;/h2&gt; &lt;p&gt;You can now add metering labels to your Eclipse Vert.x applications running on OpenShift. Customers use the labels to track deployments they have subscribed to follow. Eclipse Vert.x uses the following metering labels:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;com.redhat.component-name: Vert.x&lt;/li&gt; &lt;li&gt;com.redhat.component-type: application&lt;/li&gt; &lt;li&gt;com.redhat.component-version: 4.0.0&lt;/li&gt; &lt;li&gt;com.redhat.product-name: &amp;#8220;Red_Hat_Runtimes&amp;#8221;&lt;/li&gt; &lt;li&gt;com.redhat.product-version: 2021/Q1&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;See the OpenShift 4.6 documentation for &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.6/html/metering/index"&gt;more about metering labels&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Deploying Eclipse Vert.x applications to OpenShift&lt;/h2&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/eclipse/jkube"&gt;Eclipse JKube&lt;/a&gt; is a collection of plug-ins and libraries for building container images using Docker, Jib, or source-to-image (S2I) build strategies. Unlike its predecessor, Fabric8, Eclipse JKube eases Java development on &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; and OpenShift. Developers can focus on creating applications without getting into details, such as creating manifests.&lt;/p&gt; &lt;p&gt;Eclipse JKube includes manifests as part of the Maven build, then generates and deploys them at compile time. The JKube plug-in generates resource manifests for you automatically, which you can apply afterward. Here&amp;#8217;s an example of how to run an application on OpenShift with Eclipse JKube:&lt;/p&gt; &lt;pre&gt;# The following commmands will create your OpenShift resource descriptors. mvn clean oc:resource -Popenshift # Starting the S2I build mvn package oc:build -Popenshift   # Deploying to OpenShift mvn oc:deploy -Popenshift &lt;/pre&gt; &lt;p&gt;See this &lt;a target="_blank" rel="nofollow" href="https://github.com/eclipse/jkube/tree/master/quickstarts/maven/vertx/"&gt;sample project using Eclipse JKube plug-ins&lt;/a&gt; for more details.&lt;/p&gt; &lt;h2&gt;Packaging and deployment&lt;/h2&gt; &lt;p&gt;You can now package and deploy your applications to OpenShift with Open Container Initiative (OCI)-compliant &lt;a href="https://developers.redhat.com/articles/ubi-faq"&gt;Universal Base Images&lt;/a&gt; for &lt;a href="https://developers.redhat.com/products/openjdk/overview"&gt;Red Hat OpenJDK 8 and 11&lt;/a&gt; on &lt;a href="https://developers.redhat.com/topics/linux"&gt;Red Hat Enterprise Linux 8&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Additionally, the Vert.x &lt;code&gt;vertx-web-client.js&lt;/code&gt; is now published in the NPM repository and no longer available as a Maven artifact. You can access the client from &lt;a target="_blank" rel="nofollow" href="https://www.npmjs.com/package/@vertx/eventbus-bridge-client.js"&gt;@vertx/eventbus-bridge-client.js&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;New to reactive programming?&lt;/h2&gt; &lt;p&gt;If you are new to reactive programming, you can use &lt;a target="_blank" rel="nofollow" href="https://learn.openshift.com/middleware/courses/middleware-vertx/"&gt;self-paced scenarios&lt;/a&gt; to learn and experiment with Vert.x or learn about other technologies within Red Hat Runtimes. Each scenario provides a preconfigured Red Hat OpenShift instance that is accessible from your browser without any downloads or configuration.&lt;/p&gt; &lt;p&gt;For developers who prefer to dive deep, I recommend reading &lt;a target="_blank" rel="nofollow" href="https://www.manning.com/books/vertx-in-action"&gt;&lt;em&gt;Vert.x in Action&lt;/em&gt;&lt;/a&gt; by &lt;a href="https://developers.redhat.com/blog/author/jponge/"&gt;Julien Ponge&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Get the Red Hat build of Vert.x 4.0&lt;/h2&gt; &lt;p&gt;Support for Eclipse Vert.x is available to Red Hat customers through a &lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/en/products/runtimes"&gt;Red Hat Runtimes&lt;/a&gt; subscription. Red Hat&amp;#8217;s runtime support is scheduling according to the &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/support/policy/updates/jboss_notes/"&gt;Red Hat product update and support lifecycle&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;If you are new to Eclipse Vert.x and would like to learn more, go to our live learning portal for a guided &lt;a target="_blank" rel="nofollow" href="https://learn.openshift.com/middleware/courses/middleware-vertx/"&gt;tutorial&lt;/a&gt;, or see the &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_build_of_eclipse_vert.x/4.0/"&gt;product documentation&lt;/a&gt; for technical details. You can also check the &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/articles/3985941"&gt;supported configurations&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/articles/3348731"&gt;component details&lt;/a&gt; for Eclipse Vert.x on Red Hat Runtimes, and see the &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_build_of_eclipse_vert.x/4.0/html/eclipse_vert.x_4.0_migration_guide/"&gt;migration guide&lt;/a&gt; for a detailed introduction to migrating from Eclipse Vert.x 3.x to Vert.x 4.0.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F21%2Fintroducing-the-red-hat-build-of-eclipse-vert-x-4-0%2F&amp;#38;linkname=Introducing%20the%20Red%20Hat%20build%20of%20Eclipse%20Vert.x%204.0" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F21%2Fintroducing-the-red-hat-build-of-eclipse-vert-x-4-0%2F&amp;#38;linkname=Introducing%20the%20Red%20Hat%20build%20of%20Eclipse%20Vert.x%204.0" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F21%2Fintroducing-the-red-hat-build-of-eclipse-vert-x-4-0%2F&amp;#38;linkname=Introducing%20the%20Red%20Hat%20build%20of%20Eclipse%20Vert.x%204.0" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F21%2Fintroducing-the-red-hat-build-of-eclipse-vert-x-4-0%2F&amp;#38;linkname=Introducing%20the%20Red%20Hat%20build%20of%20Eclipse%20Vert.x%204.0" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F21%2Fintroducing-the-red-hat-build-of-eclipse-vert-x-4-0%2F&amp;#38;linkname=Introducing%20the%20Red%20Hat%20build%20of%20Eclipse%20Vert.x%204.0" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F21%2Fintroducing-the-red-hat-build-of-eclipse-vert-x-4-0%2F&amp;#38;linkname=Introducing%20the%20Red%20Hat%20build%20of%20Eclipse%20Vert.x%204.0" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F21%2Fintroducing-the-red-hat-build-of-eclipse-vert-x-4-0%2F&amp;#38;linkname=Introducing%20the%20Red%20Hat%20build%20of%20Eclipse%20Vert.x%204.0" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F21%2Fintroducing-the-red-hat-build-of-eclipse-vert-x-4-0%2F&amp;#038;title=Introducing%20the%20Red%20Hat%20build%20of%20Eclipse%20Vert.x%204.0" data-a2a-url="https://developers.redhat.com/blog/2021/01/21/introducing-the-red-hat-build-of-eclipse-vert-x-4-0/" data-a2a-title="Introducing the Red Hat build of Eclipse Vert.x 4.0"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/21/introducing-the-red-hat-build-of-eclipse-vert-x-4-0/"&gt;Introducing the Red Hat build of Eclipse Vert.x 4.0&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/PcEgqD9cg-M" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;If you are interested in reactive, non-blocking, and asynchronous Java development, you are likely familiar with Eclipse Vert.x. The project started in 2011 and successfully moved to the Eclipse Foundation in 2013. Since then, Vert.x has undergone nine years of rigorous development and grown into a thriving community. It is one of the most widely [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/21/introducing-the-red-hat-build-of-eclipse-vert-x-4-0/"&gt;Introducing the Red Hat build of Eclipse Vert.x 4.0&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/01/21/introducing-the-red-hat-build-of-eclipse-vert-x-4-0/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">855807</post-id><dc:creator>Syed M Shaaf</dc:creator><dc:date>2021-01-21T08:00:28Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/01/21/introducing-the-red-hat-build-of-eclipse-vert-x-4-0/</feedburner:origLink></entry><entry><title type="html">Apache Camel 3.8 and Java Flight Recorder</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/gS5qIFb9BGc/apache-camel-38-and-java-flight-recorder.html" /><author><name>Claus Ibsen</name></author><id>http://feedproxy.google.com/~r/ApacheCamel/~3/MAojxhqbNc0/apache-camel-38-and-java-flight-recorder.html</id><updated>2021-01-20T11:35:00Z</updated><content type="html">In the upcoming 3.8 release we have a new Camel component to integrate with Java Flight Recorder. Camel is now capable of capturing "work steps" during startup that can be recorded with Java Flight Recorder. This can be used to better diagnose and find where your Camel applications may be slow to startup, for example due to a misbehaving component or custom user code. The screenshot below shows a recording that has captured a Camel application that takes about 3 seconds to startup. Its a very tiny application so we expected it to be faster.  If we sort the events by duration in the JDK mission control, we can see that there are 4 events that take over 2 seconds. The sequence is a sequence of the following step (sub step): Initializing context -&gt; Initializing routes -&gt; Creating route (route2) -&gt; Creating Bean processor (bean1) What we can see is that the step with the highest depth is "Creating Bean processor" which takes about 2 seconds. This is the culprit of the bottleneck. If we check the Camel route for where bean1 is in use, its in route2 at:         from("direct:slow")             .to("log:slow?level=OFF")             .bean(MyBean.class, "hello"); Here we can see the bean is using MyBean class, which we can then look at next:     public MyBean() {         // force slow startup         try {             LOG.warn("Forcing 2 sec delay to have slow startup");             Thread.sleep(2000);         } catch (Exception e) {             // ignore         }     } Ah okay here is the problem. The bean is sleeping for 2 seconds. Yes of course this is a made up example, but it does affect the recording and allow us to find it via the JDK mission control tool. We also offer a logging recorder where you can "see" some of the same information as in JDK mission control. However when using JDK mission control, you have the entire JFR recording that also captures alot of JVM information about CPU and memory use and whatnot. To use Java Flight Recorder with Camel, all you have to do is to add camel-jfr on the classpath. Then Camel will auto-detect this and enable it. You can configure the recorder with various options which will be documented as part of the . But for quickly finding startup bottlenecks for Camel applications then the logging recorder is a good start. The screenshot below shows the logging output, and as you can see from the red square we have identified where the "2 second" problem is. The logging recorder comes out of the box in camel-core, and you can just use it by configuring: camel.main.startup-recorder = logging If you are using Camel Main, Camel Quarkus etc. And for Spring Boot, you can enable it with camel.springboot.startup-recorder = logging You can also set a custom recorder, or one of the out of the box implementation via Java code: camelContext.adapt(ExtendedCamelContext.class)   .setStartupStepRecorder(...); You can try this example () from the Camel Examples git repository. From command line you can run  mvn camel:run And Camel will automatic capture a JFR recording and save to disk. The output of the file is shown in the log, which you can then open from JDK mission control.  &lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/gS5qIFb9BGc" height="1" width="1" alt=""/&gt;</content><dc:creator>Claus Ibsen</dc:creator><feedburner:origLink>http://feedproxy.google.com/~r/ApacheCamel/~3/MAojxhqbNc0/apache-camel-38-and-java-flight-recorder.html</feedburner:origLink></entry><entry><title type="html">Quarkus 1.11 released - RESTEasy Reactive, Dev UI, and more!</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Cd7IOlusvD8/" /><author><name /></author><id>https://quarkus.io/blog/quarkus-1-11-0-final-released/</id><updated>2021-01-20T00:00:00Z</updated><content type="html">For each Quarkus release, it’s the same story: it comes with a ton of exciting new features and enhancements… But believe it or not, it’s true. 1.11 is an important milestone as it marks the beginning of two amazing new features: RESTEasy Reactive, Our Dev UI. But it also comes...&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Cd7IOlusvD8" height="1" width="1" alt=""/&gt;</content><dc:creator /><feedburner:origLink>https://quarkus.io/blog/quarkus-1-11-0-final-released/</feedburner:origLink></entry><entry><title>Use vim in a production Red Hat OpenShift container in 6 easy steps</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/USaqb-inbjk/" /><category term="Containers" /><category term="Kubernetes" /><category term="Linux" /><category term="Operating System" /><category term="Docker" /><category term="Fedora" /><category term="openshift" /><category term="Podman" /><category term="vim" /><author><name>Konrad Kleine</name></author><id>https://developers.redhat.com/blog/?p=806727</id><updated>2021-01-19T08:00:48Z</updated><published>2021-01-19T08:00:48Z</published><content type="html">&lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Disclaimer&lt;/strong&gt;: In most cases, we don&amp;#8217;t recommend editing files in a container. However, in rare cases, you might need to reproduce and slightly modify a file in a production container, especially when debugging. (In this case, the &lt;a target="_blank" rel="nofollow" href="https://fedoraproject.org/wiki/Vim"&gt;vim&lt;/a&gt; method I&amp;#8217;m using works on Fedora 32 on my laptop and it is the base of my &lt;a target="_blank" rel="nofollow" href="http://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt; container image.)&lt;/p&gt; &lt;p&gt;In this article, I present a quick demo on how to install and run vim in a production Red Hat OpenShift container, when vim was not installed in the &lt;a href="https://developers.redhat.com/topics/containers/"&gt;container&lt;/a&gt; image. I also describe the method to use to overcome an event where the local operating system and container base image diverge.&lt;/p&gt; &lt;h3&gt;Step 1: Copy the vim binary&lt;/h3&gt; &lt;p&gt;For &lt;code&gt;oc cp&lt;/code&gt; to work, copy the vim binary: &lt;code&gt;&lt;/code&gt;&lt;/p&gt; &lt;pre&gt;$ cp /usr/bin/vim ~/Downloads/vim&lt;/pre&gt; &lt;p&gt;(This way of copying the vim binary works best for me, although there might be another cleaner way. Let me know in the comments if you have a different way of doing it.)&lt;/p&gt; &lt;h3&gt;Step 2: Log in to the &lt;code&gt;oc&lt;/code&gt; cluster&lt;/h3&gt; &lt;p&gt;To login to the &lt;code&gt;oc&lt;/code&gt; cluster, run the command:&lt;/p&gt; &lt;pre&gt;$ oc login ..&lt;/pre&gt; &lt;h3&gt;Step 3: Specify the container to install vim into&lt;/h3&gt; &lt;p&gt;I only have one container running in my pod, so oc picks the first container in the pod automatically:&lt;/p&gt; &lt;pre&gt;$ export POD=yourPodName&lt;/pre&gt; &lt;h3&gt;Step 4: Copy files needed to run vim&lt;/h3&gt; &lt;p&gt;For vim to start properly, copy this list of files. If vim doesn&amp;#8217;t start, add files to this list and copy them over:&lt;/p&gt; &lt;pre&gt;$ export VIM_DEPS="~/Downloads/vim /lib64/libgpm.so.2.1.0 /lib64/libpython3.8.so.1.0 /lib64/libgpm.so.2"&lt;/pre&gt; &lt;pre&gt;$ for i in $VIM_DEPS; do oc cp $i $POD:/home/worker; done&lt;/pre&gt; &lt;h3&gt;Step 5: Log into the pod&lt;/h3&gt; &lt;p&gt;To login to pod, run this command:&lt;/p&gt; &lt;p&gt;&lt;code&gt;$ oc rsh $POD&lt;/code&gt;&lt;/p&gt; &lt;h3&gt;Step 6: Run vim&lt;/h3&gt; &lt;p&gt;To run vim, enter the following:&lt;/p&gt; &lt;pre&gt;worker@pod$ LD_LIBRARY_PATH="$LD_LIBRARY_PATH:/home/worker" PATH="$PATH:$PWD" vim&lt;/pre&gt; &lt;h3&gt;What if my operating system differs from the container&amp;#8217;s base image?&lt;/h3&gt; &lt;p style="text-align: left;"&gt;Make sure the architecture of your container image and laptop match. Then fire up a base image that can run locally in a container. Install vim in that container that runs on your localhost. Copy out the vim binary as is; for example, using &lt;code&gt;podman cp&lt;/code&gt; or &lt;code&gt;docker cp&lt;/code&gt;, and copy it to the pod as previously described. Run vim in the pod and observe what files are missing. These files can be taken from the container running on your localhost.&lt;/p&gt; &lt;p&gt;I hope that this quick tip vim helps when you need to reproduce and slightly modify a file in an OpenShift production container.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F19%2Fuse-vim-in-a-production-red-hat-openshift-container-in-6-easy-steps%2F&amp;#38;linkname=Use%20vim%20in%20a%20production%20Red%20Hat%20OpenShift%20container%20in%206%20easy%20steps" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F19%2Fuse-vim-in-a-production-red-hat-openshift-container-in-6-easy-steps%2F&amp;#38;linkname=Use%20vim%20in%20a%20production%20Red%20Hat%20OpenShift%20container%20in%206%20easy%20steps" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F19%2Fuse-vim-in-a-production-red-hat-openshift-container-in-6-easy-steps%2F&amp;#38;linkname=Use%20vim%20in%20a%20production%20Red%20Hat%20OpenShift%20container%20in%206%20easy%20steps" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F19%2Fuse-vim-in-a-production-red-hat-openshift-container-in-6-easy-steps%2F&amp;#38;linkname=Use%20vim%20in%20a%20production%20Red%20Hat%20OpenShift%20container%20in%206%20easy%20steps" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F19%2Fuse-vim-in-a-production-red-hat-openshift-container-in-6-easy-steps%2F&amp;#38;linkname=Use%20vim%20in%20a%20production%20Red%20Hat%20OpenShift%20container%20in%206%20easy%20steps" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F19%2Fuse-vim-in-a-production-red-hat-openshift-container-in-6-easy-steps%2F&amp;#38;linkname=Use%20vim%20in%20a%20production%20Red%20Hat%20OpenShift%20container%20in%206%20easy%20steps" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F19%2Fuse-vim-in-a-production-red-hat-openshift-container-in-6-easy-steps%2F&amp;#38;linkname=Use%20vim%20in%20a%20production%20Red%20Hat%20OpenShift%20container%20in%206%20easy%20steps" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F19%2Fuse-vim-in-a-production-red-hat-openshift-container-in-6-easy-steps%2F&amp;#038;title=Use%20vim%20in%20a%20production%20Red%20Hat%20OpenShift%20container%20in%206%20easy%20steps" data-a2a-url="https://developers.redhat.com/blog/2021/01/19/use-vim-in-a-production-red-hat-openshift-container-in-6-easy-steps/" data-a2a-title="Use vim in a production Red Hat OpenShift container in 6 easy steps"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/19/use-vim-in-a-production-red-hat-openshift-container-in-6-easy-steps/"&gt;Use vim in a production Red Hat OpenShift container in 6 easy steps&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/USaqb-inbjk" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Disclaimer: In most cases, we don&amp;#8217;t recommend editing files in a container. However, in rare cases, you might need to reproduce and slightly modify a file in a production container, especially when debugging. (In this case, the vim method I&amp;#8217;m using works on Fedora 32 on my laptop and it is the base of my [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/19/use-vim-in-a-production-red-hat-openshift-container-in-6-easy-steps/"&gt;Use vim in a production Red Hat OpenShift container in 6 easy steps&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/01/19/use-vim-in-a-production-red-hat-openshift-container-in-6-easy-steps/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">806727</post-id><dc:creator>Konrad Kleine</dc:creator><dc:date>2021-01-19T08:00:48Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/01/19/use-vim-in-a-production-red-hat-openshift-container-in-6-easy-steps/</feedburner:origLink></entry><entry><title type="html">Keycloak 12.0.2 released</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/NitRTLxDU2Y/keycloak-1202-released.html" /><author><name /></author><id>https://www.keycloak.org//2021/01/keycloak-1202-released.html</id><updated>2021-01-19T00:00:00Z</updated><content type="html">To download the release go to . ALL RESOLVED ISSUES The full list of resolved issues are available in UPGRADING Before you upgrade remember to backup your database and check the for anything that may have changed.&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/NitRTLxDU2Y" height="1" width="1" alt=""/&gt;</content><dc:creator /><feedburner:origLink>https://www.keycloak.org//2021/01/keycloak-1202-released.html</feedburner:origLink></entry><entry><title>Operator integration testing for Operator Lifecycle Manager</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/JGPT-p5D_pY/" /><category term="Linux" /><category term="Mac" /><category term="Operator" /><category term="Red Hat CodeReady Containers" /><category term="Red Hat OpenShift Container Platform" /><author><name>Taneem Ibrahim</name></author><id>https://developers.redhat.com/blog/?p=784997</id><updated>2021-01-18T08:00:54Z</updated><published>2021-01-18T08:00:54Z</published><content type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/topics/kubernetes/operators"&gt;Operators&lt;/a&gt; are one of the ways to package, deploy, and manage application distribution on &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt;. After a developer creates an Operator, the next step is to get the Operator published on &lt;a target="_blank" rel="nofollow" href="https://operatorhub.io/"&gt;OperatorHub.io&lt;/a&gt;. Doing this allows users to install and deploy the Operator in their OpenShift clusters. The Operator is installed, updated, and the management lifecycle is handled by the &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.5/operators/understanding_olm/olm-understanding-olm.html"&gt;Operator Lifecycle Manager (OLM)&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;In this article, we explore the steps required to test OLM integration for the Operator. For demonstration, we use a simple Operator that prints a test message to the shell. The Operator is packaged in the recently introduced &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.5/operators/olm-packaging-format.html#olm-bundle-format_olm-packaging-format"&gt;Bundle Format&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;span id="more-784997"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;For our local development environment, we need access to the following toolkits:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/products/codeready-containers"&gt;Red Hat CodeReady Containers (CRC)&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://podman.io/"&gt;Podman&lt;/a&gt;, or a Docker daemon process running on the local machine&lt;/li&gt; &lt;li&gt;Operator SDK toolkit, v1.0.0 or higher (optional)&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/operator-framework/operator-registry/releases/tag/v1.13.8"&gt;Operator Package Manager (OPM)&lt;/a&gt;&lt;/li&gt; &lt;li&gt;OpenShift Container Platform, cluster version 4.5 or higher&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;We need CRC because it provides convenient single-node minimal OpenShift clusters that are primarily intended to aid developers in testing. The OPM provides our local desktop environment.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: After downloading OPM, we rename the &lt;code&gt;opm&lt;/code&gt; binary for ease of use by setting the binary&amp;#8217;s permission to at least make it readable and executable.&lt;/p&gt; &lt;p&gt;Once you have everything set up, create a free account on &lt;a target="_blank" rel="nofollow" href="https://quay.io/"&gt;Red Hat Quay.io&lt;/a&gt;. We use Quay to build, analyze, distribute, and host container images. In this case, take note of the &lt;code&gt;quay_username&lt;/code&gt; and set the following environment variable for ease of use:&lt;/p&gt; &lt;pre style="padding-left: 40px;"&gt;&amp;#62; export quay_username=&amp;#60;your_quay_user_name&amp;#62; &amp;#62; echo $quay_username&lt;/pre&gt; &lt;p&gt;Now we are ready to get started on our OLM integration test.&lt;/p&gt; &lt;h2&gt;Step 1: Download the Operator package&lt;/h2&gt; &lt;p&gt;To get started, let’s clone the following Git repository. This repository contains our example Operator bundle package that we deploy to the local OperatorHub instance in our cluster.&lt;/p&gt; &lt;pre style="padding-left: 40px;"&gt;&amp;#62;  git clone https://github.com/taneem-ibrahim/olm-testing-bundle-format-index.git&lt;/pre&gt; &lt;p&gt;This creates the following directory structure:&lt;/p&gt; &lt;pre style="padding-left: 40px;"&gt;foo-operator % tree ├── bundle │   ├── manifests │   │   ├── example.com_foobars.yaml │   │   ├── foobar-operator-metrics-reader_rbac.authorization.k8s.io_v1beta1_clusterrole.yaml │   │   └── foobar-operator.clusterserviceversion.yaml │   ├── metadata │   │   └── annotations.yaml │   └── tests │       └── scorecard │           └── config.yaml ├── bundle.Dockerfile ├── catalogsource.yaml └── subscription.yaml&lt;/pre&gt; &lt;h2&gt;&lt;b&gt;Step 2: Build and push the Operator bundle image&lt;/b&gt;&lt;/h2&gt; &lt;p&gt;Our next step is to build the Operator bundle image and publish it to a container registry. In our examples, we use Quay to host our container images. From the Operator&amp;#8217;s root directory, &lt;code&gt;foobar-operator&lt;/code&gt;, let’s run the following commands. Substitute the &lt;code&gt;&amp;#60;quay_username&amp;#62;&lt;/code&gt; tag for your own &lt;code&gt;quay_username&lt;/code&gt;.&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: When you use Podman, you can run the following commands just by replacing the word Docker with Podman. For example:&lt;/p&gt;&lt;/blockquote&gt; &lt;pre style="padding-left: 40px;"&gt;&amp;#62; docker login quay.io -u $quay_username &amp;#62; docker build -f bundle.Dockerfile -t quay.io/$quay_username/foobar-operator:v0.0.1 . &amp;#62; docker push quay.io/$quay_username/foobar-operator:v0.0.1&lt;/pre&gt; &lt;p&gt;When we create a new repository in Quay by default, the repository visibility is set to private. For simplicity, we log into the Quay web portal and see the &lt;a target="_blank" rel="nofollow" href="https://docs.quay.io/guides/repo-view.html"&gt;repository access&lt;/a&gt; to the public. This can be set from the repository&amp;#8217;s Settings tab or by going to &lt;code&gt;https://quay.io/repository/&lt;/code&gt;. Then substitute the &lt;code&gt;quay_username&lt;/code&gt; or repository name accordingly.&lt;/p&gt; &lt;p&gt;When we prefer to keep the repository visibility private, we can add an &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.5/openshift_images/managing_images/using-image-pull-secrets.html#images-update-global-pull-secret_using-image-pull-secrets"&gt;image pull secret&lt;/a&gt;. Operator pods use the default &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.5/authentication/using-service-accounts-in-applications.html"&gt;service account&lt;/a&gt; in the &lt;code&gt;openshift-marketplace&lt;/code&gt; namespace.&lt;/p&gt; &lt;p&gt;This Operator is a simple image that loops and prints the following message &lt;code&gt;v0.0.1&lt;/code&gt; to the console:&lt;/p&gt; &lt;pre style="padding-left: 40px;"&gt;spec: ....               containers:               - &lt;b&gt;command: [ "/bin/sh", "-c", "while true ; do echo v0.0.1; sleep 10; done;" ]&lt;/b&gt;                 image: docker.io/busybox&lt;/pre&gt; &lt;h2&gt;&lt;b&gt;Step 3: Validate the Operator bundle package (optional)&lt;/b&gt;&lt;/h2&gt; &lt;p&gt;This is an optional step. Let’s validate the Operator bundle package we just built and pushed. The following command needs to end with the message: &lt;code&gt;all validation tests have completed successfully&lt;/code&gt;&lt;/p&gt; &lt;pre style="padding-left: 40px;"&gt;&amp;#62; operator-sdk bundle validate quay.io/$quay_username/foobar-operator:v0.0.1&lt;/pre&gt; &lt;h2&gt;&lt;b&gt;Step 4: Build and push an index image&lt;/b&gt;&lt;/h2&gt; &lt;p&gt;Once the Operator bundle image is pushed, the next step is to create and publish an index image, making the Operator available using the OLM for users to install in their clusters. &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.5/operators/olm-managing-custom-catalogs.html#olm-creating-index-image_olm-managing-custom-catalogs"&gt;Index image&lt;/a&gt; is a database of pointers to Operator manifest content, which enables OLM to query the Operator image versions and get the desired Operator version installed on the cluster.&lt;/p&gt; &lt;p&gt;We use the OPM tool to create the index image for our &lt;code&gt;foobar-operator&lt;/code&gt; bundle. After building the image, we push the image to Quay. When we use Podman, we do not need to add &lt;code&gt;--build-tool docker&lt;/code&gt; because &lt;code&gt;opm&lt;/code&gt; defaults to Podman for the build tool:&lt;/p&gt; &lt;pre style="padding-left: 40px;"&gt;&amp;#62; opm index add --bundles quay.io/$quay_username/foobar-operator:v0.0.1 --tag quay.io/$quay_username/foobar-operator-index:latest --build-tool docker &amp;#62; docker push quay.io/$quay_username/foobar-operator-index:latest&lt;/pre&gt; &lt;p&gt;As before, we need to set the repository visibility of &lt;code&gt;foobar-operator&lt;/code&gt; index to public for simplicity on Quay.&lt;/p&gt; &lt;h2&gt;&lt;b&gt;Step 5: Create a custom CatalogSource object&lt;/b&gt;&lt;/h2&gt; &lt;p&gt;The &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.5/operators/olm-managing-custom-catalogs.html#olm-creating-catalog-from-index_olm-managing-custom-catalogs"&gt;CatalogSource&lt;/a&gt; represents Operator metadata that OLM can query to discover and install Operators and their dependencies. We create the following CatalogSource resource. Don’t forget to substitute the appropriate &lt;code&gt;quay_username&lt;/code&gt; according to the &lt;code&gt;$quay_username&lt;/code&gt; for the index image location on Quay. Save the file as &lt;code&gt;catalogsource.yaml&lt;/code&gt;:&lt;/p&gt; &lt;pre style="padding-left: 40px;"&gt;spec:   sourceType: grpc   image: quay.io/&lt;b&gt;&amp;#60;substitute_quay_username&amp;#62;&lt;/b&gt;/foobar-operator-index:latest   displayName: Custom Catalog   updateStrategy:     registryPoll:        interval: 5m&lt;/pre&gt; &lt;p&gt;Let’s create the catalog source object:&lt;/p&gt; &lt;pre style="padding-left: 40px;"&gt;&amp;#62; oc create -f catalogsource.yaml&lt;/pre&gt; &lt;p&gt;We are using the &lt;code&gt;openshift-marketplace&lt;/code&gt; namespace above since it is a global namespace. This means a subscription created in any namespace is able to resolve in the cluster. However, we can choose any custom namespace here as long as it matches the related subscription object namespace created in the next step.&lt;/p&gt; &lt;p&gt;Additionally, the name of the CatalogSource object determines which catalog registry the Operator shows up under on the OperatorHub console. In the example above, we are using &lt;code&gt;custom&lt;/code&gt; with the display name set to CustomCatalog. We also configured the catalog to automatically poll for the latest version of the index image for the Operator every five minutes.&lt;/p&gt; &lt;p&gt;We can validate the deployment of the pod by querying the pod logs:&lt;/p&gt; &lt;pre style="padding-left: 40px;"&gt;&amp;#62; oc get pods -n openshift-marketplace | grep “custom” &amp;#62; oc logs custom-&amp;#60;pod_id&amp;#62; -n openshift-marketplace &amp;#62; … level=info msg="serving registry" database=/database/index.db port=50051&lt;/pre&gt; &lt;h2&gt;&lt;b&gt;Step 6: Create a subscription object&lt;/b&gt;&lt;/h2&gt; &lt;p&gt;A &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.5/operators/understanding_olm/olm-understanding-olm.html#olm-subscription_olm-understanding-olm"&gt;subscription&lt;/a&gt; is a custom resource that describes the channel the Operator subscribes to, and whether the Operator needs to be updated manually or automatically. We are installing the Operator in the alpha channel since our bundle manifest channel is set to &lt;code&gt;alpha&lt;/code&gt; in the annotations.yaml file. The other available channel is &lt;code&gt;stable&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;We can validate the channel by running the following command:&lt;/p&gt; &lt;pre style="padding-left: 40px;"&gt;&amp;#62; oc get packagemanifests foobar-operator -o jsonpath='{.status.defaultChannel}' &amp;#62; alpha&lt;/pre&gt; &lt;p&gt;The GitHub repository has a subscription.yaml file provided. From the &lt;code&gt;foobar-operator&lt;/code&gt; root directory, we can run the following command to create the subscription object:&lt;/p&gt; &lt;pre style="padding-left: 40px;"&gt;&amp;#62; oc create -f subscription.yaml&lt;/pre&gt; &lt;h2&gt;&lt;b&gt;Step 7: Install the Operator from the OperatorHub&lt;/b&gt;&lt;/h2&gt; &lt;p&gt;Let’s log into the OpenShift admin console, navigate to the OperatorHub, and search for our Operator, as shown in Figure 1.&lt;/p&gt; &lt;div id="attachment_785017" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/step-8.png"&gt;&lt;img aria-describedby="caption-attachment-785017" class="wp-image-785017 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/step-8-1024x269.png" alt="Operators -&amp;#62; OperatorHub -&amp;#62; Searching All Items for &amp;#34;foo&amp;#34; returns &amp;#34;foobar&amp;#34;" width="640" height="168" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/step-8-1024x269.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/step-8-300x79.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/step-8-768x202.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/step-8.png 1600w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-785017" class="wp-caption-text"&gt;Figure 1. Use the OperatorHub to search and locate our Operator.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Now we can install this Operator as shown in Figure 2.&lt;/p&gt; &lt;div id="attachment_785027" style="width: 242px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/step8-1.png"&gt;&lt;img aria-describedby="caption-attachment-785027" class="wp-image-785027 size-medium" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/step8-1-232x300.png" alt="foobar install section set to Capability Level Basic Install" width="232" height="300" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/step8-1-232x300.png 232w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/step8-1.png 628w" sizes="(max-width: 232px) 100vw, 232px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-785027" class="wp-caption-text"&gt;Figure 2. Click Install and select openshift-marketplace namespace.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;We can also query the Operator pod logs to see if it’s printing &lt;code&gt;v0.0.1&lt;/code&gt; as we had in our deployment container spec for the Operator image:&lt;/p&gt; &lt;pre style="padding-left: 40px;"&gt;&amp;#62; oc logs -f foobar-operator-controller-manager-&amp;#60;pod_id&amp;#62; -n openshift-marketplace &amp;#62; v0.0.1&lt;/pre&gt; &lt;p&gt;That’s it. We successfully validated our Operator integration with OLM.&lt;/p&gt; &lt;h2&gt;&lt;b&gt;Upgrade the Operator version&lt;/b&gt;&lt;/h2&gt; &lt;p&gt;Now we do a simple Operator upgrade test just by updating the Operator version tag from &lt;code&gt;0.0.1&lt;/code&gt; to &lt;code&gt;0.0.2&lt;/code&gt; in the CatalogService Version (CSV) file. Let’s run the following command from the root directory of our &lt;code&gt;foobar-operator&lt;/code&gt;:&lt;/p&gt; &lt;pre style="padding-left: 40px;"&gt;&amp;#62; sed 's/0.0.1/0.0.2/g' ./bundle/manifests/foobar-operator.clusterserviceversion.yaml &amp;#62; ./bundle/manifests/foobar-operator.clusterserviceversion.yaml&lt;/pre&gt; &lt;p&gt;Next, we repeat Steps 1 and 2 above to build and optionally validate the new Operator bundle image, and substitute the image version tags to be &lt;code&gt;0.0.2&lt;/code&gt; instead of &lt;code&gt;0.0.1&lt;/code&gt; in the Docker push commands respectively.&lt;/p&gt; &lt;p&gt;We are now ready to add the new Operator version to the registry. We can do that by using the &lt;code&gt;opm add&lt;/code&gt; command. Notice how we are adding the upgraded Operator version cumulatively by inserting the &lt;code&gt;from-index&lt;/code&gt; parameter. If using Podman, then we do not have to pass the &lt;code&gt;--build-tool docker&lt;/code&gt; option since &lt;code&gt;opm&lt;/code&gt; defaults to Podman build tool:&lt;/p&gt; &lt;pre style="padding-left: 40px;"&gt;&amp;#62; opm index add --bundles quay.io/$quay_username/foobar-operator:v0.0.2 --from-index quay.io/$quay_username/foobar-operator-index:latest --tag quay.io/$quay_username/foobar-operator-index:latest --build-tool docker&lt;/pre&gt; &lt;p&gt;In the Quay repository, we can validate the latest versions of the Operator image and index image by running the Docker images (or Podman images) command as shown in Figure 3.&lt;/p&gt; &lt;div id="attachment_785037" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/upgrade-1.png"&gt;&lt;img aria-describedby="caption-attachment-785037" class="wp-image-785037 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/upgrade-1-1024x54.png" alt="opm index add output showing two repositories, foobar-operator-index (set to latest) and foobar-operator (set to v0.0.2)" width="640" height="34" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/upgrade-1-1024x54.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/upgrade-1-300x16.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/upgrade-1-768x40.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/upgrade-1.png 1600w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-785037" class="wp-caption-text"&gt;Figure 3. Validate the latest Operator images and index images using the Docker (or Podman) images command.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;We push this new version of the index image to Quay:&lt;/p&gt; &lt;pre style="padding-left: 40px;"&gt;&amp;#62; docker push quay.io/$quay_username/foobar-operator-index:latest&lt;/pre&gt; &lt;p&gt;The CatalogSource automatically polls for the latest version every five minutes. After five minutes have passed, we can go to the OperatorHub console and validate the Operator version 0.0.2 is available as shown in Figure 4.&lt;/p&gt; &lt;div id="attachment_785047" style="width: 310px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/upgrade-2.png"&gt;&lt;img aria-describedby="caption-attachment-785047" class="wp-image-785047 size-medium" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/upgrade-2-300x233.png" alt="The foobar Operator section showing version 0.0.2" width="300" height="233" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/upgrade-2-300x233.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/upgrade-2.png 628w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-785047" class="wp-caption-text"&gt;Figure 4. Verify the OperatorHub console and validate that the available Operator version is 0.0.2.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Let’s install the new Operator version in the &lt;code&gt;openshift-marketplace&lt;/code&gt; namespace and validate the Operator pod log to see if &lt;code&gt;v0.0.2&lt;/code&gt; is being echoed:&lt;/p&gt; &lt;pre style="padding-left: 40px;"&gt;&amp;#62; oc logs -f foobar-operator-controller-manager-&amp;#60;pod_id&amp;#62; -n openshift-marketplace v0.0.2&lt;/pre&gt; &lt;p&gt;Now that you know how to test OLM integration for an Operator, give it a try with your own projects!&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F18%2Foperator-integration-testing-for-operator-lifecycle-manager%2F&amp;#38;linkname=Operator%20integration%20testing%20for%20Operator%20Lifecycle%20Manager" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F18%2Foperator-integration-testing-for-operator-lifecycle-manager%2F&amp;#38;linkname=Operator%20integration%20testing%20for%20Operator%20Lifecycle%20Manager" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F18%2Foperator-integration-testing-for-operator-lifecycle-manager%2F&amp;#38;linkname=Operator%20integration%20testing%20for%20Operator%20Lifecycle%20Manager" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F18%2Foperator-integration-testing-for-operator-lifecycle-manager%2F&amp;#38;linkname=Operator%20integration%20testing%20for%20Operator%20Lifecycle%20Manager" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F18%2Foperator-integration-testing-for-operator-lifecycle-manager%2F&amp;#38;linkname=Operator%20integration%20testing%20for%20Operator%20Lifecycle%20Manager" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F18%2Foperator-integration-testing-for-operator-lifecycle-manager%2F&amp;#38;linkname=Operator%20integration%20testing%20for%20Operator%20Lifecycle%20Manager" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F18%2Foperator-integration-testing-for-operator-lifecycle-manager%2F&amp;#38;linkname=Operator%20integration%20testing%20for%20Operator%20Lifecycle%20Manager" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F18%2Foperator-integration-testing-for-operator-lifecycle-manager%2F&amp;#038;title=Operator%20integration%20testing%20for%20Operator%20Lifecycle%20Manager" data-a2a-url="https://developers.redhat.com/blog/2021/01/18/operator-integration-testing-for-operator-lifecycle-manager/" data-a2a-title="Operator integration testing for Operator Lifecycle Manager"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/18/operator-integration-testing-for-operator-lifecycle-manager/"&gt;Operator integration testing for Operator Lifecycle Manager&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/JGPT-p5D_pY" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Operators are one of the ways to package, deploy, and manage application distribution on Red Hat OpenShift. After a developer creates an Operator, the next step is to get the Operator published on OperatorHub.io. Doing this allows users to install and deploy the Operator in their OpenShift clusters. The Operator is installed, updated, and the [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/18/operator-integration-testing-for-operator-lifecycle-manager/"&gt;Operator integration testing for Operator Lifecycle Manager&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/01/18/operator-integration-testing-for-operator-lifecycle-manager/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">784997</post-id><dc:creator>Taneem Ibrahim</dc:creator><dc:date>2021-01-18T08:00:54Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/01/18/operator-integration-testing-for-operator-lifecycle-manager/</feedburner:origLink></entry><entry><title type="html">RESTEasy WADL module deployment on Wildfly</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Fgl-FcGx-QQ/" /><author><name /></author><id>https://resteasy.github.io/2021/01/18/deploy-resteasy-wadl-to-wildfly/</id><updated>2021-01-18T00:00:00Z</updated><dc:creator /><summary type="html">&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Fgl-FcGx-QQ" height="1" width="1" alt=""/&gt;</summary><feedburner:origLink>https://resteasy.github.io/2021/01/18/deploy-resteasy-wadl-to-wildfly/</feedburner:origLink></entry><entry><title>Coming in glibc 2.33: Reloadable nsswitch.conf</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/icXSyt_kNkE/" /><category term="C" /><category term="Linux" /><category term="glibc" /><category term="nsswitch" /><category term="nsswitch.conf" /><category term="reload config" /><author><name>DJ Delorie</name></author><id>https://developers.redhat.com/blog/?p=835617</id><updated>2021-01-15T08:00:59Z</updated><published>2021-01-15T08:00:59Z</published><content type="html">&lt;p&gt;In my &lt;a href="https://developers.redhat.com/blog/2018/11/26/etc-nsswitch-conf-non-complexity/"&gt;previous article about nsswitch.conf&lt;/a&gt; I talked about how simple, perhaps too simple, this config file is to use. What I didn&amp;#8217;t cover then was how simplistic its internal implementation is. Specifically, an application only loads this file once—the first time it&amp;#8217;s needed.&lt;/p&gt; &lt;p&gt;So, what do you do when &lt;a target="_blank" rel="nofollow" href="https://en.wikipedia.org/wiki/Name_Service_Switch"&gt;nsswitch.conf&lt;/a&gt; needs to change? How do you update all of the running applications? You don’t! The only way to force a reload is to stop the application and restart it. That is not always an option, especially for critical applications that might take a long time to restart.&lt;/p&gt; &lt;p&gt;Recent work behind the scenes in the GNU C library will change all of this. As of &lt;a target="_blank" rel="nofollow" href="https://www.gnu.org/software/libc/"&gt;glibc&lt;/a&gt; version 2.33, this config file now reloads and reparses each time it changes, and only the configuration is reloaded. If the configuration calls for an external shared library to be loaded, that object is only ever loaded once. It may be called in a different sequence, or not called at all, but it is never unloaded. This behavior avoids a whole class of problems related to unloading shared objects that might still be in use.&lt;/p&gt; &lt;p&gt;Most applications will never know any of this is happening. They do their lookups and get the data they need, even if it’s different than the last time. Applications that cache their lookups will never know anything changed. The catch is that if an application caches some of its lookups, but not others, it might receive an inconsistent set of information. Applications should already accommodate changes in the data, such as host addresses or the occasional UID update, so changing how that information is provided should not significantly change the application or increase the burden to the programmer.&lt;/p&gt; &lt;p&gt;I’ll address one concern likely to come up—memory. To avoid unrestrained growth in long-running programs, the parser maintains a pool of the pre-parsed lines it’s seen, and an array of the services it provides. It only needs to link the existing bits of data together. However, this practice assumes that the overall number of action permutations is limited. Most systems cycle between a few lines, so the size of this pool is limited, as shown in Figure 1. The data for each shared object is also fixed once the object is loaded.&lt;/p&gt; &lt;p&gt;&lt;div id="attachment_835637" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/12/data.png"&gt;&lt;img aria-describedby="caption-attachment-835637" class="wp-image-835637" src="https://developers.redhat.com/blog/wp-content/uploads/2020/12/data.png" alt="Change flow: passwd&amp;#62; dns files &amp;#62; libnss_dns.so + libnss_files.so + __nss_files, group &amp;#62; files, hosts &amp;#62; dns [NOTFOUND=return] files" width="640" height="253" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/12/data.png 764w, https://developers.redhat.com/blog/wp-content/uploads/2020/12/data-300x119.png 300w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-835637" class="wp-caption-text"&gt;Figure 1: Create the data for each shared object that is fixed once the object is loaded.&lt;/p&gt;&lt;/div&gt;Of course, there is one key caveat. Anything that updates nsswitch.conf needs to do it as atomically as possible so that applications don’t see a partial configuration and try to load it. If you are using a tool like &lt;code&gt;rsync&lt;/code&gt; to update remote machines (say, in a cluster or compute farm, or across a business unit), make sure you don’t use the &lt;code&gt;--inplace&lt;/code&gt; option. You might want to use a create/copy/rename sequence so that glibc doesn’t see a half-copied file.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F15%2Fcoming-in-glibc-2-33-reloadable-nsswitch-conf%2F&amp;#38;linkname=Coming%20in%20glibc%202.33%3A%20Reloadable%20nsswitch.conf" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F15%2Fcoming-in-glibc-2-33-reloadable-nsswitch-conf%2F&amp;#38;linkname=Coming%20in%20glibc%202.33%3A%20Reloadable%20nsswitch.conf" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F15%2Fcoming-in-glibc-2-33-reloadable-nsswitch-conf%2F&amp;#38;linkname=Coming%20in%20glibc%202.33%3A%20Reloadable%20nsswitch.conf" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F15%2Fcoming-in-glibc-2-33-reloadable-nsswitch-conf%2F&amp;#38;linkname=Coming%20in%20glibc%202.33%3A%20Reloadable%20nsswitch.conf" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F15%2Fcoming-in-glibc-2-33-reloadable-nsswitch-conf%2F&amp;#38;linkname=Coming%20in%20glibc%202.33%3A%20Reloadable%20nsswitch.conf" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F15%2Fcoming-in-glibc-2-33-reloadable-nsswitch-conf%2F&amp;#38;linkname=Coming%20in%20glibc%202.33%3A%20Reloadable%20nsswitch.conf" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F15%2Fcoming-in-glibc-2-33-reloadable-nsswitch-conf%2F&amp;#38;linkname=Coming%20in%20glibc%202.33%3A%20Reloadable%20nsswitch.conf" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F15%2Fcoming-in-glibc-2-33-reloadable-nsswitch-conf%2F&amp;#038;title=Coming%20in%20glibc%202.33%3A%20Reloadable%20nsswitch.conf" data-a2a-url="https://developers.redhat.com/blog/2021/01/15/coming-in-glibc-2-33-reloadable-nsswitch-conf/" data-a2a-title="Coming in glibc 2.33: Reloadable nsswitch.conf"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/15/coming-in-glibc-2-33-reloadable-nsswitch-conf/"&gt;Coming in glibc 2.33: Reloadable nsswitch.conf&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/icXSyt_kNkE" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;In my previous article about nsswitch.conf I talked about how simple, perhaps too simple, this config file is to use. What I didn&amp;#8217;t cover then was how simplistic its internal implementation is. Specifically, an application only loads this file once—the first time it&amp;#8217;s needed. So, what do you do when nsswitch.conf needs to change? How [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/15/coming-in-glibc-2-33-reloadable-nsswitch-conf/"&gt;Coming in glibc 2.33: Reloadable nsswitch.conf&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/01/15/coming-in-glibc-2-33-reloadable-nsswitch-conf/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">835617</post-id><dc:creator>DJ Delorie</dc:creator><dc:date>2021-01-15T08:00:59Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/01/15/coming-in-glibc-2-33-reloadable-nsswitch-conf/</feedburner:origLink></entry></feed>

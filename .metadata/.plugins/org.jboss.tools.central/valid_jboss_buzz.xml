<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Coming in glibc 2.33: Reloadable nsswitch.conf</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/icXSyt_kNkE/" /><category term="C" /><category term="Linux" /><category term="glibc" /><category term="nsswitch" /><category term="nsswitch.conf" /><category term="reload config" /><author><name>DJ Delorie</name></author><id>https://developers.redhat.com/blog/?p=835617</id><updated>2021-01-15T08:00:59Z</updated><published>2021-01-15T08:00:59Z</published><content type="html">&lt;p&gt;In my &lt;a href="https://developers.redhat.com/blog/2018/11/26/etc-nsswitch-conf-non-complexity/"&gt;previous article about nsswitch.conf&lt;/a&gt; I talked about how simple, perhaps too simple, this config file is to use. What I didn&amp;#8217;t cover then was how simplistic its internal implementation is. Specifically, an application only loads this file once—the first time it&amp;#8217;s needed.&lt;/p&gt; &lt;p&gt;So, what do you do when &lt;a target="_blank" rel="nofollow" href="https://en.wikipedia.org/wiki/Name_Service_Switch"&gt;nsswitch.conf&lt;/a&gt; needs to change? How do you update all of the running applications? You don’t! The only way to force a reload is to stop the application and restart it. That is not always an option, especially for critical applications that might take a long time to restart.&lt;/p&gt; &lt;p&gt;Recent work behind the scenes in the GNU C library will change all of this. As of &lt;a target="_blank" rel="nofollow" href="https://www.gnu.org/software/libc/"&gt;glibc&lt;/a&gt; version 2.33, this config file now reloads and reparses each time it changes, and only the configuration is reloaded. If the configuration calls for an external shared library to be loaded, that object is only ever loaded once. It may be called in a different sequence, or not called at all, but it is never unloaded. This behavior avoids a whole class of problems related to unloading shared objects that might still be in use.&lt;/p&gt; &lt;p&gt;Most applications will never know any of this is happening. They do their lookups and get the data they need, even if it’s different than the last time. Applications that cache their lookups will never know anything changed. The catch is that if an application caches some of its lookups, but not others, it might receive an inconsistent set of information. Applications should already accommodate changes in the data, such as host addresses or the occasional UID update, so changing how that information is provided should not significantly change the application or increase the burden to the programmer.&lt;/p&gt; &lt;p&gt;I’ll address one concern likely to come up—memory. To avoid unrestrained growth in long-running programs, the parser maintains a pool of the pre-parsed lines it’s seen, and an array of the services it provides. It only needs to link the existing bits of data together. However, this practice assumes that the overall number of action permutations is limited. Most systems cycle between a few lines, so the size of this pool is limited, as shown in Figure 1. The data for each shared object is also fixed once the object is loaded.&lt;/p&gt; &lt;p&gt;&lt;div id="attachment_835637" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/12/data.png"&gt;&lt;img aria-describedby="caption-attachment-835637" class="wp-image-835637" src="https://developers.redhat.com/blog/wp-content/uploads/2020/12/data.png" alt="Change flow: passwd&amp;#62; dns files &amp;#62; libnss_dns.so + libnss_files.so + __nss_files, group &amp;#62; files, hosts &amp;#62; dns [NOTFOUND=return] files" width="640" height="253" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/12/data.png 764w, https://developers.redhat.com/blog/wp-content/uploads/2020/12/data-300x119.png 300w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-835637" class="wp-caption-text"&gt;Figure 1: Create the data for each shared object that is fixed once the object is loaded.&lt;/p&gt;&lt;/div&gt;Of course, there is one key caveat. Anything that updates nsswitch.conf needs to do it as atomically as possible so that applications don’t see a partial configuration and try to load it. If you are using a tool like &lt;code&gt;rsync&lt;/code&gt; to update remote machines (say, in a cluster or compute farm, or across a business unit), make sure you don’t use the &lt;code&gt;--inplace&lt;/code&gt; option. You might want to use a create/copy/rename sequence so that glibc doesn’t see a half-copied file.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F15%2Fcoming-in-glibc-2-33-reloadable-nsswitch-conf%2F&amp;#38;linkname=Coming%20in%20glibc%202.33%3A%20Reloadable%20nsswitch.conf" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F15%2Fcoming-in-glibc-2-33-reloadable-nsswitch-conf%2F&amp;#38;linkname=Coming%20in%20glibc%202.33%3A%20Reloadable%20nsswitch.conf" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F15%2Fcoming-in-glibc-2-33-reloadable-nsswitch-conf%2F&amp;#38;linkname=Coming%20in%20glibc%202.33%3A%20Reloadable%20nsswitch.conf" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F15%2Fcoming-in-glibc-2-33-reloadable-nsswitch-conf%2F&amp;#38;linkname=Coming%20in%20glibc%202.33%3A%20Reloadable%20nsswitch.conf" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F15%2Fcoming-in-glibc-2-33-reloadable-nsswitch-conf%2F&amp;#38;linkname=Coming%20in%20glibc%202.33%3A%20Reloadable%20nsswitch.conf" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F15%2Fcoming-in-glibc-2-33-reloadable-nsswitch-conf%2F&amp;#38;linkname=Coming%20in%20glibc%202.33%3A%20Reloadable%20nsswitch.conf" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F15%2Fcoming-in-glibc-2-33-reloadable-nsswitch-conf%2F&amp;#38;linkname=Coming%20in%20glibc%202.33%3A%20Reloadable%20nsswitch.conf" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F15%2Fcoming-in-glibc-2-33-reloadable-nsswitch-conf%2F&amp;#038;title=Coming%20in%20glibc%202.33%3A%20Reloadable%20nsswitch.conf" data-a2a-url="https://developers.redhat.com/blog/2021/01/15/coming-in-glibc-2-33-reloadable-nsswitch-conf/" data-a2a-title="Coming in glibc 2.33: Reloadable nsswitch.conf"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/15/coming-in-glibc-2-33-reloadable-nsswitch-conf/"&gt;Coming in glibc 2.33: Reloadable nsswitch.conf&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/icXSyt_kNkE" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;In my previous article about nsswitch.conf I talked about how simple, perhaps too simple, this config file is to use. What I didn&amp;#8217;t cover then was how simplistic its internal implementation is. Specifically, an application only loads this file once—the first time it&amp;#8217;s needed. So, what do you do when nsswitch.conf needs to change? How [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/15/coming-in-glibc-2-33-reloadable-nsswitch-conf/"&gt;Coming in glibc 2.33: Reloadable nsswitch.conf&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/01/15/coming-in-glibc-2-33-reloadable-nsswitch-conf/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">835617</post-id><dc:creator>DJ Delorie</dc:creator><dc:date>2021-01-15T08:00:59Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/01/15/coming-in-glibc-2-33-reloadable-nsswitch-conf/</feedburner:origLink></entry><entry><title>10 reasons to develop Quarkus applications on Red Hat OpenShift</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/MsGdXON1s4c/" /><category term="Java" /><category term="Knative" /><category term="Kubernetes" /><category term="Quarkus" /><category term="Serverless" /><category term="MicroProfile" /><category term="openshift" /><category term="OpenTracing" /><category term="Spring framework" /><author><name>jebeck</name></author><id>https://developers.redhat.com/blog/?p=851277</id><updated>2021-01-15T08:00:20Z</updated><published>2021-01-15T08:00:20Z</published><content type="html">&lt;p&gt;Combining &lt;a href="https://developers.redhat.com/products/quarkus/getting-started"&gt;Quarkus&lt;/a&gt; with &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt; provides an ideal environment for creating scalable, fast, and lightweight applications. Quarkus significantly increases developer productivity with tooling, pre-built integrations, application services, and more. This article presents 10 reasons why you should develop your Quarkus applications on OpenShift.&lt;/p&gt; &lt;h2&gt;Reason 1: One-step OpenShift deployment&lt;/h2&gt; &lt;p&gt;You don’t have to be an OpenShift expert to deploy Quarkus applications. The Quarkus OpenShift extension automatically generates OpenShift resources, making it easy to get started. The extension provides multiple deployment options, including &lt;a target="_blank" rel="nofollow" href="https://github.com/GoogleContainerTools/jib"&gt;Jib&lt;/a&gt;, &lt;a target="_blank" rel="nofollow" href="https://quarkus.io/guides/container-image#docker"&gt;Docker&lt;/a&gt;, and Source-to-Image (&lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/enterprise/3.0/creating_images/s2i.html#:~:text=Source%2Dto%2DImage%20(S2I,ease%20of%20use%20for%20developers."&gt;S2i&lt;/a&gt;). It also creates a &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.6/applications/deployments/what-deployments-are.html"&gt;DeploymentConfig&lt;/a&gt;, which triggers an automatic redeployment whenever a change is detected in the &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.6/rest_api/image_apis/imagestream-image-openshift-io-v1.html"&gt;ImageStream&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Here is a simple example of a Quarkus deployment on OpenShift:&lt;/p&gt; &lt;pre&gt;//deploy JVM-based app on OpenShift //add OpenShift extension mvn quarkus:add-extension -Dextensions="openshift" //application.properties quarkus.s2i.base-jvm-image= quarkus.openshift.expose=true mvn clean package -Dquarkus.kubernetes.deploy=true &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Learn more&lt;/b&gt;: &lt;a target="_blank" rel="nofollow" href="https://quarkus.io/guides/deploying-to-openshift"&gt;Deploying Quarkus on OpenShift&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Reason 2: One-step serverless function deployment&lt;/h2&gt; &lt;p&gt;Quarkus applications, especially those compiled to native code, are ideal for serverless applications due to their small size and fast boot times. The Quarkus OpenShift extension also makes it easy to deploy and scale &lt;a target="_blank" rel="nofollow" href="https://www.openshift.com/learn/topics/serverless"&gt;Knative serverless services&lt;/a&gt;. As a developer, you don’t need to worry about server provisioning or maintaining the underlying infrastructure. You simply write your code and package it in a container for deployment.&lt;/p&gt; &lt;p&gt;Here is an example of a serverless function deployment:&lt;/p&gt; &lt;pre&gt;//deploy serverless knative app on OpenShift //add OpenShift extension mvn quarkus:add-extension -Dextensions="openshift" //application.propertiesquarkus.s2i.base-jvm-image= quarkus.kubernetes.deployment-target=knative mvn clean package -Dquarkus.kubernetes.deploy=true &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Learn more&lt;/b&gt;: &lt;a target="_blank" rel="nofollow" href="https://quarkus.io/guides/deploying-to-openshift#knative-openshift-serverless"&gt;Using Knative via OpenShift Serverless&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Reason 3: Live coding&lt;/h2&gt; &lt;p&gt;The traditional Java development workflow is a major drain on productivity. It can take minutes to complete each iteration in a cycle. The Quarkus live coding feature solves this problem. Figure 1 illustrates an example workflow when running in development mode.&lt;/p&gt; &lt;div id="attachment_852997" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/screenshot-docs.google.com-2021.01.08-14_18_48.png"&gt;&lt;img aria-describedby="caption-attachment-852997" class="wp-image-852997" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/screenshot-docs.google.com-2021.01.08-14_18_48.png" alt="write code + compile + deploy + refresh browser + repeat" width="640" height="84" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/screenshot-docs.google.com-2021.01.08-14_18_48.png 932w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/screenshot-docs.google.com-2021.01.08-14_18_48-300x39.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/screenshot-docs.google.com-2021.01.08-14_18_48-768x101.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-852997" class="wp-caption-text"&gt;Figure 1: The write and refresh development cycle in Quarkus.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Here&amp;#8217;s the command to run Quarkus in development mode:&lt;/p&gt; &lt;pre&gt;mvn compile quarkus:dev &lt;/pre&gt; &lt;p&gt;Given this command, Quarkus checks to see if any application source files have changed. If they have, Quarkus transparently compiles the changed files and redeploys the application.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Learn more&lt;/b&gt;: &lt;a target="_blank" rel="nofollow" href="https://quarkus.io/vision/developer-joy#live-coding"&gt;Live coding with Quarkus&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Reason 4: Remote development and debugging&lt;/h2&gt; &lt;p&gt;You can also do live coding remotely, in development mode, in a clustered OpenShift or Kubernetes environment. Any changes you make locally will be immediately visible in the clustered environment. Remote development and debugging lets you create applications in the same environment where your applications will run. The key is building a mutable application:&lt;/p&gt; &lt;pre&gt;//application.properties quarkus.package.type=mutable-jar quarkus.live-reload.password=abc123 quarkus.kubernetes.env.vars.QUARKUS_LAUNCH_DEVMODE=true //Deploy mvn clean install -Dquarkus.kubernetes.deploy=true //Start mvnw quarkus:remote-dev -Dquarkus.live-reload.url= &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Learn more&lt;/b&gt;: &lt;a target="_blank" rel="nofollow" href="https://quarkus.io/guides/maven-tooling#remote-development-mode"&gt;Building Quarkus applications in remote development mode&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Reason 5: Access to OpenShift ConfigMaps and secrets&lt;/h2&gt; &lt;p&gt;Quarkus includes a &lt;code&gt;kubernetes-config&lt;/code&gt; extension that lets you use Kubernetes &lt;code&gt;ConfigMap&lt;/code&gt;s and secrets as a configuration source. You never even have to mount them into the pod running your Quarkus application. Instead, your Quarkus application reads &lt;code&gt;ConfigMap&lt;/code&gt;s and secrets directly from the Kubernetes API server using the Kubernetes client:&lt;/p&gt; &lt;pre&gt;//application.properties quarkus.kubernetes-config.enabled=true quarkus.kubernetes-config.secrets.enabled=true quarkus.kubernetes-config.config-maps= mvn clean package -Dquarkus.kubernetes.deploy=true &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Learn more&lt;/b&gt;: &lt;a target="_blank" rel="nofollow" href="https://quarkus.io/guides/kubernetes-config"&gt;The Quarkus kubernetes-config extension&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Reason 6: Health endpoints&lt;/h2&gt; &lt;p&gt;Quarkus uses the &lt;a target="_blank" rel="nofollow" href="https://download.eclipse.org/microprofile/microprofile-health-2.1/microprofile-health-spec.html"&gt;MicroProfile Health specification&lt;/a&gt; (via the SmallRye extension) to provide information about the application state, such as availability and status. This information is useful in cloud environments where automated processes must frequently determine whether to discard or restart an application. Most Quarkus client extensions have built-in health status enabled by default:&lt;/p&gt; &lt;pre&gt;//add Kubernetes-config extension mvn quarkus:add-extension -Dextensions="smallrye-health" //validate health extension mvnw compile quarkus:dev curl http://localhost:8080/health/live //org.acme.microprofile.health.SimpleHealthCheck class package org.acme.microprofile.health; import org.eclipse.microprofile.health.HealthCheck; import org.eclipse.microprofile.health.HealthCheckResponse; import org.eclipse.microprofile.health.Liveness; import javax.enterprise.context.ApplicationScoped; @Liveness @ApplicationScoped public class SimpleHealthCheck implements HealthCheck { @Override public HealthCheckResponse call() { return HealthCheckResponse.up("Simple health check"); } } &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Learn more&lt;/b&gt;: &lt;a target="_blank" rel="nofollow" href="https://quarkus.io/guides/microprofile-health"&gt;Using the MicroProfile Health specification in Quarkus&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Reason 7: Application metrics support&lt;/h2&gt; &lt;p&gt;Quarkus uses the Micrometer extension to support capturing runtime and application metrics. These metrics provide insight into what is happening inside the application. You can also format Micrometer extension metrics for processing with tools like &lt;a target="_blank" rel="nofollow" href="https://prometheus.io/"&gt;Prometheus&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://grafana.com/"&gt;Grafana&lt;/a&gt;, which support analysis and visualization:&lt;/p&gt; &lt;pre&gt;//add Kubernetes-config extension mvn quarkus:add-extension -Dextensions="micrometer" //validate health extension mvnw compile quarkus:dev //Code snippet to discover, count, store, and record prime numbers @Path("/") public class PrimeNumberResource { private final LongAccumulator highestPrime = new LongAccumulator(Long::max, 0); private final MeterRegistry registry; PrimeNumberResource(MeterRegistry registry) { this.registry = registry; // Create a gauge to obtain the highest observed prime number registry.gauge("prime.number.max", this,PrimeNumberResource::highestObservedPrimeNumber);} // Return the highest observed prime value long highestObservedPrimeNumber() { return highestPrime.get();} } &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Learn more&lt;/b&gt;: &lt;a target="_blank" rel="nofollow" href="https://quarkus.io/guides/micrometer#support-for-the-microprofile-metrics-api"&gt;The MicroProfile Metrics API in Quarkus&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Reason 8: Tracing support&lt;/h2&gt; &lt;p&gt;Quarkus uses the &lt;a target="_blank" rel="nofollow" href="https://download.eclipse.org/microprofile/microprofile-3.3/microprofile-spec-3.3.html#mp-opentracing"&gt;MicroProfile OpenTracing&lt;/a&gt; specification (via the SmallRye extension) to provide distributed tracing across services for interactive web applications. The SmallRye extension includes the default &lt;a target="_blank" rel="nofollow" href="https://www.jaegertracing.io/"&gt;Jaeger&lt;/a&gt; tracer to monitor and troubleshoot transactions in a distributed system:&lt;/p&gt; &lt;pre&gt;//add Kubernetes-config extension mvn quarkus:add-extension -Dextensions="smallrye-opentracing" //validate health extension mvnw compile quarkus:dev //REST endpoints are automatically traced. Here's how to trace additional methods import javax.enterprise.context.ApplicationScoped; import org.eclipse.microprofile.opentracing.Traced; @Traced @ApplicationScoped public class FrancophoneService { public String bonjour() { return "bonjour";} } &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Learn more&lt;/b&gt;: &lt;a target="_blank" rel="nofollow" href="https://quarkus.io/guides/opentracing"&gt;Using OpenTracing in Quarkus applications&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Reason 9: Developer tooling&lt;/h2&gt; &lt;p&gt;You might come for the performance, but you&amp;#8217;ll stay for the developer productivity. Developer tooling makes it even easier to develop and deploy Quarkus applications on OpenShift. Here are a few examples:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;b&gt;IDE support&lt;/b&gt;: Quarkus utilizes the &lt;a target="_blank" rel="nofollow" href="https://github.com/redhat-developer/quarkus-ls"&gt;Quarkus Language Server&lt;/a&gt; to support your favorite IDE, including &lt;a href="https://developers.redhat.com/blog/category/vs-code/"&gt;VSCode&lt;/a&gt;, Eclipse, IntelliJ, and &lt;a target="_blank" rel="nofollow" href="https://quarkus.io/blog/march-of-ides/"&gt;more&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;&lt;b&gt;Build tools&lt;/b&gt;: Quarkus also supports &lt;a target="_blank" rel="nofollow" href="https://quarkus.io/guides/maven-tooling"&gt;Maven&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://quarkus.io/guides/gradle-tooling"&gt;Gradle&lt;/a&gt; build tools.&lt;/li&gt; &lt;li&gt;&lt;b&gt;Codestarts&lt;/b&gt;: Extension &lt;a target="_blank" rel="nofollow" href="https://quarkus.io/blog/extension-codestarts-a-new-way-to-learn-and-discover-quarkus/"&gt;codestarts&lt;/a&gt; include code examples and documentation to make it easier for developers new to Quarkus to create applications.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Reason 10: Compatibility with Spring APIs&lt;/h2&gt; &lt;p&gt;Spring is a dominant Java framework for developers, but Spring applications were not designed for cloud-native environments like OpenShift. Quarkus, on the other hand, was created and optimized for the cloud. As a result, Quarkus can &lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/en/resources/mi-quarkus-lab-validation-idc-analyst-paper"&gt;reduce cloud-resource efficiency by up to 64%&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;If you need cloud-native efficiency but prefer to stick with the framework you know, Quarkus provides a Spring-compatibility layer. This means you can create applications using the Spring APIs you are familiar with, including data, web, config, security, dependency injection, and more. Here&amp;#8217;s an example of Spring web development in Quarkus:&lt;/p&gt; &lt;pre&gt;//Spring Web example import java.util.List; import org.springframework.web.bind.annotation.*; @RestController @RequestMapping("/person") public class PersonController { @GetMapping(path = "/greet/{id}", produces = "text/plain") public String greetPerson(@PathVariable(name = "id") long id) { String name=""; return name; } @GetMapping(produces = "application/json") public Iterable findAll() { return personRepository.findAll(); } &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Learn more&lt;/b&gt;: &lt;a target="_blank" rel="nofollow" href="https://quarkus.io/blog/quarkus-for-spring-developers/"&gt;Quarkus for Spring developers&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Get started with Quarkus&lt;/h2&gt; &lt;p&gt;I hope the availability of developer tooling, pre-built integrations, and application services inspires you to develop your first Quarkus application on OpenShift. These additional resources will help you get started:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;b&gt;Interactive tutorials&lt;/b&gt;: The Quarkus homepage includes numerous &lt;a target="_blank" rel="nofollow" href="https://learn.openshift.com/developing-with-quarkus/"&gt;interactive tutorials&lt;/a&gt; that walk you through building Quarkus applications in a pre-configured OpenShift environment.&lt;/li&gt; &lt;li&gt;&lt;b&gt;Generate a Quarkus project&lt;/b&gt;: Quarkus project initializers make it easy to select extensions and generate sample applications for both the &lt;a target="_blank" rel="nofollow" href="http://code.quarkus.io"&gt;community&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://code.quarkus.redhat.com/"&gt;Red Hat&lt;/a&gt; builds of Quarkus.&lt;/li&gt; &lt;li&gt;&lt;b&gt;OpenShift access&lt;/b&gt;: Red Hat provides several options for accessing an OpenShift environment, including the &lt;a href="https://developers.redhat.com/developer-sandbox"&gt;developer sandbox&lt;/a&gt; shown in Figure 2. &lt;div id="attachment_853397" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/screenshot-console-openshift-console.apps_.sandbox.x8i5.p1.openshiftapps.com-2021.01.08-16_41_51.png"&gt;&lt;img aria-describedby="caption-attachment-853397" class="wp-image-853397 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/screenshot-console-openshift-console.apps_.sandbox.x8i5.p1.openshiftapps.com-2021.01.08-16_41_51-1024x574.png" alt="The sandbox include quick starts, samples, and a variety of deployment options." width="640" height="359" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/screenshot-console-openshift-console.apps_.sandbox.x8i5.p1.openshiftapps.com-2021.01.08-16_41_51-1024x574.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/screenshot-console-openshift-console.apps_.sandbox.x8i5.p1.openshiftapps.com-2021.01.08-16_41_51-300x168.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/screenshot-console-openshift-console.apps_.sandbox.x8i5.p1.openshiftapps.com-2021.01.08-16_41_51-768x431.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/screenshot-console-openshift-console.apps_.sandbox.x8i5.p1.openshiftapps.com-2021.01.08-16_41_51.png 1566w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-853397" class="wp-caption-text"&gt;Figure 2: The OpenShift developer sandbox.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://www.openshift.com/try?extIdCarryOver=true&amp;#38;sc_cid=701f2000001OH74AAG"&gt;Learn more about the possibilities&lt;/a&gt; of using a Red Hat OpenShift 4 cluster on your computer, in your datacenter, and more.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F15%2F10-reasons-to-develop-quarkus-applications-on-red-hat-openshift%2F&amp;#38;linkname=10%20reasons%20to%20develop%20Quarkus%20applications%20on%20Red%20Hat%20OpenShift" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F15%2F10-reasons-to-develop-quarkus-applications-on-red-hat-openshift%2F&amp;#38;linkname=10%20reasons%20to%20develop%20Quarkus%20applications%20on%20Red%20Hat%20OpenShift" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F15%2F10-reasons-to-develop-quarkus-applications-on-red-hat-openshift%2F&amp;#38;linkname=10%20reasons%20to%20develop%20Quarkus%20applications%20on%20Red%20Hat%20OpenShift" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F15%2F10-reasons-to-develop-quarkus-applications-on-red-hat-openshift%2F&amp;#38;linkname=10%20reasons%20to%20develop%20Quarkus%20applications%20on%20Red%20Hat%20OpenShift" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F15%2F10-reasons-to-develop-quarkus-applications-on-red-hat-openshift%2F&amp;#38;linkname=10%20reasons%20to%20develop%20Quarkus%20applications%20on%20Red%20Hat%20OpenShift" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F15%2F10-reasons-to-develop-quarkus-applications-on-red-hat-openshift%2F&amp;#38;linkname=10%20reasons%20to%20develop%20Quarkus%20applications%20on%20Red%20Hat%20OpenShift" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F15%2F10-reasons-to-develop-quarkus-applications-on-red-hat-openshift%2F&amp;#38;linkname=10%20reasons%20to%20develop%20Quarkus%20applications%20on%20Red%20Hat%20OpenShift" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F15%2F10-reasons-to-develop-quarkus-applications-on-red-hat-openshift%2F&amp;#038;title=10%20reasons%20to%20develop%20Quarkus%20applications%20on%20Red%20Hat%20OpenShift" data-a2a-url="https://developers.redhat.com/blog/2021/01/15/10-reasons-to-develop-quarkus-applications-on-red-hat-openshift/" data-a2a-title="10 reasons to develop Quarkus applications on Red Hat OpenShift"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/15/10-reasons-to-develop-quarkus-applications-on-red-hat-openshift/"&gt;10 reasons to develop Quarkus applications on Red Hat OpenShift&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/MsGdXON1s4c" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Combining Quarkus with Red Hat OpenShift provides an ideal environment for creating scalable, fast, and lightweight applications. Quarkus significantly increases developer productivity with tooling, pre-built integrations, application services, and more. This article presents 10 reasons why you should develop your Quarkus applications on OpenShift. Reason 1: One-step OpenShift deployment You don’t have to be an [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/15/10-reasons-to-develop-quarkus-applications-on-red-hat-openshift/"&gt;10 reasons to develop Quarkus applications on Red Hat OpenShift&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/01/15/10-reasons-to-develop-quarkus-applications-on-red-hat-openshift/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">851277</post-id><dc:creator>jebeck</dc:creator><dc:date>2021-01-15T08:00:20Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/01/15/10-reasons-to-develop-quarkus-applications-on-red-hat-openshift/</feedburner:origLink></entry><entry><title type="html">RESTEasy 4.6.0.Final is now available</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Q3GjepZlze4/" /><author><name /></author><id>https://resteasy.github.io/2021/01/14/resteasy-4.6.0.Final/</id><updated>2021-01-14T19:49:00Z</updated><dc:creator /><summary type="html">&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Q3GjepZlze4" height="1" width="1" alt=""/&gt;</summary><feedburner:origLink>https://resteasy.github.io/2021/01/14/resteasy-4.6.0.Final/</feedburner:origLink></entry><entry><title>Knowledge meets machine learning for smarter decisions, Part 1</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/bmbDwQ0PJ4c/" /><category term="Big Data" /><category term="Machine Learning" /><category term="Python" /><category term="AI/ML" /><category term="business process automation" /><category term="Drools" /><category term="knowledge engineering" /><category term="machine learning model" /><category term="PMML" /><author><name>Donato Marrazzo</name></author><id>https://developers.redhat.com/blog/?p=815627</id><updated>2021-01-14T08:00:15Z</updated><published>2021-01-14T08:00:15Z</published><content type="html">&lt;p&gt;Drools is a popular open source project known for its powerful rules engine. Few users realize that it can also be a gateway to the amazing possibilities of &lt;a href="https://developers.redhat.com/topics/ai-ml"&gt;artificial intelligence&lt;/a&gt;. This two-part article introduces you to using &lt;a href="https://developers.redhat.com/products/red-hat-decision-manager/overview"&gt;Red Hat Decision Manager&lt;/a&gt; and its Drools-based rules engine to combine &lt;a href="https://developers.redhat.com/blog/category/machine-learning/"&gt;machine learning&lt;/a&gt; predictions with deterministic reasoning. In Part 1, we&amp;#8217;ll prepare our machine learning logic. In Part 2, you&amp;#8217;ll learn how to use the machine learning model from a knowledge service.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: Examples in this article are based on Red Hat Decision Manager, but all of the technologies used are open source.&lt;/p&gt; &lt;h2&gt;Machine learning meets knowledge engineering&lt;/h2&gt; &lt;p&gt;Few Red Hat Decision Manager users know about its roots in artificial intelligence (AI), specifically the AI branch of knowledge engineering (also known as knowledge representation and reasoning). This branch aims to solve the problem of how to organize human knowledge so that a computer can treat it. Knowledge engineering uses &lt;i&gt;business rules&lt;/i&gt;, which means a set of knowledge metaphors that subject matter experts can easily understand and use.&lt;/p&gt; &lt;p&gt;The &lt;a target="_blank" rel="nofollow" href="https://www.omg.org/dmn/"&gt;Decision Model and Notation&lt;/a&gt; (DMN) standard recently released a new model and notation for subject matter experts. After years of using different methodologies and tools, we finally have a common language for sharing knowledge representation. A hidden treasure of the DMN is that it makes dealing with machine learning algorithms easier. The connecting link is another well-known standard in data science: The &lt;a target="_blank" rel="nofollow" href="http://dmg.org/pmml/v4-1/GeneralStructure.html"&gt;Predictive Model Markup Language&lt;/a&gt;, or PMML.&lt;/p&gt; &lt;p&gt;Using these tools to connect knowledge engineering and machine learning empowers both domains, so that the whole is greater than the sum of its parts. It opens up a wide range of use cases where combining deterministic knowledge and data science predictions leads to smarter decisions.&lt;/p&gt; &lt;h2&gt;A use case for cooperation&lt;/h2&gt; &lt;p&gt;The idea of algorithms that can learn from large sets of data and understand patterns that we humans cannot see is fascinating. However, overconfidence in machine learning technology leads us to underestimate the value of human knowledge.&lt;/p&gt; &lt;p&gt;Let’s take an example from our daily experience: We are all used to algorithms that use our internet browsing history to show us ads for products we&amp;#8217;ve already purchased. This happens because it’s quite difficult to train a machine learning algorithm to exclude ads for previously purchased products.&lt;/p&gt; &lt;p&gt;What is a difficult problem for machine learning is very easy for knowledge engineering to solve. On the flip side, encoding all possible relationships between searched words and suggested products is extremely tedious. In this realm, machine learning complements knowledge engineering.&lt;/p&gt; &lt;p&gt;Artificial intelligence has many branches—machine learning, knowledge engineering, search optimization, natural language processing, and more. Why not use more than one technique to achieve more intelligent behavior?&lt;/p&gt; &lt;h2&gt;Artificial intelligence, machine learning, and data science&lt;/h2&gt; &lt;p&gt;Artificial intelligence, machine learning, and data science are often used interchangeably. Actually, they are different but overlapping domains. As I already noted, artificial intelligence has a broader scope than machine learning. Machine learning is just one facet of artificial intelligence. Similarly, some argue that data science is a facet of artificial intelligence. Others say the opposite, that data science includes AI.&lt;/p&gt; &lt;p&gt;In the field, data scientists and AI experts offer different kinds of expertise with some overlap. Data science uses many machine learning algorithms, but not all of them. The Venn diagram in Figure 1 shows the spaces where artificial intelligence, machine learning, and data science overlap.&lt;/p&gt; &lt;div id="attachment_815637" style="width: 582px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa25e53ede08.png"&gt;&lt;img aria-describedby="caption-attachment-815637" class="wp-image-815637 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa25e53ede08.png" alt="Artificial intelligence and data science overlap. Machine learning is a subset of artificial intelligence that overlaps with data science." width="572" height="364" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa25e53ede08.png 572w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa25e53ede08-300x191.png 300w" sizes="(max-width: 572px) 100vw, 572px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-815637" class="wp-caption-text"&gt;Figure 1: The overlaps between artificial intelligence, machine learning, and data science.&lt;/p&gt;&lt;/div&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: See &lt;a target="_blank" rel="nofollow" href="https://www.mygreatlearning.com/blog/difference-data-science-machine-learning-ai/"&gt;Data Science vs. Machine Learning and Artificial Intelligence&lt;/a&gt; for more about each of these technology domains and the spaces where they meet.&lt;/p&gt; &lt;h2&gt;Craft your own machine learning model&lt;/h2&gt; &lt;p&gt;Data scientists are in charge of defining machine learning models after careful preparation. This section will look at some of the techniques data scientists use to select and tune a machine learning algorithm. The goal is to understand the workflow and learn how to craft a model that can cope with prediction problems.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: To learn more about data science methods and processes, see Wikipedia&amp;#8217;s &lt;a target="_blank" rel="nofollow" href="https://en.m.wikipedia.org/wiki/Cross-industry_standard_process_for_data_mining"&gt;Cross-industry standard process for data mining&lt;/a&gt; (CRISP-DM) page.&lt;/p&gt; &lt;h3&gt;Prepare and train a machine learning algorithm&lt;/h3&gt; &lt;p&gt;The first step for preparing and training a machine learning algorithm is to collect, analyze, and clean the data that we will use. Data preparation is an important phase that significantly impacts the quality of the final outcome. Data scientists use mathematics and statistics for this phase.&lt;/p&gt; &lt;p&gt;For simplicity, let’s say we have a reliable data set based on a manager’s historical decisions in an order-fulfillment process. The manager receives the following information: Product type (examples are phone, printer, and so on), price, urgency, and category. There are two categories: &lt;i&gt;Basic&lt;/i&gt;, for when the product is required employee equipment, and &lt;i&gt;optional&lt;/i&gt;, for when the product is not necessary for the role.&lt;/p&gt; &lt;p&gt;The two decision outcomes are &lt;i&gt;approved&lt;/i&gt; or &lt;i&gt;denied&lt;/i&gt;. Automating this decision will free the manager from a repetitive task and speed up the overall order-fulfillment process.&lt;/p&gt; &lt;p&gt;As a first attempt, we could take the data as-is to train the model. Instead, let&amp;#8217;s introduce a bit of contextual knowledge. In our fictitious organization, the purchasing department has a price-reference table where target prices are defined for all product types. We can use this information to improve the quality of the data. Instead of training our algorithm to focus on the product type, we’ll train it to consider the target price. This way, we won&amp;#8217;t need to re-train the model when the reference price list changes.&lt;/p&gt; &lt;h3&gt;Choosing a machine learning algorithm&lt;/h3&gt; &lt;p&gt;We now have a typical classification problem: Given the incoming data, the algorithm must find a class for those data. In other words, it has to label each data item &lt;i&gt;approved&lt;/i&gt; or &lt;i&gt;denied&lt;/i&gt;. Because we have the manager’s collected responses, we can use a supervised learning method. We only need to choose the correct algorithm. The major machine learning algorithms are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Linear Regression&lt;/li&gt; &lt;li&gt;Logistic Regression&lt;/li&gt; &lt;li&gt;K-Nearest Neighbors&lt;/li&gt; &lt;li&gt;Support Vector Machines&lt;/li&gt; &lt;li&gt;Decision Trees and Random Forests&lt;/li&gt; &lt;li&gt;Neural Networks&lt;/li&gt; &lt;/ul&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: For more about each of these algorithms, see&lt;br /&gt; &lt;a target="_blank" rel="nofollow" href="https://www.freecodecamp.org/news/a-no-code-intro-to-the-9-most-important-machine-learning-algorithms-today/"&gt;9 Key Machine Learning Algorithms Explained in Plain English&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Except for linear regression, we could apply any of these algorithms to our classification problem. For this use case, we will use a Logistic Regression model. Fortunately, we don&amp;#8217;t need to understand the algorithm&amp;#8217;s implementation details. We can rely on existing tools for implementation.&lt;/p&gt; &lt;h3&gt;Python and scikit-learn&lt;/h3&gt; &lt;p&gt;We will use Python and the &lt;a target="_blank" rel="nofollow" href="https://scikit-learn.org/"&gt;scikit-learn library&lt;/a&gt; to train our Logistic Regression model. We choose Python because it is concise and easy to understand and learn. It is also the de facto standard for data scientists. Many libraries expressly designed for data science are written in Python.&lt;/p&gt; &lt;h2&gt;The example project&lt;/h2&gt; &lt;p&gt;Before we go further, download the &lt;a target="_blank" rel="nofollow" href="https://github.com/dmarrazzo/rhdm-dmn-pmml-order"&gt;project source code here&lt;/a&gt;. Open the &lt;code&gt;python&lt;/code&gt; folder to find the machine training code (&lt;code&gt;ml-training.py&lt;/code&gt;) and the CSV file we&amp;#8217;ll use to train the algorithm.&lt;/p&gt; &lt;p&gt;Even without experience with Python and machine learning, the code is easy to understand and adapt. The program&amp;#8217;s logical steps are:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Initialize the algorithm to train.&lt;/li&gt; &lt;li&gt;Read the available data from a CSV file.&lt;/li&gt; &lt;li&gt;Randomly split the training and test data sets (40% is used for testing).&lt;/li&gt; &lt;li&gt;Train the model.&lt;/li&gt; &lt;li&gt;Test the model against the testing data set.&lt;/li&gt; &lt;li&gt;Print the test results.&lt;/li&gt; &lt;li&gt;Save the trained model in PMML.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;A nice feature of the &lt;code&gt;scikit-learn&lt;/code&gt; library is that its machine learning algorithms expose nearly all the same APIs. You can switch between the available algorithms by changing one line of code. This means you can easily benchmark different algorithms for accuracy and decide which one best fits your use case. This type of benchmarking is common because it&amp;#8217;s often hard to know in advance which algorithm will perform better for a use case.&lt;/p&gt; &lt;h3&gt;Run the program&lt;/h3&gt; &lt;p&gt;If you run the Python program, you should see results similar to the following, but not exactly the same. The training and test data are randomly selected so that the results will differ each time. The point is to verify that the algorithm works consistently across multiple executions.&lt;/p&gt; &lt;pre&gt;Results for model LogisticRegression Correct: 1522 Incorrect: 78 Accuracy: 95.12% True Positive Rate: 93.35% True Negative Rate: 97.10% &lt;/pre&gt; &lt;p&gt;The results are quite accurate, at 95%. More importantly, the True Negative Rate (measuring specificity) is very high, at 97.1%. In general, there is a tradeoff between the True Negative Rate and True Positive Rate, which measures sensitivity. Intuitively, you can liken the prediction sensitivity to a car alarm: If we increase an alarm&amp;#8217;s sensitivity, it is more likely to go off by mistake and increase the number of false positives. The increase in false positives lowers specificity.&lt;/p&gt; &lt;h3&gt;Tune the algorithm&lt;/h3&gt; &lt;p&gt;In this particular use case, of approving or rejecting a product order, we would reject the order. Manual approval is better than having too many false positives, which would lead to wrongly approved orders. To improve our results, we can adjust the logistic regression to reduce the prediction sensitivity.&lt;/p&gt; &lt;p&gt;Predictive machine learning models are also known as &lt;i&gt;classification&lt;/i&gt; algorithms because they place an input dataset in a specific class. In our case, we have two classes:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&amp;#8220;true&amp;#8221; to approve the order.&lt;/li&gt; &lt;li&gt;&amp;#8220;false&amp;#8221; to refuse it.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;To reduce the likelihood of a false positive, we can tune the &amp;#8220;true&amp;#8221; class weight (note that 1 is the default):&lt;/p&gt; &lt;pre&gt;model = LogisticRegression(class_weight ={    "true" : .6,    "false" : 1 }) &lt;/pre&gt; &lt;h3&gt;Store the model in a PMML file&lt;/h3&gt; &lt;p&gt;Python is handy for analysis, but we might prefer another language or product for running a machine learning model in production. Reasons include better performance and integration with the enterprise ecosystem.&lt;/p&gt; &lt;p&gt;What we need is a way to exchange machine learning model definitions between different software. The PMML format is commonly used for this purpose. The DMN specification includes a direct reference to a PMML model, which makes this option straightforward.&lt;/p&gt; &lt;p&gt;You should make a couple of changes to the PMML file before importing it to the DMN editor. First, you might need to change the Python PMML version tag to 4.3, which is the version supported by Decision Manager 7.7 (the current version as of this writing):&lt;/p&gt; &lt;pre&gt;&amp;#60;PMML version="4.3" xmlns="http://www.dmg.org/PMML-4_3" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"&amp;#62; &lt;/pre&gt; &lt;p&gt;Next, you want to be able to easily identify the predictive model from the DMN modeler. Use the &lt;code&gt;modelName&lt;/code&gt; attribute to name your model:&lt;/p&gt; &lt;pre&gt;&amp;#60;RegressionModel modelName="approvalRegression" functionName="classification" normalizationMethod="logit"&amp;#62; &lt;/pre&gt; &lt;p&gt;The diagram in Figure 2 shows where we are currently with this project.&lt;/p&gt; &lt;div id="attachment_815657" style="width: 447px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa25ef15607b.png"&gt;&lt;img aria-describedby="caption-attachment-815657" class="wp-image-815657 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa25ef15607b.png" alt="The scikit-learn library requires a training set and an algorithm configuration; the outcome is the PMML model." width="437" height="147" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa25ef15607b.png 437w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa25ef15607b-300x101.png 300w" sizes="(max-width: 437px) 100vw, 437px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-815657" class="wp-caption-text"&gt;Figure 2: A usage block diagram for scikit-learn.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;So far, you&amp;#8217;ve seen how to create a machine learning model and store it in a PMML file. In the second half of this article, you will learn more about using PMML to store and transfer machine learning models. You&amp;#8217;ll also discover how to consume a predictive model from a deterministic decision using DMN. Finally, we&amp;#8217;ll review the advantages of creating more cooperation between the deterministic world and the predictive one.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F14%2Fknowledge-meets-machine-learning-for-smarter-decisions-part-1%2F&amp;#38;linkname=Knowledge%20meets%20machine%20learning%20for%20smarter%20decisions%2C%20Part%201" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F14%2Fknowledge-meets-machine-learning-for-smarter-decisions-part-1%2F&amp;#38;linkname=Knowledge%20meets%20machine%20learning%20for%20smarter%20decisions%2C%20Part%201" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F14%2Fknowledge-meets-machine-learning-for-smarter-decisions-part-1%2F&amp;#38;linkname=Knowledge%20meets%20machine%20learning%20for%20smarter%20decisions%2C%20Part%201" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F14%2Fknowledge-meets-machine-learning-for-smarter-decisions-part-1%2F&amp;#38;linkname=Knowledge%20meets%20machine%20learning%20for%20smarter%20decisions%2C%20Part%201" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F14%2Fknowledge-meets-machine-learning-for-smarter-decisions-part-1%2F&amp;#38;linkname=Knowledge%20meets%20machine%20learning%20for%20smarter%20decisions%2C%20Part%201" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F14%2Fknowledge-meets-machine-learning-for-smarter-decisions-part-1%2F&amp;#38;linkname=Knowledge%20meets%20machine%20learning%20for%20smarter%20decisions%2C%20Part%201" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F14%2Fknowledge-meets-machine-learning-for-smarter-decisions-part-1%2F&amp;#38;linkname=Knowledge%20meets%20machine%20learning%20for%20smarter%20decisions%2C%20Part%201" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F14%2Fknowledge-meets-machine-learning-for-smarter-decisions-part-1%2F&amp;#038;title=Knowledge%20meets%20machine%20learning%20for%20smarter%20decisions%2C%20Part%201" data-a2a-url="https://developers.redhat.com/blog/2021/01/14/knowledge-meets-machine-learning-for-smarter-decisions-part-1/" data-a2a-title="Knowledge meets machine learning for smarter decisions, Part 1"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/14/knowledge-meets-machine-learning-for-smarter-decisions-part-1/"&gt;Knowledge meets machine learning for smarter decisions, Part 1&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/bmbDwQ0PJ4c" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Drools is a popular open source project known for its powerful rules engine. Few users realize that it can also be a gateway to the amazing possibilities of artificial intelligence. This two-part article introduces you to using Red Hat Decision Manager and its Drools-based rules engine to combine machine learning predictions with deterministic reasoning. In [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/14/knowledge-meets-machine-learning-for-smarter-decisions-part-1/"&gt;Knowledge meets machine learning for smarter decisions, Part 1&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/01/14/knowledge-meets-machine-learning-for-smarter-decisions-part-1/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">815627</post-id><dc:creator>Donato Marrazzo</dc:creator><dc:date>2021-01-14T08:00:15Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/01/14/knowledge-meets-machine-learning-for-smarter-decisions-part-1/</feedburner:origLink></entry><entry><title type="html">Using case principal transformers in Elytron</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/1V5ylAbtZzE/" /><author><name>Sonia Zaldana Calles</name></author><id>https://wildfly-security.github.io/wildfly-elytron/blog/case-principal-transformer/</id><updated>2021-01-14T00:00:00Z</updated><dc:creator>Sonia Zaldana Calles</dc:creator><summary type="html">&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/1V5ylAbtZzE" height="1" width="1" alt=""/&gt;</summary><feedburner:origLink>https://wildfly-security.github.io/wildfly-elytron/blog/case-principal-transformer/</feedburner:origLink></entry><entry><title>Getting started with Tekton and Pipelines</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Epbp7VHsb-o/" /><category term="CI/CD" /><category term="Kubernetes" /><category term="Microservices" /><category term="Serverless" /><category term="Continuous Integration" /><category term="kubectl" /><category term="minikube" /><category term="openshift" /><category term="Tekton" /><author><name>Cedric Clyburn</name></author><id>https://developers.redhat.com/blog/?p=793097</id><updated>2021-01-13T08:00:28Z</updated><published>2021-01-13T08:00:28Z</published><content type="html">&lt;p&gt;Tekton is a powerful, &lt;a href="https://developers.redhat.com/blog/2020/04/08/why-kubernetes-native-instead-of-cloud-native/"&gt;Kubernetes-native&lt;/a&gt; framework for creating continuous integration and delivery (CI/CD) systems. In this article, we&amp;#8217;ll use real-world examples to show you how to install Tekton, create Tasks, and eventually create our own pipeline.&lt;/p&gt; &lt;h2&gt;What&amp;#8217;s a pipeline?&lt;/h2&gt; &lt;p&gt;Great question! In software development, pipelines are automated processes that drive software through a process of building, testing, and deploying code. Such an efficient process can help minimize human error, as well as maintain consistency in deployment. Since &lt;a href="https://developers.redhat.com/topics/ci-cd"&gt;Tekton&lt;/a&gt; is cloud-native, its pipelines are containerized and don&amp;#8217;t have dependencies on other projects, mitigating potential issues and saving you time.&lt;/p&gt; &lt;div id="attachment_846497" style="width: 634px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-846497" class=" size-full wp-image-846497 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/12/pipeline-concepts.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/12/pipeline-concepts.png" alt="Defining and running a pipeline from pipeline Tasks through PipelineRun TaskRuns, controllers, and pods." width="624" height="195" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/12/pipeline-concepts.png 624w, https://developers.redhat.com/blog/wp-content/uploads/2020/12/pipeline-concepts-300x94.png 300w" sizes="(max-width: 624px) 100vw, 624px" /&gt;&lt;p id="caption-attachment-846497" class="wp-caption-text"&gt;The structure of a pipeline.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;About Tekton&lt;/h2&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/tektoncd/pipeline"&gt;Tekton&lt;/a&gt; is a &lt;a href="https://developers.redhat.com/topics/serverless-architecture"&gt;Knative&lt;/a&gt;-based framework for CI/CD pipelines, but it&amp;#8217;s unique due to its decoupled nature—meaning that one pipeline can be used to deploy to any Kubernetes cluster across multiple hybrid cloud providers. In addition, Tekton stores everything related to a pipeline as &lt;a target="_blank" rel="nofollow" href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/"&gt;custom resources&lt;/a&gt; (CRs) within the cluster, allowing pieces to be used across multiple pipelines.&lt;/p&gt; &lt;h2&gt;Installing Tekton&lt;/h2&gt; &lt;p&gt;For this guide, we&amp;#8217;ll assume you&amp;#8217;re using &lt;a target="_blank" rel="nofollow" href="https://kubernetes.io/docs/tasks/tools/install-minikube/"&gt;Minikube&lt;/a&gt; for your Kubernetes cluster, although we&amp;#8217;ve created a &lt;a href="https://developers.redhat.com/courses/middleware/openshift-pipelines"&gt;Katacoda Tekton scenario&lt;/a&gt; if you don&amp;#8217;t have access to Minikube. Once your cluster is running, install the latest version of Tekton by applying the YAML from the &lt;a href="https://github.com/tektoncd/pipeline/releases"&gt;latest release&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;kubectl apply -f https://storage.googleapis.com/tekton-releases/pipeline/previous/v0.16.3/release.yaml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This command will create a &lt;code&gt;tekton-pipelines&lt;/code&gt; namespace, as well as other resources to finalize your Tekton install. With that namespace in mind, we can easily track the progress of our install using the command below:&lt;/p&gt; &lt;p&gt;&lt;code&gt;kubectl get pods --namespace tekton-pipelines --watch&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Finally, to interact with Tekton through the console, we need to install the Tekton CLI, also known as &lt;code&gt;tkn&lt;/code&gt;. Depending on your operating system, please use the instructions from the &lt;a target="_blank" rel="nofollow" href="https://github.com/tektoncd/cli"&gt;official repository&lt;/a&gt; to install the latest binary executable.&lt;/p&gt; &lt;h2&gt;Optional: Install the tutorial repo&lt;/h2&gt; &lt;p&gt;The &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt; developer advocate team has created a &lt;a target="_blank" rel="nofollow" href="https://github.com/joellord/handson-tekton"&gt;repository&lt;/a&gt; to help you get started and master Tekton concepts. If you&amp;#8217;re interested in seeing more concepts and getting hands-on, feel free to clone our repo to your local directory:&lt;/p&gt; &lt;p&gt;&lt;code&gt;git clone https://github.com/joellord/handson-tekton&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Once you&amp;#8217;ve cloned the tutorial repository, be sure to &lt;code&gt;cd&lt;/code&gt; into the folder with:&lt;/p&gt; &lt;p&gt;&lt;code&gt;cd handson-tekton&lt;/code&gt;&lt;/p&gt; &lt;h2&gt;Creating our first Task&lt;/h2&gt; &lt;p&gt;For our introduction to Tasks, let&amp;#8217;s start off with a simple &amp;#8220;Hello World&amp;#8221; Task. Task resources are essential building block components for creating a Pipeline, and this first Task will allow us to use a &lt;a href="https://developers.redhat.com/blog/category/ubi/"&gt;Red Hat Universal Base Image&lt;/a&gt; and echo a &amp;#8220;Hello World&amp;#8221;. To begin, let&amp;#8217;s open the file &lt;code&gt;01-hello.yaml&lt;/code&gt; in the &lt;code&gt;/demo&lt;/code&gt; folder:&lt;/p&gt; &lt;pre&gt;&lt;span class="pl-ent"&gt;apiVersion&lt;/span&gt;: &lt;span class="pl-s"&gt;tekton.dev/v1beta1&lt;/span&gt; &lt;span class="pl-ent"&gt;kind&lt;/span&gt;: &lt;span class="pl-s"&gt;Task&lt;/span&gt; &lt;span class="pl-ent"&gt;metadata&lt;/span&gt;: &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;hello&lt;/span&gt; &lt;span class="pl-ent"&gt;spec&lt;/span&gt;: &lt;span class="pl-ent"&gt;steps&lt;/span&gt;: - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;say-hello&lt;/span&gt; &lt;span class="pl-ent"&gt;image&lt;/span&gt;: &lt;span class="pl-s"&gt;registry.access.redhat.com/ubi8/ubi&lt;/span&gt; &lt;span class="pl-ent"&gt;command&lt;/span&gt;: - &lt;span class="pl-s"&gt;/bin/bash&lt;/span&gt; &lt;span class="pl-ent"&gt;args&lt;/span&gt;: &lt;span class="pl-s"&gt;['-c', 'echo Hello World']&lt;/span&gt;&lt;/pre&gt; &lt;p&gt;You&amp;#8217;ll notice several details above, from the &lt;code&gt;kind&lt;/code&gt; being a Task, to the &lt;code&gt;step&lt;/code&gt; of &amp;#8220;say-hello&amp;#8221;, and the &lt;code&gt;args&lt;/code&gt; being to simply output an &lt;code&gt;echo&lt;/code&gt; command to the console. Let&amp;#8217;s apply this Task to our cluster, similar to any other Kubernetes object:&lt;/p&gt; &lt;p&gt;&lt;code&gt;kubectl apply -f ./demo/01-hello.yaml&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;tkn task start --showlog hello&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Great work! After running this &lt;code&gt;tkn&lt;/code&gt; command, you&amp;#8217;ll soon see an output from the Task in the console like such:&lt;/p&gt; &lt;pre&gt;TaskRun started: hello-run-6cgf5 Waiting for logs to be available... [say-hello] Hello World&lt;/pre&gt; &lt;h2&gt;Adding parameters to a task&lt;/h2&gt; &lt;p&gt;An important feature of Tasks is the ability to take in and pass parameters. If you&amp;#8217;re looking to build out various Pipelines, parameters, or &lt;code&gt;params&lt;/code&gt;, are instrumental. These properties are constructed of a &lt;code&gt;name&lt;/code&gt; and &lt;code&gt;type&lt;/code&gt;, but can also accept a &lt;code&gt;description&lt;/code&gt; and &lt;code&gt;default&lt;/code&gt; value. To take a better look at how parameters work, let&amp;#8217;s open up the file &lt;code&gt;02-param.yaml&lt;/code&gt; in the &lt;code&gt;/demo&lt;/code&gt; folder:&lt;/p&gt; &lt;pre&gt;&lt;span class="pl-ent"&gt;apiVersion&lt;/span&gt;: &lt;span class="pl-s"&gt;tekton.dev/v1beta1&lt;/span&gt; &lt;span class="pl-ent"&gt;kind&lt;/span&gt;: &lt;span class="pl-s"&gt;Task&lt;/span&gt; &lt;span class="pl-ent"&gt;metadata&lt;/span&gt;: &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;hello&lt;/span&gt; &lt;span class="pl-ent"&gt;spec&lt;/span&gt;: &lt;span class="pl-ent"&gt;params&lt;/span&gt;: - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;person&lt;/span&gt; &lt;span class="pl-ent"&gt;description&lt;/span&gt;: &lt;span class="pl-s"&gt;Name of person to greet&lt;/span&gt; &lt;span class="pl-ent"&gt;default&lt;/span&gt;: &lt;span class="pl-s"&gt;World&lt;/span&gt; &lt;span class="pl-ent"&gt;type&lt;/span&gt;: &lt;span class="pl-s"&gt;string&lt;/span&gt; &lt;span class="pl-ent"&gt;steps&lt;/span&gt;: - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;say-hello&lt;/span&gt; &lt;span class="pl-ent"&gt;image&lt;/span&gt;: &lt;span class="pl-s"&gt;registry.access.redhat.com/ubi8/ubi&lt;/span&gt; &lt;span class="pl-ent"&gt;command&lt;/span&gt;: - &lt;span class="pl-s"&gt;/bin/bash&lt;/span&gt; &lt;span class="pl-ent"&gt;args&lt;/span&gt;: &lt;span class="pl-s"&gt;['-c', 'echo Hello $(params.person)']&lt;/span&gt;&lt;/pre&gt; &lt;p&gt;Building from our &amp;#8220;Hello World&amp;#8221; example, we&amp;#8217;ve added in a &lt;code&gt;person&lt;/code&gt; parameter with generic values. In addition, to access the new param, we can call it using &lt;code&gt;$(params.person)&lt;/code&gt;. In order to run this new Task, we can add it to our cluster and run the Task with the following command:&lt;/p&gt; &lt;p&gt;&lt;code&gt;kubectl apply -f ./demo/02-param.yaml&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;tkn task start --showlog hello&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Looks good! Now, it looks as if the console is asking for us to specify the parameter in the command line, similar to below:&lt;/p&gt; &lt;pre&gt;? Value for param `person` of type `string`? (Default is `World`) Cedric TaskRun started: hello-run-z4gsw Waiting for logs to be available... [say-hello] Hello Cedric&lt;/pre&gt; &lt;h2&gt;Creating a Pipeline&lt;/h2&gt; &lt;p&gt;Now that you understand Tasks and parameters, let&amp;#8217;s dive into creating a Pipeline. For consistency, Tasks are meant for single actions, while a Pipeline is a series of Tasks that can be run either in parallel or sequentially. For this example, we&amp;#8217;ll use the &lt;code&gt;04-tasks.yaml&lt;/code&gt; file in the &lt;code&gt;/demo&lt;/code&gt; folder for our Pipeline:&lt;/p&gt; &lt;pre&gt;&lt;span class="pl-ent"&gt;apiVersion&lt;/span&gt;: &lt;span class="pl-s"&gt;tekton.dev/v1beta1&lt;/span&gt; &lt;span class="pl-ent"&gt;kind&lt;/span&gt;: &lt;span class="pl-s"&gt;Task&lt;/span&gt; &lt;span class="pl-ent"&gt;metadata&lt;/span&gt;: &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;say-something&lt;/span&gt; &lt;span class="pl-ent"&gt;spec&lt;/span&gt;: &lt;span class="pl-ent"&gt;params&lt;/span&gt;: - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;say-what&lt;/span&gt; &lt;span class="pl-ent"&gt;description&lt;/span&gt;: &lt;span class="pl-s"&gt;What should I say&lt;/span&gt; &lt;span class="pl-ent"&gt;default&lt;/span&gt;: &lt;span class="pl-s"&gt;hello&lt;/span&gt; &lt;span class="pl-ent"&gt;type&lt;/span&gt;: &lt;span class="pl-s"&gt;string&lt;/span&gt; - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;pause-duration&lt;/span&gt; &lt;span class="pl-ent"&gt;description&lt;/span&gt;: &lt;span class="pl-s"&gt;How long to wait before saying something&lt;/span&gt; &lt;span class="pl-ent"&gt;default&lt;/span&gt;: &lt;span class="pl-c1"&gt;0&lt;/span&gt; &lt;span class="pl-ent"&gt;type&lt;/span&gt;: &lt;span class="pl-s"&gt;string&lt;/span&gt; &lt;span class="pl-ent"&gt;steps&lt;/span&gt;: - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;say-it&lt;/span&gt; &lt;span class="pl-ent"&gt;image&lt;/span&gt;: &lt;span class="pl-s"&gt;registry.access.redhat.com/ubi8/ubi&lt;/span&gt; &lt;span class="pl-ent"&gt;command&lt;/span&gt;: - &lt;span class="pl-s"&gt;/bin/bash&lt;/span&gt; &lt;span class="pl-ent"&gt;args&lt;/span&gt;: &lt;span class="pl-s"&gt;['-c', 'sleep $(params.pause-duration) &amp;#38;&amp;#38; echo $(params.say-what)']&lt;/span&gt;&lt;/pre&gt; &lt;p&gt;With this generic Task file, which will &lt;code&gt;echo&lt;/code&gt; whatever it receives in its parameters, we can build our first Pipeline. With the &lt;code&gt;05-pipeline.yaml&lt;/code&gt; file in the &lt;code&gt;/demo&lt;/code&gt; folder, we can manipulate the &lt;code&gt;04-tasks.yaml&lt;/code&gt; Task twice, with different outputs:&lt;/p&gt; &lt;pre&gt;apiVersion: tekton.dev/v1beta1 kind: Pipeline metadata: name: say-things spec: tasks: - name: first-task params: - name: pause-duration value: "2" - name: say-what value: "Hello, this is the first task" taskRef: name: say-something - name: second-task params: - name: say-what value: "And this is the second task" taskRef: name: say-something&lt;/pre&gt; &lt;p&gt;We&amp;#8217;re now ready to apply the generic Task and the new Pipeline to our cluster, and officially start the Pipeline. Using &lt;code&gt;tkn pipeline start&lt;/code&gt;, we create a &lt;code&gt;PipelineRun&lt;/code&gt; resource automatically with a random name:&lt;/p&gt; &lt;p&gt;&lt;code&gt;kubectl apply -f ./demo/04-tasks.yaml&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;kubectl apply -f ./demo/05-pipeline.yaml&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;tkn pipeline start say-things --showlog&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Congrats! You&amp;#8217;ll notice the console has to output the logs from the &lt;code&gt;PipelineRun.&lt;/code&gt; However, the order seems to be confused.&lt;/p&gt; &lt;pre&gt;PipelineRun started: say-things-run-ncfsq Waiting for logs to be available... [second-task : say-it] And this is the second task [first-task : say-it] Hello, this is the first task&lt;/pre&gt; &lt;p&gt;You&amp;#8217;ll notice that the first task seems to happen after the second task, and this is due to Tekton naturally running all the tasks simultaneously.&lt;/p&gt; &lt;h2&gt;Run in parallel or sequentially&lt;/h2&gt; &lt;p&gt;For Tasks to run in a specific order, the &lt;code&gt;runAfter&lt;/code&gt; parameter is needed in the task definition of your Pipeline. Let&amp;#8217;s open up the &lt;code&gt;06-pipeline-order.yaml&lt;/code&gt; file in the &lt;code&gt;/demo&lt;/code&gt; folder:&lt;/p&gt; &lt;pre&gt;&lt;span class="pl-ent"&gt;apiVersion&lt;/span&gt;: &lt;span class="pl-s"&gt;tekton.dev/v1beta1&lt;/span&gt; &lt;span class="pl-ent"&gt;kind&lt;/span&gt;: &lt;span class="pl-s"&gt;Pipeline&lt;/span&gt; &lt;span class="pl-ent"&gt;metadata&lt;/span&gt;: &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;say-things-in-order&lt;/span&gt; &lt;span class="pl-ent"&gt;spec&lt;/span&gt;: &lt;span class="pl-ent"&gt;tasks&lt;/span&gt;: - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;first-task&lt;/span&gt; &lt;span class="pl-ent"&gt;params&lt;/span&gt;: - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;pause-duration&lt;/span&gt; &lt;span class="pl-ent"&gt;value&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;2&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;say-what&lt;/span&gt; &lt;span class="pl-ent"&gt;value&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Hello, this is the first task&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-ent"&gt;taskRef&lt;/span&gt;: &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;say-something&lt;/span&gt; - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;second-task&lt;/span&gt; &lt;span class="pl-ent"&gt;params&lt;/span&gt;: - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;say-what&lt;/span&gt; &lt;span class="pl-ent"&gt;value&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Happening after task 1, in parallel with task 3&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;pause-duration&lt;/span&gt; &lt;span class="pl-ent"&gt;value&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;2&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-ent"&gt;taskRef&lt;/span&gt;: &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;say-something&lt;/span&gt; &lt;span class="pl-ent"&gt;runAfter&lt;/span&gt;: - &lt;span class="pl-s"&gt;first-task&lt;/span&gt; - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;third-task&lt;/span&gt; &lt;span class="pl-ent"&gt;params&lt;/span&gt;: - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;say-what&lt;/span&gt; &lt;span class="pl-ent"&gt;value&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Happening after task 1, in parallel with task 2&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;pause-duration&lt;/span&gt; &lt;span class="pl-ent"&gt;value&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;1&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-ent"&gt;taskRef&lt;/span&gt;: &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;say-something&lt;/span&gt; &lt;span class="pl-ent"&gt;runAfter&lt;/span&gt;: - &lt;span class="pl-s"&gt;first-task&lt;/span&gt; - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;fourth-task&lt;/span&gt; &lt;span class="pl-ent"&gt;params&lt;/span&gt;: - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;say-what&lt;/span&gt; &lt;span class="pl-ent"&gt;value&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Happening after task 2 and 3&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-ent"&gt;taskRef&lt;/span&gt;: &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;say-something&lt;/span&gt; &lt;span class="pl-ent"&gt;runAfter&lt;/span&gt;: - &lt;span class="pl-s"&gt;second-task&lt;/span&gt; - &lt;span class="pl-s"&gt;third-task&lt;/span&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;runAfter&lt;/code&gt; parameter is being applied to specific numbered tasks, and after applying this Pipeline to our cluster, we&amp;#8217;ll be able to see logs from each task, but ordered:&lt;/p&gt; &lt;p&gt;&lt;code&gt;kubectl apply -f ./demo/06-pipeline-order.yaml&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;tkn pipeline start say-things-in-order --showlog&lt;/code&gt;&lt;/p&gt; &lt;p&gt;After running &lt;code&gt;tkn&lt;/code&gt;, your CLI output should be similar to this example:&lt;/p&gt; &lt;pre&gt;PipelineRun started: say-things-in-order-run-5dklz Waiting for logs to be available... [first-task : say-it] Hello, this is the first task [second-task : say-it] Happening after task 1, in parallel with task 3 [third-task : say-it] Happening after task 1, in parallel with task 2 [fourth-task : say-it] Happening after task 2 and 3&lt;/pre&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Feel free to &lt;a target="_blank" rel="nofollow" href="https://github.com/joellord/handson-tekton"&gt;continue the demo here&lt;/a&gt;, and try out our &lt;a href="https://developers.redhat.com/courses/middleware/openshift-pipelines"&gt;guided Katacoda scenario here&lt;/a&gt; as well, which offers an interactive environment right in your browser.&lt;/p&gt; &lt;p&gt;For more interactive demonstrations of many of the examples you&amp;#8217;ve seen here, check out our video!&lt;/p&gt; &lt;p&gt;&lt;iframe class='youtube-player' type='text/html' width='640' height='360' src='https://www.youtube.com/embed/pEmyyrjLrBE?version=3&amp;#038;rel=1&amp;#038;fs=1&amp;#038;autohide=2&amp;#038;showsearch=0&amp;#038;showinfo=1&amp;#038;iv_load_policy=1&amp;#038;wmode=transparent' allowfullscreen='true' style='border:0;'&gt;&lt;/iframe&gt;&lt;/p&gt; &lt;h2&gt;Resources&lt;/h2&gt; &lt;p&gt;If you want to keep learning about Tekton, start with these articles on Red Hat Developer:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2020/08/14/introduction-to-cloud-native-ci-cd-with-tekton-kubecon-europe-2020/"&gt;Introduction to cloud-native CI/CD with Tekton&lt;/a&gt; (Jan Kleinert &amp;#38; Joel Lord)&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2020/01/08/the-new-tekton-pipelines-extension-for-visual-studio-code/"&gt;The new Tekton Pipelines extension for Visual Studio Code&lt;/a&gt; (Denis Golovin &amp;#38; Lindsey Tulloch)&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2020/04/30/creating-pipelines-with-openshift-4-4s-new-pipeline-builder-and-tekton-pipelines/"&gt;Creating Pipelines with OpenShift 4.4’s new Pipeline Builder and Tekton Pipelines&lt;/a&gt; (Joel Lord)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F13%2Fgetting-started-with-tekton-and-pipelines%2F&amp;#38;linkname=Getting%20started%20with%20Tekton%20and%20Pipelines" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F13%2Fgetting-started-with-tekton-and-pipelines%2F&amp;#38;linkname=Getting%20started%20with%20Tekton%20and%20Pipelines" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F13%2Fgetting-started-with-tekton-and-pipelines%2F&amp;#38;linkname=Getting%20started%20with%20Tekton%20and%20Pipelines" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F13%2Fgetting-started-with-tekton-and-pipelines%2F&amp;#38;linkname=Getting%20started%20with%20Tekton%20and%20Pipelines" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F13%2Fgetting-started-with-tekton-and-pipelines%2F&amp;#38;linkname=Getting%20started%20with%20Tekton%20and%20Pipelines" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F13%2Fgetting-started-with-tekton-and-pipelines%2F&amp;#38;linkname=Getting%20started%20with%20Tekton%20and%20Pipelines" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F13%2Fgetting-started-with-tekton-and-pipelines%2F&amp;#38;linkname=Getting%20started%20with%20Tekton%20and%20Pipelines" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F13%2Fgetting-started-with-tekton-and-pipelines%2F&amp;#038;title=Getting%20started%20with%20Tekton%20and%20Pipelines" data-a2a-url="https://developers.redhat.com/blog/2021/01/13/getting-started-with-tekton-and-pipelines/" data-a2a-title="Getting started with Tekton and Pipelines"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/13/getting-started-with-tekton-and-pipelines/"&gt;Getting started with Tekton and Pipelines&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Epbp7VHsb-o" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Tekton is a powerful, Kubernetes-native framework for creating continuous integration and delivery (CI/CD) systems. In this article, we&amp;#8217;ll use real-world examples to show you how to install Tekton, create Tasks, and eventually create our own pipeline. What&amp;#8217;s a pipeline? Great question! In software development, pipelines are automated processes that drive software through a process of [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/13/getting-started-with-tekton-and-pipelines/"&gt;Getting started with Tekton and Pipelines&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/01/13/getting-started-with-tekton-and-pipelines/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">2</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">793097</post-id><dc:creator>Cedric Clyburn</dc:creator><dc:date>2021-01-13T08:00:28Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/01/13/getting-started-with-tekton-and-pipelines/</feedburner:origLink></entry><entry><title type="html">WildFly 22 is released!</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/YrzhXaPcNgs/" /><author><name>Brian Stansberry</name></author><id>https://wildfly.org//news/2021/01/13/WildFly22-Final-Released/</id><updated>2021-01-13T00:00:00Z</updated><content type="html">I’m pleased to announce that the WildFly 22 Final zip is now available . Let’s have a look at what’s new. NEW FEATURES LOGGING * In response to a great deal of user demand, WildFly has added . Applications deployed in the server can use the log4j2 API which will delegate to the JBoss Log Manager. PROVISIONING AND MANAGING WILDFLY * It is now possible to use a to into your WildFly installation, instead of having to unzip content manually into your installation and update your config using the CLI. These Keycloak adapters allow you to secure deployments using OpenID Connect. * A new is available. Use it to provision the Distributable Web subsystem configured with a local web container cache. * New and subsystems are available. These provide a foundation for updated versions of the corresponding 'microprofile-health-smallrye' and 'microprofile-metrics-smallrye' subsystems. They also allow users who don’t need the custom deployment-specific health and metrics information provided by Eclipse MicroProfile Health and Metrics to still get general server health and metrics information via the management endpoint without needing to include the MicroProfile Health and Metrics libraries in their server installation. This is discussed further in the Feature Pack Changes section below. * If the --read-only-server-config startup param is used, the server will now run . This allows non-writable storage to be mounted as the configuration directory. * The high-level CLI command command has been enhanced to . MESSAGING * The management API can now be used to thus stopping all the subscribers from receiving new messages from a paused topic. * In order to help mitigate the possibility of split brain problems ActiveMQ Artemis has the ability to ping a configurable list of hosts to check the health of the broker’s network connection. This Artemis feature can now be . SECURITY * WildFly now provides the ability to . This self-signed certificate should only be used for testing purposes. It should never be used in a production environment. * It is now possible to to convert a principal to upper or lower case. Previously, a custom transformer was required to adjust a principal’s username to upper/lower case. Elytron now provides a principal transformer for this use case. WILDFLY PREVIEW As I when we released WildFly 22 Alpha1, along with our traditional Jakarta EE 8 distribution we want to give our users a preview of what will be coming in WildFly as we move on to EE 9 and later. We call this distribution "WildFly Preview". The WildFly 22.0.0.Final release includes an update to WildFly Preview. Even though this is coming from a .Final tag of the WildFly codebase, WildFly Preview should always be regarded as a tech-preview/beta distribution. EE 9 is primarily about implementing the necessary change in the Jakarta EE APIs from the javax.* package namespace to the jakarta.* namespace. This is a big change that is going to take a while to percolate through the EE ecosystem, e.g. for the many projects that compile against the EE APIs to provide versions that use jakarta.*. While this happens we want to continue to deliver new features and fixes to our community, so the primary WildFly distribution will continue to provide the EE 8 APIs. EE 9 VIA BYTECODE TRANSFORMATION AND THE 'WILDFLY-PREVIEW' GALLEON FEATURE PACK The large majority of the libraries included in WildFly Preview that were compiled against EE APIs were based on the javax.* EE 8 APIs. This includes the libraries produced from WildFly’s own code base and by WildFly Core. But the EE APIs libraries available in the WildFly Preview runtime all use the jakarta.* packages. How can this work? The solution we’ve come up with for this is to provide a new 'wildfly-preview' Galleon feature pack, in addition to the standard 'wildfly' feature pack. (Recall that any WildFly server installation, including the ones that are zipped up and made available for download here, is produced by telling Galleon tooling to provision from a feature pack.) The 'wildfly-preview' feature pack differs from the standard 'wildfly' one in a number of ways, with the key ones relevant to EE 9 being: * Where suitable EE 9 spec API jars were available from Eclipse, those were used instead of the EE 8 spec jars used in standard WildFly. * Where suitable 'native' EE 9 implementation libraries (i.e. ones compiled against jakarta.*) were available, those were used. This includes Weld, Hibernate Validator, Mojarra, Yasson, Jakarta EL and Jakarta JSON. * Any libraries that were using EE 8 APIs were detected and instructions were incorporated in the feature pack telling Galleon to do byte code transformation of that library whenever it provisions a server using the feature pack. The last item is the key point. When Galleon provisions a 'wildfly-preview' server by pulling jars down from maven, it knows that some artifacts were compiled against EE 8 javax.* packages. So it bytecode transforms those jars to alter references to EE 8 packages in the class file constant tables to change from javax.* to jakarta.*. The transformation goes beyond simple package renames; a number of other known differences between EE 8 and EE 9 are handled. Thanks to the project for their work on the underlying transformation tool. You can use the Galleon CLI tool to provision a server from the wildfly-preview feature pack yourself: galleon.sh install wildfly-preview:current --dir=my-wildfly-server Note the use of 'wildfly-preview' instead of 'wildfly'. As Galleon provisions the server it will log quite a bit of information about the transformation work it is doing. Please note that the transformation adds a fair bit to the amount of time it takes to provision the server. WILDFLY PREVIEW SUPPORT FOR EE 8 DEPLOYMENTS The APIs that WildFly Preview exposes to deployments are the EE 9 APIs, so all the classes and interfaces are in the jakarta.* packages. But what if you want to run an existing EE 8 application on WildFly Preview? We expect that to be a very important use case in the long run. Eventually the jakarta.* APIs will be what’s provided by the standard WildFly distribution, but many WildFly users will have existing applications that they’ll want to continue to run unchanged. So we wanted to make sure from the very beginning that that works. What we’ve done is we’ve added to the server’s handling of managed deployments the same basic transformation that’s applied to the server artifacts when provisioning. A managed deployment is one where a management client (the CLI, HAL console or the deployment scanner) presents deployment content to the server and the server makes a copy of it in its internal deployment content repository. The content that gets installed into the runtime is that internal copy. A WildFly Preview server, when it reads in deployment content to store in the content repository, will transform any EE 8 content into EE 9. In the long run I feel it’s better for users if they either convert their application source to EE 9 APIs, or use build-time tooling that we and the rest of the Jakarta community will work to provide to do transformation at build time. But some applications just can’t be changed, so the server-side solution we’re using can handle those cases. FEATURE PACK CHANGES The WildFly server is provisioned using five Galleon feature packs. The composition of these feature packs has changed somewhat in WildFly 22. The five feature packs are: * wildfly-core — provides the functionality provided by the project. * wildfly-servlet — depends on wildfly-core and adds the functionality needed for the "Servlet-Only Distribution" you can find for each WildFly release on the . * wildfly-ee — depends on wildfly-servlet and adds the functionality needed for a full EE appserver, plus other long-standing appserver functionality like clustering support. * wildfly — depends on wildfly-ee and adds Eclipse MicroProfile functionality. This is the feature pack used to provision the standard WildFly distribution found on the , and is the feature pack that we expect most users who provision their own server or bootable jar to use. * wildfly-preview — depends on wildfly-core and adds all other functionality needed for the WildFly Preview distribution. In WildFly 22 we corrected a conceptual problem in WildFly 21 and earlier where the 'wildfly-ee' feature pack was including five MicroProfile specifications: Config, Health, Metrics, OpenTracing and Rest Client. We want the support for the faster moving, more-open-to-breaking-changes MicroProfile specs to only come from the top level 'wildfly' feature pack. So in WildFly 22 we moved that functionality out of 'wildfly-ee' and into 'wildfly'. People only using only 'wildfly-ee' to provision will no longer have access to those specifications. We do want 'wildfly-ee' users to be able to continue to use the WildFly management interface to do server health and readiness checks and to get JVM and container metrics in Prometheus format. To support this we have added new and subsystems to wildfly-ee. These subsystems do not provide any sort of API to deployments; e.g. you can’t use them to provide your own health checks or metrics in your application code. If you want that you should use the 'wildfly' feature pack and the MicroProfile Health and Metrics subsystems. The MicroProfile Health and Metrics subsystems now require the presence in the config of the base health and base metrics subsystems. Users migrating from WildFly 21 or earlier should add these new extensions/subsystems to their configuration. We anticipate further evolution in these feature packs in WildFly 23. In particular, it is likely the 'wildfly-ee' feature pack will no longer depend on 'wildfly-servlet' or transitively on 'wildfly-core'. Instead it will directly provide the content currently provided by those feature packs. STANDARDS SUPPORT WildFly 22.0.0 is a Jakarta EE 8 compatible implementation, with both the Full Platform and the Web Profile. Evidence supporting our certification is available and . WildFly 22 is also a compatible implementation of Java EE 8. WildFly 22 is also a compliant implementation of the Eclipse MicroProfile 3.3 platform specification. The WildFly Preview distribution released today is not yet a compatible implementation of Jakarta EE 9 or MicroProfile 3.3. We’re continuing to make good progress toward being able to certify compatibility, but we’re not there yet. The main area where users may hit meaningful issues related to EE compliance is in webservices if deployment descriptors using the EE 9 xml schemas are used. This can be worked around by using EE 8 schemas, which are functionally equivalent. JDK SUPPORT Our recommendation is that you run WildFly on the most recent long-term support JDK release, i.e. on JDK 11 for WildFly 22. While we do do some testing of WildFly on JDK 12 and 13, we do considerably more testing of WildFly itself on the LTS JDKs, and we make no attempt to ensure the projects producing the various libraries we integrate are testing their libraries on anything other than JDK 8 or 11. WildFly 22 also is heavily tested and runs well on Java 8. We plan to continue to support Java 8 at least through WildFly 23, and probably beyond. While we recommend using an LTS JDK release, I do believe WildFly runs well on JDK 13. By run well, I mean the main WildFly testsuite runs with no more than a few failures in areas not expected to be commonly used. We want developers who are trying to evaluate what a newer JVM means for their applications to be able to look to WildFly as a useful development platform. We do see a couple of test failures with JDK 13 when using the deprecated Picketlink subsystem and WS Trust. Work to allow WildFly to run on JDK 14 and 15 is ongoing. We’re continuing our work to digest fully some of the package removals that came in JDK 14, particularly in the security area. The biggest barrier we face is the deprecated legacy security implementation based on Picketbox cannot support JDK 14. We intend to remove support for that security implementation after WildFly 23 and to only provide Elytron-based security. A lot of behind-the-scenes work to make that possible got accomplished during the WildFly 21 cycle. Please note that WildFly runs on Java 11 and later in classpath mode. DOCUMENTATION The WildFly 22 documentation is available at the . The WildFly 22 management API documentation is in the . JIRA RELEASE NOTES The full list of issues resolved is available . Issues resolved in the WildFly Core 14 releases included with WildFly 22 are available . ENJOY! We hope you enjoy WildFly 22. We’d love to hear your feedback at the . But most important, please stay safe and well!&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/YrzhXaPcNgs" height="1" width="1" alt=""/&gt;</content><dc:creator>Brian Stansberry</dc:creator><feedburner:origLink>https://wildfly.org//news/2021/01/13/WildFly22-Final-Released/</feedburner:origLink></entry><entry><title>Develop Eclipse MicroProfile applications on Red Hat JBoss Enterprise Application Platform XP 2.0</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/cmgVgrBpkwY/" /><category term="Containers" /><category term="DevOps" /><category term="Java" /><category term="Microservices" /><category term="codeready" /><category term="CodeReady Studio" /><category term="jboss" /><category term="MicroProfile" /><category term="MicroProfile Config" /><author><name>Emmanuel Hugonnet</name></author><id>https://developers.redhat.com/blog/?p=850617</id><updated>2021-01-12T08:00:45Z</updated><published>2021-01-12T08:00:45Z</published><content type="html">&lt;p&gt;This article shows you how to install &lt;a href="https://developers.redhat.com/products/eap/overview"&gt;Red Hat JBoss Enterprise Application Platform (JBoss EAP)&lt;/a&gt; XP 2.0.0 GA with support for Eclipse MicroProfile. Once you&amp;#8217;ve enabled Eclipse MicroProfile, you will be able to use its quickstart examples to start developing your own MicroProfile applications with &lt;a href="https://developers.redhat.com/products/codeready-studio/overview"&gt;Red Hat CodeReady Studio&lt;/a&gt;. In this demonstration, you&amp;#8217;ll learn two ways to build and run the &lt;a href="https://developers.redhat.com/cheat-sheets/microprofile-config"&gt;MicroProfile Config&lt;/a&gt; quickstart application.&lt;/p&gt; &lt;h2&gt;Installing JBoss EAP XP 2.0.0 GA&lt;/h2&gt; &lt;p&gt;To install JBoss EAP XP 2.0.0 GA:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Download the following software from the &lt;a href="https://developers.redhat.com/products/eap/download"&gt;product download page&lt;/a&gt;: &lt;ul&gt; &lt;li&gt;JBoss EAP XP 2.0.0 GA manager&lt;/li&gt; &lt;li&gt;JBoss EAP 7.3.4 GA patch&lt;/li&gt; &lt;li&gt;JBoss EAP XP 2.0.0 GA patch&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Apply the JBoss EAP 7.3.4 GA patch: &lt;pre&gt;$ patch apply /DOWNLOAD/PATH/jboss-eap-7.3.4-patch.zip &lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Set up the JBoss EAP XP manager: &lt;pre&gt;$ java -jar jboss-eap-xp-2.0.0.GA-manager.jar setup --jboss-home=/INSTALL_PATH/jboss-eap-7.3 &lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Apply the JBoss EAP XP 2.0 patch using the following management command: &lt;pre&gt;$ java -jar jboss-eap-xp-2.0.0.GA-manager.jar patch-apply --jboss-home=/INSTALL_PATH/jboss-eap-7.3 --patch=/DOWNLOAD/PATH/jboss-eap-xp-2.0.0.GA-patch.zip &lt;/pre&gt; &lt;/li&gt; &lt;/ol&gt; &lt;h2&gt;Configuring CodeReady Studio&lt;/h2&gt; &lt;p&gt;To enable Eclipse MicroProfile support on JBoss EAP, we first need to register a runtime server for our newly installed JBoss EAP XP 2.0.0 instance. For this, we will create a new JBoss EAP 7.3 server called Red Hat JBoss EAP 7.3 XP 2.0.&lt;/p&gt; &lt;p&gt;The server will use a new JBoss EAP 7.3 XP 2.0 runtime that points to the runtime that we&amp;#8217;ve just installed. The JBoss EAP 7.3 XP 2.0 runtime uses the &lt;code&gt;standalone-microprofile.xml&lt;/code&gt; configuration file.&lt;/p&gt; &lt;p&gt;Select or enter the following configurations in the &lt;strong&gt;Define a New Server&lt;/strong&gt; dialog, as shown in Figure 1:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Select the server type &lt;b&gt;Red Hat JBoss Enterprise Application Platform 7.3&lt;/b&gt;.&lt;/li&gt; &lt;li&gt;Set the server’s hostname to &lt;b&gt;localhost&lt;/b&gt;.&lt;/li&gt; &lt;li&gt;Enter &lt;b&gt;Red Hat JBoss EAP 7.3 XP 2.0&lt;/b&gt; as the server name.&lt;/li&gt; &lt;li&gt;Click &lt;b&gt;Next&lt;/b&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;div id="attachment_850737" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_1.png"&gt;&lt;img aria-describedby="caption-attachment-850737" class="wp-image-850737 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_1-926x1024.png" alt="Create your new Red Hat JBoss EAP 7.3 XP 2.0 server." width="640" height="708" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_1-926x1024.png 926w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_1-271x300.png 271w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_1-768x849.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_1.png 954w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-850737" class="wp-caption-text"&gt;Figure 1: Define your new server.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The next screen invites you to create a new server adapter. Keep the defaults and select &lt;strong&gt;Create new runtime&lt;/strong&gt; to continue, as shown in Figure 2.&lt;/p&gt; &lt;div id="attachment_850757" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_2.png"&gt;&lt;img aria-describedby="caption-attachment-850757" class="wp-image-850757 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_2-1019x1024.png" alt="Create a new Server Adapter." width="640" height="643" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_2-1019x1024.png 1019w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_2-150x150.png 150w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_2-300x300.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_2-768x772.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_2.png 1050w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-850757" class="wp-caption-text"&gt;Figure 2: Select &amp;#8216;Create new runtime&amp;#8217; to continue.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;In the next dialog, you will configure your new runtime server. Enter the configurations shown in Figure 3:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Set the home directory if you don’t want to use the default setting.&lt;/li&gt; &lt;li&gt;Make sure your execution environment is set to &lt;b&gt;JavaSE-1.8&lt;/b&gt; (but you can use &lt;b&gt;JavaSE-11&lt;/b&gt;).&lt;/li&gt; &lt;li&gt;Change the settings for the server base directory and configuration file if you don’t want the defaults.&lt;/li&gt; &lt;li&gt;Click &lt;b&gt;Finish&lt;/b&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;div id="attachment_850767" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_3.png"&gt;&lt;img aria-describedby="caption-attachment-850767" class="wp-image-850767 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_3-1024x799.png" alt="An overview of the server's settings." width="640" height="499" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_3-1024x799.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_3-300x234.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_3-768x599.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_3.png 1352w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-850767" class="wp-caption-text"&gt;Figure 3: Configure the server runtime.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Before we can run the MicroProfile quickstarts (see Figure 5), we need to set the environment variables on our runtime. Navigate to the Red Hat JBoss EAP 7.3 XP 2.0 Server Overview dialog and click &lt;b&gt;Open launch configuration&lt;/b&gt;. You will see the option to set the environment variables, as shown in Figure 4.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Set &lt;b&gt;JAEGER_REPORTER_LOG_SPANS&lt;/b&gt; to &lt;b&gt;true&lt;/b&gt;.&lt;/li&gt; &lt;li&gt;Set &lt;b&gt;JAEGER_SAMPLER_PARAM&lt;/b&gt; to &lt;b&gt;1&lt;/b&gt;.&lt;/li&gt; &lt;li&gt;Set &lt;b&gt;JAEGER_SAMPLER_TYPE&lt;/b&gt; to &lt;b&gt;const&lt;/b&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;div id="attachment_850777" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_4.png"&gt;&lt;img aria-describedby="caption-attachment-850777" class="wp-image-850777 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_4-1024x1017.png" alt="The newly defined environment variables." width="640" height="636" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_4-1024x1017.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_4-150x150.png 150w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_4-300x298.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_4-768x762.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_4.png 1095w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-850777" class="wp-caption-text"&gt;Figure 4: Configure your runtime’s environment variables.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Running the Eclipse MicroProfile quickstarts&lt;/h2&gt; &lt;p&gt;The Eclipse MicroProfile quickstarts offer the following examples, which you can run and test on your installed server:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Eclipse MicroProfile Config&lt;/li&gt; &lt;li&gt;Eclipse MicroProfile Fault-tolerance&lt;/li&gt; &lt;li&gt;Eclipse MicroProfile Health&lt;/li&gt; &lt;li&gt;Eclipse MicroProfile JWT&lt;/li&gt; &lt;li&gt;Eclipse MicroProfile Metrics&lt;/li&gt; &lt;li&gt;Eclipse MicroProfile OpenAPI&lt;/li&gt; &lt;li&gt;Eclipse MicroProfile OpenTracing&lt;/li&gt; &lt;li&gt;Eclipse MicroProfile REST Client&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;To turn on the quickstarts, open your project explorer, then select and import the &lt;code&gt;quickstart-parent&lt;/code&gt; &lt;code&gt;pom.xml&lt;/code&gt;. You will see the list of quickstarts shown in Figure 5.&lt;/p&gt; &lt;div id="attachment_850797" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-projects_5.png"&gt;&lt;img aria-describedby="caption-attachment-850797" class="wp-image-850797 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-projects_5.png" alt="Project Explorer with quickstart-parent selected." width="640" height="643" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-projects_5.png 640w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-projects_5-150x150.png 150w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-projects_5-300x300.png 300w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-850797" class="wp-caption-text"&gt;Figure 5: Importing the quickstart parent turns on quickstarts.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Running the Eclipse MicroProfile Config quickstart&lt;/h2&gt; &lt;p&gt;There are two ways to run the Eclipse MicroProfile Config application: A bare-metal installation of JBoss EAP XP Server or a bootable JAR application. I&amp;#8217;ll show you how to do both.&lt;/p&gt; &lt;h3&gt;Bare-metal installation&lt;/h3&gt; &lt;p&gt;If you are installing &lt;code&gt;microprofile-config&lt;/code&gt; on bare metal, do the following:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Right-click on the &lt;b&gt;microprofile-config&lt;/b&gt; file.&lt;/li&gt; &lt;li&gt;Select &lt;b&gt;Run As&lt;/b&gt;.&lt;/li&gt; &lt;li&gt;Left-click &lt;b&gt;1 Run on Server&lt;/b&gt;.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;This configuration, shown in Figure 6, starts the server with the &lt;code&gt;microprofile-config&lt;/code&gt; application deployed.&lt;/p&gt; &lt;div id="attachment_851147" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_on_server_6.png"&gt;&lt;img aria-describedby="caption-attachment-851147" class="wp-image-851147" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_on_server_6.png" alt="Selections to run the microprofile-config project on a local server." width="640" height="683" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_on_server_6.png 810w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_on_server_6-281x300.png 281w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_on_server_6-768x820.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-851147" class="wp-caption-text"&gt;Figure 6: A bare-metal installation.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Install the application as a bootable JAR&lt;/h3&gt; &lt;p&gt;Instead of running your application on a bare-metal installation of JBoss EAP XP server, you can now package a JBoss EAP XP server and Eclipse MicroProfile application inside a bootable JAR. You can then run the application on a JBoss EAP XP bare-metal platform.&lt;/p&gt; &lt;p&gt;For demonstration purposes, we&amp;#8217;ve defined a Maven project for &lt;code&gt;microprofile-config&lt;/code&gt;. The project includes the following &lt;code&gt;bootable-jar&lt;/code&gt; profile:&lt;/p&gt; &lt;pre&gt; ---- &amp;#60;profile&amp;#62; &amp;#60;id&amp;#62;bootable-jar&amp;#60;/id&amp;#62; &amp;#60;build&amp;#62; &amp;#60;plugins&amp;#62; &amp;#60;plugin&amp;#62; &amp;#60;groupId&amp;#62;org.wildfly.plugins&amp;#60;/groupId&amp;#62; &amp;#60;artifactId&amp;#62;wildfly-jar-maven-plugin&amp;#60;/artifactId&amp;#62; &amp;#60;configuration&amp;#62; &amp;#60;feature-pack-location&amp;#62;org.jboss.eap:wildfly-galleon-pack:${version.server.bootable-jar}&amp;#60;/feature-pack-location&amp;#62; &amp;#60;layers&amp;#62; &amp;#60;layer&amp;#62;jaxrs-server&amp;#60;/layer&amp;#62; &amp;#60;layer&amp;#62;microprofile-platform&amp;#60;/layer&amp;#62; &amp;#60;/layers&amp;#62; &amp;#60;/configuration&amp;#62; &amp;#60;executions&amp;#62; &amp;#60;execution&amp;#62; &amp;#60;goals&amp;#62; &amp;#60;goal&amp;#62;package&amp;#60;/goal&amp;#62; &amp;#60;/goals&amp;#62; &amp;#60;/execution&amp;#62; &amp;#60;/executions&amp;#62; &amp;#60;/plugin&amp;#62; &amp;#60;/plugins&amp;#62; &amp;#60;/build&amp;#62; &amp;#60;/profile&amp;#62; ---- &lt;/pre&gt; &lt;p&gt;As you can see, we have selected the &lt;code&gt;jaxrs-server&lt;/code&gt; and the &lt;code&gt;microprofile-plateform&lt;/code&gt; layers to construct a slim version of the JBoss EAP XP server, which encapsulates our application. All you need to do is select the correct profile, as shown in Figure 7:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Right-click on the &lt;b&gt;pom.xml&lt;/b&gt;.&lt;/li&gt; &lt;li&gt;Navigate to &lt;b&gt;Maven&lt;/b&gt; and choose &lt;b&gt;Select Maven Profiles&lt;/b&gt;.&lt;/li&gt; &lt;li&gt;Check &lt;b&gt;bootable-jar&lt;/b&gt;.&lt;/li&gt; &lt;/ol&gt; &lt;div id="attachment_851157" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-select_maven_profile_7.png"&gt;&lt;img aria-describedby="caption-attachment-851157" class="wp-image-851157" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-select_maven_profile_7.png" alt="Dialog to select the apache Maven profile to use." width="640" height="735" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-select_maven_profile_7.png 873w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-select_maven_profile_7-261x300.png 261w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-select_maven_profile_7-768x882.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-851157" class="wp-caption-text"&gt;Figure 7: Select the Apache Maven profile.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Next, we need to build the bootable JAR using Apache Maven. Right-click on the &lt;code&gt;pom.xml&lt;/code&gt;. Then, go into the &lt;strong&gt;Run As&lt;/strong&gt; menu, and select &lt;strong&gt;9 Maven install&lt;/strong&gt;. Figure 8 shows these selections.&lt;/p&gt; &lt;div id="attachment_851167" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-build_bootable_jar_8.png"&gt;&lt;img aria-describedby="caption-attachment-851167" class="wp-image-851167" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-build_bootable_jar_8.png" alt="Building the bootable JAR using Apache Maven," width="640" height="717" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-build_bootable_jar_8.png 751w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-build_bootable_jar_8-268x300.png 268w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-851167" class="wp-caption-text"&gt;Figure 8: Build the bootable JAR.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Once the bootable JAR is built, we need to run our application from CodeReady Studio. We will create a new Apache Maven run configuration for this purpose. As shown in Figure 9, right-click on the &lt;code&gt;pom.xml&lt;/code&gt; and navigate to the &lt;strong&gt;Run As&lt;/strong&gt; menu, then select &lt;strong&gt;5 Maven build&lt;/strong&gt;. Set &lt;strong&gt;org.wildfly.plugins:wildfly-jar-maven-plugin:run&lt;/strong&gt; as the goal and rename the execution to &lt;strong&gt;microprofile-config bootable run&lt;/strong&gt;, then click &lt;strong&gt;Run&lt;/strong&gt;.&lt;/p&gt; &lt;div id="attachment_851177" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_bootable_jar_9.png"&gt;&lt;img aria-describedby="caption-attachment-851177" class="wp-image-851177 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_bootable_jar_9-1024x801.png" alt="The dialog to run the bootable JAR using Apache Maven." width="640" height="501" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_bootable_jar_9-1024x801.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_bootable_jar_9-300x235.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_bootable_jar_9-768x601.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_bootable_jar_9.png 1389w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-851177" class="wp-caption-text"&gt;Figure 9: Run the bootable JAR.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;When the server starts, the application will be available as the root context, at &lt;a target="_blank" rel="nofollow" href="http://localhost:8080/config/value"&gt;http://localhost:8080/config/value&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Shutting down the server&lt;/h2&gt; &lt;p&gt;Closing or terminating the terminal will not stop the running server, so we need another run configuration to shut down the server. The easiest approach is to copy the run configuration we&amp;#8217;ve just created, rename it &lt;strong&gt;microprofile-config bootable shutdown&lt;/strong&gt;, and use the goal &lt;strong&gt;org.wildfly.plugins:wildfly-jar-maven-plugin:shutdown&lt;/strong&gt;, as shown in Figure 10.&lt;/p&gt; &lt;div id="attachment_851197" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_bootable_jar_10.png"&gt;&lt;img aria-describedby="caption-attachment-851197" class="wp-image-851197 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_bootable_jar_10-1024x801.png" alt="Create a new run configuration to shut down the server." width="640" height="501" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_bootable_jar_10-1024x801.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_bootable_jar_10-300x235.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_bootable_jar_10-768x601.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_bootable_jar_10.png 1389w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-851197" class="wp-caption-text"&gt;Figure 10: Create a new run configuration to shut down the server.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;This article showed you how to install JBoss Enterprise Application Platform XP 2.0.0 GA with Eclipse MicroProfile support. I then showed you two ways to configure and run a MicroProfile Config quickstart project using Red Hat CodeReady Studio.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F12%2Fdevelop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-xp-2-0%2F&amp;#38;linkname=Develop%20Eclipse%20MicroProfile%20applications%20on%20Red%20Hat%20JBoss%20Enterprise%20Application%20Platform%20XP%202.0" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F12%2Fdevelop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-xp-2-0%2F&amp;#38;linkname=Develop%20Eclipse%20MicroProfile%20applications%20on%20Red%20Hat%20JBoss%20Enterprise%20Application%20Platform%20XP%202.0" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F12%2Fdevelop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-xp-2-0%2F&amp;#38;linkname=Develop%20Eclipse%20MicroProfile%20applications%20on%20Red%20Hat%20JBoss%20Enterprise%20Application%20Platform%20XP%202.0" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F12%2Fdevelop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-xp-2-0%2F&amp;#38;linkname=Develop%20Eclipse%20MicroProfile%20applications%20on%20Red%20Hat%20JBoss%20Enterprise%20Application%20Platform%20XP%202.0" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F12%2Fdevelop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-xp-2-0%2F&amp;#38;linkname=Develop%20Eclipse%20MicroProfile%20applications%20on%20Red%20Hat%20JBoss%20Enterprise%20Application%20Platform%20XP%202.0" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F12%2Fdevelop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-xp-2-0%2F&amp;#38;linkname=Develop%20Eclipse%20MicroProfile%20applications%20on%20Red%20Hat%20JBoss%20Enterprise%20Application%20Platform%20XP%202.0" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F12%2Fdevelop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-xp-2-0%2F&amp;#38;linkname=Develop%20Eclipse%20MicroProfile%20applications%20on%20Red%20Hat%20JBoss%20Enterprise%20Application%20Platform%20XP%202.0" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F12%2Fdevelop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-xp-2-0%2F&amp;#038;title=Develop%20Eclipse%20MicroProfile%20applications%20on%20Red%20Hat%20JBoss%20Enterprise%20Application%20Platform%20XP%202.0" data-a2a-url="https://developers.redhat.com/blog/2021/01/12/develop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-xp-2-0/" data-a2a-title="Develop Eclipse MicroProfile applications on Red Hat JBoss Enterprise Application Platform XP 2.0"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/12/develop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-xp-2-0/"&gt;Develop Eclipse MicroProfile applications on Red Hat JBoss Enterprise Application Platform XP 2.0&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/cmgVgrBpkwY" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;This article shows you how to install Red Hat JBoss Enterprise Application Platform (JBoss EAP) XP 2.0.0 GA with support for Eclipse MicroProfile. Once you&amp;#8217;ve enabled Eclipse MicroProfile, you will be able to use its quickstart examples to start developing your own MicroProfile applications with Red Hat CodeReady Studio. In this demonstration, you&amp;#8217;ll learn two [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/12/develop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-xp-2-0/"&gt;Develop Eclipse MicroProfile applications on Red Hat JBoss Enterprise Application Platform XP 2.0&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/01/12/develop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-xp-2-0/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">850617</post-id><dc:creator>Emmanuel Hugonnet</dc:creator><dc:date>2021-01-12T08:00:45Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/01/12/develop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-xp-2-0/</feedburner:origLink></entry><entry><title type="html">Bored with magic tricks?</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/5Xd-KucGQfc/" /><author><name /></author><id>https://quarkus.io/blog/magic-control/</id><updated>2021-01-12T00:00:00Z</updated><content type="html">Just before my PTO, someone told me: 'I don’t like magic.' In this context, magic refers to the amount of hidden stuff done by Quarkus under the hood for the sake of simplicity. It includes dependency injection, annotations, and so on. It’s not the first time that I get that...&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/5Xd-KucGQfc" height="1" width="1" alt=""/&gt;</content><dc:creator /><feedburner:origLink>https://quarkus.io/blog/magic-control/</feedburner:origLink></entry><entry><title>Getting started with Buildah</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/C-oFmv-GD0U/" /><category term="Containers" /><category term="Kubernetes" /><category term="Linux" /><category term="buildah" /><category term="container image" /><category term="Docker" /><category term="openshift" /><category term="Podman" /><author><name>Cedric Clyburn</name></author><id>https://developers.redhat.com/blog/?p=758807</id><updated>2021-01-11T08:00:01Z</updated><published>2021-01-11T08:00:01Z</published><content type="html">&lt;p&gt;If you&amp;#8217;re looking to build Open Container Initiative (OCI) container images without a full container runtime or daemon installed, &lt;a target="_blank" rel="nofollow" href="https://buildah.io/"&gt;Buildah&lt;/a&gt; is the perfect solution. Now, Buildah is an open source, Linux-based tool that can build Docker- and &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;-compatible images, and is easy to incorporate into scripts and build pipelines. In addition, Buildah has overlap functionality with &lt;a target="_blank" rel="nofollow" href="https://podman.io/"&gt;Podman&lt;/a&gt;, &lt;a target="_blank" rel="nofollow" href="https://github.com/containers/skopeo"&gt;Skopeo&lt;/a&gt;, and &lt;a target="_blank" rel="nofollow" href="https://cri-o.io/"&gt;CRI-O&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Buildah has the ability to create a working &lt;a href="https://developers.redhat.com/topics/containers/"&gt;container&lt;/a&gt; from scratch, but also from a pre-existing Dockerfile. Plus, with it not needing a daemon, you&amp;#8217;ll never have to worry about Docker daemon issues when building container images.&lt;/p&gt; &lt;p&gt;Let&amp;#8217;s cover some real-world examples to show how easy it is to get started with Buildah, and how easy it is to create a container image.&lt;/p&gt; &lt;h2&gt;Installing Buildah&lt;/h2&gt; &lt;p&gt;If you&amp;#8217;re running &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt; (RHEL) 8, follow the steps below. For Fedora users, be sure to replace &lt;code&gt;yum&lt;/code&gt; with &lt;code&gt;dnf&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;$ yum -y install buildah&lt;/pre&gt; &lt;p&gt;However, if you don&amp;#8217;t have Linux available, you can use &lt;a target="_blank" rel="nofollow" href="https://www.katacoda.com/courses/containers-without-docker/building-container-images-with-buildah"&gt;Buildah online with Katacoda&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Basic commands&lt;/h2&gt; &lt;p&gt;To get to know Buildah, let&amp;#8217;s play around with some basic commands. The command &lt;code&gt;buildah --version&lt;/code&gt; will output the current version of our Buildah install, and &lt;code&gt;buildah --help&lt;/code&gt; will help if you get stuck.&lt;/p&gt; &lt;p&gt;For example, in order to pull a container image from a repository, use the &lt;code&gt;from&lt;/code&gt; variable. For example, if your favorite Linux distribution is CentOS:&lt;/p&gt; &lt;pre&gt;$ buildah from centos&lt;/pre&gt; &lt;p&gt;After pulling the image and storing it on the host, list our current images by running &lt;code&gt;buildah images&lt;/code&gt;. This behavior is similar to Podman and Docker, as many commands are cross-compatible. To get a list of our running containers, which are provisioned as soon as the image pull is completed, use &lt;code&gt;buildah containers&lt;/code&gt;. For an example, see Figure 1.&lt;/p&gt; &lt;div id="attachment_763307" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Buildah-containers.png"&gt;&lt;img aria-describedby="caption-attachment-763307" class="wp-image-763307 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Buildah-containers-1024x127.png" alt="The output of the command &amp;#34;buildah containers&amp;#34;, showing CONTAINER ID, BUILDER, IMAGE ID, IMAGE NAME, and CONTAINER #" width="640" height="79" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Buildah-containers-1024x127.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Buildah-containers-300x37.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Buildah-containers-768x95.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-763307" class="wp-caption-text"&gt;Figure 1: Run &amp;#8220;buildah containers&amp;#8221; to see your provisioned containers.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Finally, since we&amp;#8217;ve pulled and displayed a container, let&amp;#8217;s clean up and remove our running containers with &lt;code&gt;buildah rm -all&lt;/code&gt;. Be sure to exercise caution, however, as Buildah has the ability to remove a running container while Docker does not.&lt;/p&gt; &lt;h2&gt;Building a container&lt;/h2&gt; &lt;p&gt;Time to get hands-on with Buildah and build an Apache web server that will run inside a container. To get things started, let&amp;#8217;s pull a CentOS base image and start working:&lt;/p&gt; &lt;pre&gt;$ buildah from centos&lt;/pre&gt; &lt;p&gt;You&amp;#8217;ll see the default image name as output in the console like &lt;code&gt;centos-working-container&lt;/code&gt;, giving us the ability to run commands within the specified container. For our case, we&amp;#8217;ll be installing an &lt;a target="_blank" rel="nofollow" href="https://httpd.apache.org/docs/current/programs/httpd.html"&gt;httpd&lt;/a&gt; package, which can be done using the following command:&lt;/p&gt; &lt;pre&gt;$ buildah run centos-working-container yum install httpd -y&lt;/pre&gt; &lt;p&gt;Once we&amp;#8217;ve installed &lt;code&gt;httpd&lt;/code&gt;, we can take our attention to creating a main page to be directed to on our web server, commonly known as an &lt;code&gt;index.html&lt;/code&gt; file. To create a simple file without having to worry about formatting, use the &lt;code&gt;echo&lt;/code&gt; command below:&lt;/p&gt; &lt;pre&gt;$ echo "Hello from Red Hat" &amp;#62; index.html&lt;/pre&gt; &lt;p&gt;In addition, after creating this new file, let&amp;#8217;s copy it into our current working container with the Buildah &lt;code&gt;copy&lt;/code&gt; function. The default location for publicly accessible files is also included:&lt;/p&gt; &lt;pre&gt;$ buildah copy centos-working-container index.html /var/www/html/index.html&lt;/pre&gt; &lt;p&gt;To start this container, we must configure an entry point for a container, which is used to start &lt;code&gt;httpd&lt;/code&gt; as the container begins and keep it in the foreground:&lt;/p&gt; &lt;pre&gt;$ buildah config --entrypoint "/usr/sbin/httpd -DFOREGROUND" centos-working-container&lt;/pre&gt; &lt;p&gt;Finally, let&amp;#8217;s &lt;code&gt;commit&lt;/code&gt; our changes to the container, and prepare it to be pushed to any container registry you&amp;#8217;d like (ex. &lt;a href="https://developers.redhat.com/blog/2019/02/21/podman-and-buildah-for-docker-users/"&gt;Docker and Quay.io&lt;/a&gt;):&lt;/p&gt; &lt;pre&gt;$ buildah commit centos-working-container redhat-website&lt;/pre&gt; &lt;p&gt;Your &lt;code&gt;redhat-website&lt;/code&gt; image is ready to &lt;a href="https://developers.redhat.com/blog/2019/08/14/best-practices-for-running-buildah-in-a-container/"&gt;run with Podman&lt;/a&gt;, or push to your registry of choice.&lt;/p&gt; &lt;h2&gt;Building with a Dockerfile&lt;/h2&gt; &lt;p&gt;Another significant part of Buildah is the ability to build images using a Dockerfile, and the &lt;code&gt;build-using-dockerfile&lt;/code&gt;, or &lt;code&gt;bud&lt;/code&gt; command can do just that. Let&amp;#8217;s take an example Dockerfile as input, and output an OCI image:&lt;/p&gt; &lt;pre&gt;# &lt;strong&gt;CoreOS Base&lt;/strong&gt; FROM fedora:latest # &lt;strong&gt;Install httpd&lt;/strong&gt; RUN echo "Installing httpd"; yum -y install httpd # &lt;strong&gt;Expose the default httpd port 80&lt;/strong&gt; EXPOSE 80 # &lt;strong&gt;Run httpd&lt;/strong&gt; CMD ["/usr/sbin/httpd", "-DFOREGROUND"]&lt;/pre&gt; &lt;p&gt;Once we save this file as &lt;code&gt;Dockerfile&lt;/code&gt; in our local directory, we can use the &lt;code&gt;bud&lt;/code&gt; command to build the image:&lt;/p&gt; &lt;pre&gt;$ buildah bud -t fedora-httpd&lt;/pre&gt; &lt;p&gt;To double-check our progress, let&amp;#8217;s run &lt;code&gt;buildah images&lt;/code&gt; and ensure we can see our new &lt;code&gt;fedora-httpd&lt;/code&gt; image resting in our localhost repository. Now, feel free to again &lt;a href="https://developers.redhat.com/blog/2019/08/14/best-practices-for-running-buildah-in-a-container/"&gt;run the image with Podman&lt;/a&gt;, or push it to your favorite registry.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Great job! We&amp;#8217;ve gone through building a container from scratch, as well as from a predefined Dockerfile. Buildah is a lightweight and flexible way to create container images without the need for a runtime or daemon installed.&lt;/p&gt; &lt;p&gt;You can continue to experiment with Buildah by setting up &lt;a target="_blank" rel="nofollow" href="https://www.katacoda.com/courses/containers-without-docker/building-container-images-with-buildah"&gt;this Katacoda scenario&lt;/a&gt;, which offers you an interactive environment right in your browser.&lt;/p&gt; &lt;p&gt;If you need container orchestration, you can use Buildah with &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; or &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt;. To get started with these platforms, see &lt;a target="_blank" rel="nofollow" href="https://kubernetesbyexample.com/"&gt;kubernetesbyexample.com&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://learn.openshift.com/"&gt;learn.openshift.com.&lt;/a&gt;&lt;/p&gt; &lt;p&gt;For interactive demonstrations of many of the examples you&amp;#8217;ve seen here, watch this video:&lt;/p&gt; &lt;p&gt;&lt;iframe class='youtube-player' type='text/html' width='640' height='360' src='https://www.youtube.com/embed/SNDjOfs2zCM?version=3&amp;#038;rel=1&amp;#038;fs=1&amp;#038;autohide=2&amp;#038;showsearch=0&amp;#038;showinfo=1&amp;#038;iv_load_policy=1&amp;#038;wmode=transparent' allowfullscreen='true' style='border:0;'&gt;&lt;/iframe&gt;&lt;/p&gt; &lt;h2&gt;Resources&lt;/h2&gt; &lt;p&gt;Learn more about Buildah:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2019/02/21/podman-and-buildah-for-docker-users/"&gt;Podman and Buildah for Docker users&lt;/a&gt; (William Henry)&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2019/08/14/best-practices-for-running-buildah-in-a-container/"&gt;Best practices for running Buildah in a container&lt;/a&gt; (Daniel Walsh)&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2019/04/04/build-and-run-buildah-inside-a-podman-container/"&gt;Build and run Buildah inside a Podman container&lt;/a&gt; (Tom Sweeney)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F11%2Fgetting-started-with-buildah%2F&amp;#38;linkname=Getting%20started%20with%20Buildah" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F11%2Fgetting-started-with-buildah%2F&amp;#38;linkname=Getting%20started%20with%20Buildah" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F11%2Fgetting-started-with-buildah%2F&amp;#38;linkname=Getting%20started%20with%20Buildah" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F11%2Fgetting-started-with-buildah%2F&amp;#38;linkname=Getting%20started%20with%20Buildah" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F11%2Fgetting-started-with-buildah%2F&amp;#38;linkname=Getting%20started%20with%20Buildah" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F11%2Fgetting-started-with-buildah%2F&amp;#38;linkname=Getting%20started%20with%20Buildah" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F11%2Fgetting-started-with-buildah%2F&amp;#38;linkname=Getting%20started%20with%20Buildah" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F11%2Fgetting-started-with-buildah%2F&amp;#038;title=Getting%20started%20with%20Buildah" data-a2a-url="https://developers.redhat.com/blog/2021/01/11/getting-started-with-buildah/" data-a2a-title="Getting started with Buildah"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/11/getting-started-with-buildah/"&gt;Getting started with Buildah&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/C-oFmv-GD0U" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;If you&amp;#8217;re looking to build Open Container Initiative (OCI) container images without a full container runtime or daemon installed, Buildah is the perfect solution. Now, Buildah is an open source, Linux-based tool that can build Docker- and Kubernetes-compatible images, and is easy to incorporate into scripts and build pipelines. In addition, Buildah has overlap functionality [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/11/getting-started-with-buildah/"&gt;Getting started with Buildah&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/01/11/getting-started-with-buildah/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">758807</post-id><dc:creator>Cedric Clyburn</dc:creator><dc:date>2021-01-11T08:00:01Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/01/11/getting-started-with-buildah/</feedburner:origLink></entry></feed>

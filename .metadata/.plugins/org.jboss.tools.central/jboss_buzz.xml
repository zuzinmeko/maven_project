<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Static analysis updates in GCC 11</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/1kjII0gq9pc/" /><category term="C" /><category term="Linux" /><category term="Open source" /><category term="Security" /><category term="-fanalyzer" /><category term="Fedora" /><category term="gcc" /><category term="program state" /><category term="static analysis" /><author><name>David Malcolm</name></author><id>https://developers.redhat.com/blog/?p=842257</id><updated>2021-01-28T08:00:24Z</updated><published>2021-01-28T08:00:24Z</published><content type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2014/09/gnu-logo.png" target="_blank" rel="noopener noreferrer"&gt;&lt;img class="alignleft" src="https://developers.redhat.com/blog/wp-content/uploads/2014/09/gnu-logo.png" alt="The GNU logo." width="179" height="173" /&gt;&lt;/a&gt;&lt;br /&gt; I work at Red Hat on the &lt;a target="_blank" rel="nofollow" href="https://gcc.gnu.org/"&gt;GNU Compiler Collection&lt;/a&gt; (GCC). In GCC 10, I added the new &lt;code&gt;-fanalyzer&lt;/code&gt; option, a &lt;a href="https://developers.redhat.com/blog/2020/03/26/static-analysis-in-gcc-10/"&gt;static analysis pass&lt;/a&gt; for identifying various problems at compile-time, rather than at runtime. The initial implementation was aimed at early adopters, who found a few bugs, including a security vulnerability: &lt;a target="_blank" rel="nofollow" href="https://www.theregister.com/2020/04/23/gcc_openssl_vulnerability/"&gt;CVE-2020-1967&lt;/a&gt;. Bernd Edlinger, who discovered the issue, had to wade through many false positives accompanying the real issue. Other users also managed to get the analyzer to crash on their code.&lt;/p&gt; &lt;p&gt;I&amp;#8217;ve been rewriting the analyzer to address these issues in the next major release, &lt;a target="_blank" rel="nofollow" href="https://gcc.gnu.org/gcc-11/changes.html"&gt;GCC 11&lt;/a&gt;. In this article, I describe the steps I&amp;#8217;m taking to reduce the number of false positives and make this static analysis tool more robust.&lt;/p&gt; &lt;p&gt;&lt;span id="more-842257"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Tracking program states&lt;/h2&gt; &lt;p&gt;I&amp;#8217;ve been attempting to fix bugs in &lt;code&gt;-fanalyzer&lt;/code&gt; as they are reported via GCC&amp;#8217;s Bugzilla instance. The analyzer&amp;#8217;s state-tracking component in GCC 10 had many crasher bugs. The more bugs I fixed, the more bugs turned up, with no apparent slowdown in the rate of discovery. This suggested to me that I needed to rewrite the component.&lt;/p&gt; &lt;p&gt;I made at least two big mistakes in how I tracked program states in the original &lt;code&gt;-fanalyzer&lt;/code&gt; implementation. These were in how I tracked symbolic values and regions. The GCC 10 implementation attempted to assign unique IDs to these symbolic entities and canonicalize them so that different states could be compared (equivalent entities ought to have the same ID between different states). Unfortunately, there was always one more canonicalization issue.&lt;/p&gt; &lt;p&gt;In the new implementation, I&amp;#8217;ve made these entities singletons. As a result, a unique object now represents the (symbolic) initial value of a particular parameter at a function call at the entry to the analysis. The change to singletons got rid of large amounts of fiddly canonicalization code, using simple pointers instead. The implementation is simpler, faster, and I&amp;#8217;ve been able to fix all of the crasher bugs. (I&amp;#8217;m not quite sure what benefit I saw in the original approach, but hindsight is 20/20, I guess.)&lt;/p&gt; &lt;p&gt;The second big change is in what the symbolic values and regions represent. Previously, I represented a mapping to symbolic values, where the keys were symbolic access paths of memory regions. In the new implementation, I&amp;#8217;ve represented the state as mappings of clusters of bit-offsets within memory. These are sometimes concrete (for example, at a specific bit-offset) and sometimes symbolic (such as an array offset where the index is symbolic). This approach does a much better job of handling unions, pointer aliasing, and so forth. Additionally, lots of fiddly bugs &amp;#8220;fixed themselves&amp;#8221; when I switched to the new implementation, which reassured me that I was on the right track.&lt;/p&gt; &lt;h2&gt;Memory leak detection and non-determinism&lt;/h2&gt; &lt;p&gt;I had to rewrite memory leak detection for the new implementation completely. That said, the old implementation had many false positives, whereas the new one seems much less prone to them.&lt;/p&gt; &lt;p&gt;Another issue I ran into is non-determinism, where the analyzer&amp;#8217;s exact behavior would vary from invocation to invocation. At various places, the implementation would iterate though values, and the order of iteration would depend implicitly on precise pointer values due to hashing algorithms. The pointer values can differ due to address-space layout randomization, which led to different results. I&amp;#8217;ve now fixed such logic in the code to ensure that the analyzer&amp;#8217;s behavior is repeatable from run to run.&lt;/p&gt; &lt;h2&gt;Four new warnings&lt;/h2&gt; &lt;p&gt;The GCC 10 implementation of &lt;code&gt;-fanalyzer&lt;/code&gt; added 15 warnings:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Warnings relating to memory management: &lt;ul&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-double-free&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-use-after-free&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-free-of-non-heap&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-malloc-leak&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Warnings relating to missing error-checking or misusing NULL pointers: &lt;ul&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-possible-null-argument&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-possible-null-dereference&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-null-argument&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-null-dereference&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Warnings relating to &lt;code&gt;stdio&lt;/code&gt; streams: &lt;ul&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-double-fclose&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-file-leak&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Warnings relating to use-after-return from stack frames: &lt;ul&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-stale-setjmp-buffer&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-use-of-pointer-in-stale-stack-frame&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Unsafe call warning: &lt;ul&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-unsafe-call-within-signal-handler&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Proof-of-concept warnings: &lt;ul&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-tainted-array-index&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-exposure-through-output-file&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;For GCC 11, I&amp;#8217;ve added four new warnings:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-write-to-const&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-write-to-string-literal&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-shift-count-negative&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;-Wanalyzer-shift-count-overflow&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Each of these corresponds to a pre-existing warning implemented in the C and C++ front ends, but with a &amp;#8220;&lt;code&gt;-Wanalyzer&lt;/code&gt;&amp;#8221; prefix rather than &amp;#8220;&lt;code&gt;-W&lt;/code&gt;.&amp;#8221; As an example, &lt;code&gt;-Wanalyzer-write-to-const&lt;/code&gt; corresponds to &lt;code&gt;-Wwrite-to-const&lt;/code&gt;. It&amp;#8217;s important to note that the two implementations are slightly different: Whereas the existing warning merely walks the syntax tree of a particular expression, the analyzer variant does an interprocedural path-based analysis, looking for code paths that attempt to write to a &lt;code&gt;const&lt;/code&gt; global.&lt;/p&gt; &lt;p&gt;After discussing whether to reuse the existing command-line options for such warnings, I chose to create new options to make it explicit that the warnings are implemented differently. The &lt;code&gt;-Wanalyzer&lt;/code&gt;-prefixed warnings will find more issues, but they are much more expensive at compile-time. (Though you&amp;#8217;ve already paid that price by choosing &lt;code&gt;-fanalyzer&lt;/code&gt;.)&lt;/p&gt; &lt;h2&gt;In progress: Attributes for marking APIs&lt;/h2&gt; &lt;p&gt;GCC has long had &lt;code&gt;__attribute__((malloc))&lt;/code&gt; for marking an API entry point as being a memory allocator. In previous GCC releases, this was purely a hint to the optimizer&amp;#8217;s pointer-aliasing logic. The attribute let the optimizer &amp;#8220;know&amp;#8221; that the pointer returned from the function pointed to different memory than the other pointers being optimized. The optimizer could then eliminate reads from locations that had not been clobbered after a write through the returned pointer.&lt;/p&gt; &lt;p&gt;In GCC 11, this attribute can now take an additional parameter marking which deallocator function should be called on the result. I&amp;#8217;m working on generalizing &lt;code&gt;-fanalyzer&lt;/code&gt; to warn about mismatches, leaks, and double-frees for APIs marked with this attribute. So far, however, it&amp;#8217;s unclear if the results will be useful without many additional attributes. For example, I attempted to use the following attribute to detect a leak in a Linux driver (CVE-2019-19078):&lt;/p&gt; &lt;pre&gt; extern struct urb *usb_alloc_urb(int iso_packets, gfp_t mem_flags); extern void usb_free_urb(struct urb *urb); &lt;/pre&gt; &lt;p&gt;I added the attribute to mark the &lt;code&gt;fns&lt;/code&gt; as an allocation/deallocation pair, where there is a leak of an &lt;code&gt;urb&lt;/code&gt; on an error-handling path. Unfortunately, various other functions take &lt;code&gt;struct urb *&lt;/code&gt;, and the analyzer conservatively assumes that an &lt;code&gt;urb&lt;/code&gt; passed to them might or might not be freed. It thus stops tracking state for them and only reports the issue if I disable much of the intervening code. This feature needs additional work to be useful except in the simplest cases.&lt;/p&gt; &lt;h2&gt;In progress: HTML output&lt;/h2&gt; &lt;p&gt;The analyzer&amp;#8217;s emitted control flow paths can be very verbose, so I&amp;#8217;ve been experimenting with other forms of output. I have an implementation of HTML output, in which the path information is written out to a separate HTML file. Here are a few examples:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://dmalcolm.fedorapeople.org/gcc/2020-11-05/html-examples/test.c.path-1.html"&gt;Double-free bug&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://dmalcolm.fedorapeople.org/gcc/2020-11-05/html-examples/signal-1.c.path-1.html"&gt;Signal handler issue&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://dmalcolm.fedorapeople.org/gcc/2020-11-05/html-examples/setjmp-7.c.path-1.html"&gt;Memory leak&lt;/a&gt; (due to &lt;code&gt;longjmp&lt;/code&gt; past a &lt;code&gt;free&lt;/code&gt;)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The HTML path output shows stack frames and runs of events, using drop-shadows to give a 3D look. The idea is to highlight the stack of frames as if it were an actual stack of overlapping cards. I also added JavaScript to use &lt;code&gt;j&lt;/code&gt; and &lt;code&gt;k&lt;/code&gt; to move forward and back through control-flow events.&lt;/p&gt; &lt;p&gt;Unfortunately, the HTML output doesn&amp;#8217;t capture the warnings themselves, just the paths. Fixing that would require deep changes to GCC&amp;#8217;s diagnostics subsystem, which I&amp;#8217;m wary of doing at this point in the development cycle. So, I&amp;#8217;m not sure I&amp;#8217;ve found the best way to enable the HTML format as an option; it seems better to capture all of the diagnostics somehow as build artifacts, rather than just the paths of those diagnostics that have paths associated with them.&lt;/p&gt; &lt;h2&gt;What&amp;#8217;s next for GCC 11 and -fanalyzer&lt;/h2&gt; &lt;p&gt;We&amp;#8217;re in the bug-fixing phase of GCC 11 development, aiming for a release in the spring of 2021. The analyzer still needs a fair bit of bug-fixing, and we&amp;#8217;re working on scaling it up. I plan to focus on that for this first part of the new year. (These problems can be related, by the way: Bugs sometimes lead to loop-handling going awry. The analyzer will then attempt to effectively &lt;em&gt;unroll a loop&lt;/em&gt;, which leads to hitting a safety limit and a slow, incomplete analysis.)&lt;/p&gt; &lt;p&gt;I am still developing &lt;code&gt;-fanalyzer&lt;/code&gt; only for C in GCC 11. I added partial support for C++&amp;#8217;s &lt;code&gt;new&lt;/code&gt; and &lt;code&gt;delete&lt;/code&gt;But there are enough missing features that it&amp;#8217;s not yet worth using on real C++ code. I plan to make the analyzer robust and scalable for C code in GCC 11 and defer C++ support to GCC 12.&lt;/p&gt; &lt;p&gt;GCC 11 will be in &lt;a target="_blank" rel="nofollow" href="https://fedoraproject.org/wiki/Changes/GNUToolchain"&gt;Fedora 34&lt;/a&gt;, which should also be out in the spring of 2021. For simple code examples, you can play around with the new GCC online at &lt;a target="_blank" rel="nofollow" href="https://godbolt.org/"&gt;godbolt.org&lt;/a&gt;. Select your GCC &amp;#8220;trunk&amp;#8221; and add &lt;code&gt;-fanalyzer&lt;/code&gt; to the compiler options. Have fun!&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F28%2Fstatic-analysis-updates-in-gcc-11%2F&amp;#38;linkname=Static%20analysis%20updates%20in%20GCC%2011" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F28%2Fstatic-analysis-updates-in-gcc-11%2F&amp;#38;linkname=Static%20analysis%20updates%20in%20GCC%2011" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F28%2Fstatic-analysis-updates-in-gcc-11%2F&amp;#38;linkname=Static%20analysis%20updates%20in%20GCC%2011" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F28%2Fstatic-analysis-updates-in-gcc-11%2F&amp;#38;linkname=Static%20analysis%20updates%20in%20GCC%2011" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F28%2Fstatic-analysis-updates-in-gcc-11%2F&amp;#38;linkname=Static%20analysis%20updates%20in%20GCC%2011" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F28%2Fstatic-analysis-updates-in-gcc-11%2F&amp;#38;linkname=Static%20analysis%20updates%20in%20GCC%2011" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F28%2Fstatic-analysis-updates-in-gcc-11%2F&amp;#38;linkname=Static%20analysis%20updates%20in%20GCC%2011" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F28%2Fstatic-analysis-updates-in-gcc-11%2F&amp;#038;title=Static%20analysis%20updates%20in%20GCC%2011" data-a2a-url="https://developers.redhat.com/blog/2021/01/28/static-analysis-updates-in-gcc-11/" data-a2a-title="Static analysis updates in GCC 11"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/28/static-analysis-updates-in-gcc-11/"&gt;Static analysis updates in GCC 11&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/1kjII0gq9pc" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;I work at Red Hat on the GNU Compiler Collection (GCC). In GCC 10, I added the new -fanalyzer option, a static analysis pass for identifying various problems at compile-time, rather than at runtime. The initial implementation was aimed at early adopters, who found a few bugs, including a security vulnerability: CVE-2020-1967. Bernd Edlinger, who [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/28/static-analysis-updates-in-gcc-11/"&gt;Static analysis updates in GCC 11&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/01/28/static-analysis-updates-in-gcc-11/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">842257</post-id><dc:creator>David Malcolm</dc:creator><dc:date>2021-01-28T08:00:24Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/01/28/static-analysis-updates-in-gcc-11/</feedburner:origLink></entry><entry><title type="html">Quarkus 1.11.1.Final released - Bugfixes</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/_ITdvGjyNJI/" /><author><name /></author><id>https://quarkus.io/blog/quarkus-1-11-1-final-released/</id><updated>2021-01-27T00:00:00Z</updated><content type="html">1.11.1.Final is a maintenance release fixing bugs and improving the documentation. Thanks to all the contributors who reported issues and provided reproducers: it allowed us to make steady progress on fixing issues. Also a big thanks to all the contributors providing pull requests, be they for the code or the...&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/_ITdvGjyNJI" height="1" width="1" alt=""/&gt;</content><dc:creator /><feedburner:origLink>https://quarkus.io/blog/quarkus-1-11-1-final-released/</feedburner:origLink></entry><entry><title>JBoss Tools and Red Hat CodeReady Studio for Eclipse 2020-09</title><link rel="alternate" type="text/html" href="http://feedproxy.google.com/~r/jbossbuzz/~3/OYBlMzJYgxU/12.18.0.ga.html" /><category term="release" /><category term="jbosstools" /><category term="devstudio" /><category term="jbosscentral" /><category term="codereadystudio" /><author><name>jeffmaury</name></author><id>https://tools.jboss.org/blog/12.18.0.ga.html</id><updated>2021-01-26T08:23:40Z</updated><published>2021-01-26T00:00:00Z</published><content type="html">&lt;div&gt;&lt;div id="preamble"&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;&lt;a href="https://tools.jboss.org/downloads/jbosstools/2020-09/4.18.0.Final.html"&gt;JBoss Tools 4.18.0&lt;/a&gt; and &lt;a href="https://tools.jboss.org/downloads/devstudio/2020-09/12.18.0.GA.html"&gt;Red Hat CodeReady Studio 12.18&lt;/a&gt; for Eclipse 2020-09 are here waiting for you. Check it out!&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://tools.jboss.org/blog/images/crstudio12.png" alt="crstudio12" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="installation"&gt;&lt;a class="anchor" href="#installation"&gt;&lt;/a&gt;Installation&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Red Hat CodeReady Studio comes with everything pre-bundled in its installer. Simply download it from our &lt;a href="https://developers.redhat.com/products/codeready-studio/overview/"&gt;Red Hat CodeReady product page&lt;/a&gt; and run it like this:&lt;/p&gt; &lt;/div&gt; &lt;div class="literalblock"&gt; &lt;div class="content"&gt; &lt;pre&gt;java -jar codereadystudio-&amp;lt;installername&amp;gt;.jar&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;JBoss Tools or Bring-Your-Own-Eclipse (BYOE) CodeReady Studio require a bit more:&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;This release requires at least Eclipse 4.17 (2020-09) but we recommend using the latest &lt;a href="https://www.eclipse.org/downloads/packages/release/2020-09/r/eclipse-ide-enterprise-java-developers"&gt;Eclipse 4.17 2020-09 JEE Bundle&lt;/a&gt; since then you get most of the dependencies preinstalled.&lt;/p&gt; &lt;/div&gt; &lt;div class="admonitionblock warning"&gt; &lt;table&gt; &lt;tr&gt; &lt;td class="icon"&gt; &lt;i class="fa icon-warning" title="Warning"&gt;&lt;/i&gt; &lt;/td&gt; &lt;td class="content"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Java11 is now required to run Red Hat Developer Studio or JBoss Tools (this is a requirement from Eclipse 4.17). So make sure to select a Java11 JDK in the installer. You can still work with pre-Java11 JDK/JRE and projects in the tool.&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Once you have installed Eclipse, you can either find us on the Eclipse Marketplace under &amp;quot;JBoss Tools&amp;quot; or &amp;quot;Red Hat CodeReady Studio&amp;quot;.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;For JBoss Tools, you can also use our update site directly.&lt;/p&gt; &lt;/div&gt; &lt;div class="literalblock"&gt; &lt;div class="content"&gt; &lt;pre&gt;http://download.jboss.org/jbosstools/photon/stable/updates/&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="what-is-new"&gt;&lt;a class="anchor" href="#what-is-new"&gt;&lt;/a&gt;What is new?&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Our main focus for this release was an improved tooling for the Quarkus framework, improvements for container based development and bug fixing.&lt;/p&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="openshift"&gt;&lt;a class="anchor" href="#openshift"&gt;&lt;/a&gt;OpenShift&lt;/h3&gt; &lt;div class="sect3"&gt; &lt;h4 id="devfile-based-deployments"&gt;&lt;a class="anchor" href="#devfile-based-deployments"&gt;&lt;/a&gt;Devfile based deployments&lt;/h4&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The Application Explorer view is now based on odo 2.x, which allows deployments to be based on devfile (developer oriented manifest file). The components from the default odo registry are listed with legacy S2I components:&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://tools.jboss.org/documentation/whatsnew/openshift/images/devfile.png" alt="devfile" width="600" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;It is also now possible to bootstrap from an empty project as the components from the registry may expose starter projects (sample code that will initialize your empty project).&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://tools.jboss.org/documentation/whatsnew/openshift/images/devfile1.png" alt="devfile1" width="600" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="quarkus"&gt;&lt;a class="anchor" href="#quarkus"&gt;&lt;/a&gt;Quarkus&lt;/h3&gt; &lt;div class="sect3"&gt; &lt;h4 id="support-for-codestarts-in-new-quarkus-project-wizard"&gt;&lt;a class="anchor" href="#support-for-codestarts-in-new-quarkus-project-wizard"&gt;&lt;/a&gt;Support for codestarts in New Quarkus project wizard&lt;/h4&gt; &lt;div class="paragraph"&gt; &lt;p&gt;code.quarkus.io has added a new option codestart that allows extension that support this new feature to contribute sample code in the generated project. It is enabled by default and is accessible from the second step in the wizard:&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://tools.jboss.org/documentation/whatsnew/quarkus/images/quarkus30.png" alt="quarkus30" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="server-tools"&gt;&lt;a class="anchor" href="#server-tools"&gt;&lt;/a&gt;Server Tools&lt;/h3&gt; &lt;div class="sect3"&gt; &lt;h4 id="wildfly-22-server-adapter"&gt;&lt;a class="anchor" href="#wildfly-22-server-adapter"&gt;&lt;/a&gt;Wildfly 22 Server Adapter&lt;/h4&gt; &lt;div class="paragraph"&gt; &lt;p&gt;A server adapter has been added to work with Wildfly 22.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="hibernate-tools"&gt;&lt;a class="anchor" href="#hibernate-tools"&gt;&lt;/a&gt;Hibernate Tools&lt;/h3&gt; &lt;div class="sect3"&gt; &lt;h4 id="hibernate-runtime-provider-updates"&gt;&lt;a class="anchor" href="#hibernate-runtime-provider-updates"&gt;&lt;/a&gt;Hibernate Runtime Provider Updates&lt;/h4&gt; &lt;div class="paragraph"&gt; &lt;p&gt;A number of additions and updates have been performed on the available Hibernate runtime providers.&lt;/p&gt; &lt;/div&gt; &lt;div class="sect4"&gt; &lt;h5 id="runtime-provider-updates"&gt;&lt;a class="anchor" href="#runtime-provider-updates"&gt;&lt;/a&gt;Runtime Provider Updates&lt;/h5&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The Hibernate 5.4 runtime provider now incorporates Hibernate Core version 5.4.27.Final and Hibernate Tools version 5.4.27.Final.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The Hibernate 5.3 runtime provider now incorporates Hibernate Core version 5.3.20.Final and Hibernate Tools version 5.3.20.Final.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="and-more"&gt;&lt;a class="anchor" href="#and-more"&gt;&lt;/a&gt;And more…​&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;You can find more noteworthy updates in on &lt;a href="https://tools.jboss.org/documentation/whatsnew/jbosstools/4.17.0.Final.html"&gt;this page&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="what-is-next"&gt;&lt;a class="anchor" href="#what-is-next"&gt;&lt;/a&gt;What is next?&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Having JBoss Tools 4.18.0 and Red Hat CodeReady Studio 12.18 out we are already working on the next release.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Enjoy!&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Jeff Maury&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/OYBlMzJYgxU" height="1" width="1" alt=""/&gt;</content><summary>JBoss Tools 4.18.0 and Red Hat CodeReady Studio 12.18 for Eclipse 2020-09 are here waiting for you. Check it out! Installation Red Hat CodeReady Studio comes with everything pre-bundled in its installer. Simply download it from our Red Hat CodeReady product page and run it like this: java -jar codereadystudio-&lt;installername&gt;.jar JBoss Tools or Bring-Your-Own-Eclipse (BYOE) CodeReady Studio require a bit more: This release requires at least Eclipse 4.17 (2020-09) but we recommend using the latest Eclipse 4.17 2020-09 JEE Bundle since then you get most of the dependencies preinstalled. Java11 is now required to run Red Hat Developer Studio or JBoss Tools (this is a requirement from Eclipse 4.17). So...</summary><dc:creator>jeffmaury</dc:creator><dc:date>2021-01-26T00:00:00Z</dc:date><feedburner:origLink>https://tools.jboss.org/blog/12.18.0.ga.html</feedburner:origLink></entry><entry><title>Introduction to ContainerJFR: JDK Flight Recorder for containers</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/PPHmWvkzro8/" /><category term="Containers" /><category term="Java" /><category term="Kubernetes" /><category term="Open source" /><category term="ContainerJFR" /><category term="Java flight recorder" /><category term="monitor java" /><category term="OpenJDK" /><category term="profile java" /><author><name>Andrew Azores</name></author><id>https://developers.redhat.com/blog/?p=798277</id><updated>2021-01-25T08:00:18Z</updated><published>2021-01-25T08:00:18Z</published><content type="html">&lt;p&gt;OpenJDK has long been a top pick for real-world applications and workloads, chosen for its blend of performance, compatibility, reliability, and observability. For many years, JDK Flight Recorder (JFR) and JDK Mission Control (JMC) have contributed to OpenJDK&amp;#8217;s success. Until recently, both were commercial features, however, available only for certain users and workloads.&lt;/p&gt; &lt;p&gt;In 2018, JDK Mission Control and JDK Flight Recorder were open-sourced. JDK Flight Recorder is now built into the Java Virtual Machine (JVM) for later releases of OpenJDK 8 and all versions from OpenJDK 11 onward. Open-sourcing these tools brings their power—always-on, near-zero overhead production profiling and monitoring, application-specific custom events, and unified-core JDK analytical tooling—to all JDK users. On the downside, JDK Mission Control and JDK Flight Recorder have emerged into a world rapidly moving toward containerization, which is not the paradigm that they were designed for.&lt;/p&gt; &lt;p&gt;The desktop-only JDK Mission Control application requires developers and administrators to access flight recordings on the local disk. Otherwise, one resorts to a complex and potentially insecure setup to connect directly to applications over Java Management Extensions (JMX) in the cloud. Similarly, the bare-metal-focused JDK Flight Recorder allows JVMs to dump recordings into the local filesystem, but not when the application runs inside a container. In that case, the filesystem is not easily accessible from the outside world, and it isn&amp;#8217;t possible to retrieve and analyze recordings.&lt;/p&gt; &lt;p&gt;This article introduces &lt;a target="_blank" rel="nofollow" href="https://github.com/rh-jmc-team/container-jfr"&gt;ContainerJFR&lt;/a&gt;, a young project on the way to becoming a Red Hat product. ContainerJFR seeks to bridge the gaps between JDK Flight Recorder in the cloud and end-users at their workstations.&lt;/p&gt; &lt;h2&gt;Manual ContainerJFR installation and setup&lt;/h2&gt; &lt;p&gt;Installing ContainerJFR manually is straightforward using the available images on &lt;a target="_blank" rel="nofollow" href="https://quay.io/repository/rh-jmc-team/container-jfr"&gt;Quay.io&lt;/a&gt;. Run the following for a basic installation and product demonstration:&lt;/p&gt; &lt;pre&gt;$ podman run -it --rm -p 8181 -e CONTAINER_JFR_WEB_HOST=0.0.0.0 quay.io/rh-jmc-team/container-jfr:latest &lt;/pre&gt; &lt;p&gt;For a more full-fledged demonstration, you can clone the ContainerJFR repository and run its &lt;code&gt;smoketest.sh&lt;/code&gt;. The following sets up a few containers in a Podman pod for testing and demonstration:&lt;/p&gt; &lt;pre&gt;$ git clone &lt;a target="_blank" rel="nofollow" href="https://github.com/rh-jmc-team/container-jfr"&gt;https://github.com/rh-jmc-team/container-jfr&lt;/a&gt; $ cd container-jfr $ sh smoketest.sh &lt;/pre&gt; &lt;p&gt;ContainerJFR&amp;#8217;s credentials, in this case, are &lt;code&gt;smoketest:smoketest&lt;/code&gt;. The other application’s credentials are &lt;code&gt;admin:adminpass123&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;Deploying ContainerJFR on Red Hat OpenShift&lt;/h2&gt; &lt;p&gt;If you have access to &lt;a href="https://developers.redhat.com/products/openshift/getting-started"&gt;Red Hat OpenShift&lt;/a&gt; or another Kubernetes cluster, you can use the &lt;a target="_blank" rel="nofollow" href="https://github.com/rh-jmc-team/container-jfr-operator"&gt;ContainerJFR Operator&lt;/a&gt; to deploy ContainerJFR on your cluster:&lt;/p&gt; &lt;pre&gt;$ git clone &lt;a target="_blank" rel="nofollow" href="https://github.com/rh-jmc-team/container-jfr-operator"&gt;https://github.com/rh-jmc-team/container-jfr-operator&lt;/a&gt; $ cd container-jfr-operator $ oc login # ensure you are logged in to your running OpenShift cluster first $ make deploy # to directly deploy the Operator in your cluster along with a ContainerJFR CR, required ServiceAccount and Role/RoleBindings, etc. $ make catalog # alternative to make deploy. This will add a custom CatalogSource to your cluster, allowing you to install the Operator from your Administrator view’s OperatorHub panel &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: If you don’t already have access to an OpenShift or Kubernetes cluster, try &lt;a href="https://developers.redhat.com/products/codeready-containers/overview"&gt;Red Hat CodeReady Containers&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Figure 1 shows ContainerJFR in the OpenShift OperatorHub after we&amp;#8217;ve issued a &lt;code&gt;$ make catalog&lt;/code&gt; to add a custom catalog source.&lt;/p&gt; &lt;div id="attachment_799477" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/operatorhub.png"&gt;&lt;img aria-describedby="caption-attachment-799477" class="wp-image-799477 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/operatorhub-1024x516.png" alt="The OpenShift OperatorHub with the ContainerJFR Operator." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/operatorhub-1024x516.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/operatorhub-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/operatorhub-768x387.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799477" class="wp-caption-text"&gt;Figure 1: ContainerJFR in the OpenShift OperatorHub.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Figure 2 shows a ContainerJFR instance installed in the default namespace.&lt;/p&gt; &lt;div id="attachment_799537" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/installed-operator-1.png"&gt;&lt;img aria-describedby="caption-attachment-799537" class="wp-image-799537 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/installed-operator-1-1024x214.png" alt="The ContainerJFR Operator has been installed." width="640" height="134" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/installed-operator-1-1024x214.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/installed-operator-1-300x63.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/installed-operator-1-768x160.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799537" class="wp-caption-text"&gt;Figure 2: ContainerJFR installed in a project namespace.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;After you&amp;#8217;ve installed ContainerJFR, create a custom resource for it, as shown in Figure 3. Choose any name you like and leave the &lt;b&gt;minimal&lt;/b&gt; setting on&lt;strong&gt; false&lt;/strong&gt; for now.&lt;/p&gt; &lt;div id="attachment_799457" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/create-containerjfr-cr.png"&gt;&lt;img aria-describedby="caption-attachment-799457" class="wp-image-799457 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/create-containerjfr-cr-1024x433.png" alt="The dialog to create a ContainerJFR custom resource." width="640" height="271" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/create-containerjfr-cr-1024x433.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/create-containerjfr-cr-300x127.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/create-containerjfr-cr-768x325.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/create-containerjfr-cr.png 1337w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799457" class="wp-caption-text"&gt;Figure 3: Create and configure the ContainerJFR custom resource.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;After a short time, the Operator finishes deploying ContainerJFR and its services. You can use any view that shows the exposed route URLs to see the ContainerJFR web client. Figure 4 shows ContainerJFR in OpenShift&amp;#8217;s Topology view.&lt;/p&gt; &lt;div id="attachment_799437" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/topology-view.png"&gt;&lt;img aria-describedby="caption-attachment-799437" class="wp-image-799437 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/topology-view-1024x517.png" alt="ContainerJFR seen from the OpenShift developer console in the Topology view." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/topology-view-1024x517.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/topology-view-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/topology-view-768x388.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799437" class="wp-caption-text"&gt;Figure 4: ContainerJFR in the OpenShift Topology view.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Next, we&amp;#8217;ll take a look at ContainerJFR&amp;#8217;s major features, and I&amp;#8217;ll show you how to configure them for your container-managed OpenJDK applications.&lt;/p&gt; &lt;h2&gt;Discovery with ContainerJFR&lt;/h2&gt; &lt;p&gt;ContainerJFR is a containerized JVM that runs as a “sidecar” alongside your OpenJDK applications. Depending on the runtime environment, it automatically selects the best strategy for discovering your JMX-enabled applications. For applications running with &lt;code&gt;docker-compose&lt;/code&gt; or &lt;code&gt;podman-compose&lt;/code&gt;, ContainerJFR would use the &lt;a target="_blank" rel="nofollow" href="https://docs.oracle.com/javase/10/management/java-discovery-protocol.htm"&gt;Java Discovery Protocol&lt;/a&gt; (JDP). For applications running on Kubernetes or OpenShift, it would use endpoints. These are only examples of the platform implementations ContainerJFR currently provides. It is easily extensible if you need customized support for a different container platform.&lt;/p&gt; &lt;h3&gt;Java Management Extensions&lt;/h3&gt; &lt;p&gt;Ensure that your applications have JMX enabled and that the JMX port is published and reachable by ContainerJFR. In practical terms, this means passing the following JVM flags when you start the application:&lt;/p&gt; &lt;pre&gt;-Dcom.sun.management.jmxremote.port=9091 -Dcom.sun.management.jmxremote.rmi.port=9091 &lt;/pre&gt; &lt;p&gt;Then, expose the port using whatever mechanism your container platform uses. In OpenShift or Kubernetes, you would create a service for your deployment and then add an exposed port to the service. By default, ContainerJFR uses port 9091 for JMX, but you can use any port number given the port is named &lt;code&gt;jfr-jmx&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Figure 5 shows ContainerJFR with two sample applications in the OpenShift Topology view.&lt;/p&gt; &lt;div id="attachment_799547" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/topology-with-apps.png"&gt;&lt;img aria-describedby="caption-attachment-799547" class="wp-image-799547 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/topology-with-apps-1024x517.png" alt="The OpenShift Topology view shows ContainerJFR and two sample applications." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/topology-with-apps-1024x517.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/topology-with-apps-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/topology-with-apps-768x388.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799547" class="wp-caption-text"&gt;Figure 5: ContainerJFR with two sample applications.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Java Discovery Protocol&lt;/h3&gt; &lt;p&gt;If you are running with Podman or Docker, or if you are running a local JVM process directly on your host machine, you should also enable Java Discovery Protocol (JDP):&lt;/p&gt; &lt;pre&gt;-Dcom.sun.management.jmxremote.autodiscovery=true &lt;/pre&gt; &lt;h2&gt;Event templates in ContainerJFR&lt;/h2&gt; &lt;p&gt;ContainerJFR supports JDK Flight Recorder event templates, which pre-set the event types and configuration properties to be supported. Using event templates simplifies the task of capturing meaningful data for your applications. ContainerJFR also includes a view that displays all of the event types registered with the JDK Flight Recorder framework for a target JVM. This view is useful when creating or modifying your own event templates.&lt;/p&gt; &lt;p&gt;The Event Templates view in Figure 7 displays pre-set event templates that you can download to your local machine to examine or modify. After you&amp;#8217;ve modified a template, you can upload it for reuse. You can also create recordings from templates.&lt;/p&gt; &lt;div id="attachment_799587" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-templates.png"&gt;&lt;img aria-describedby="caption-attachment-799587" class="wp-image-799587 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-templates-1024x517.png" alt="The Event Templates view in ContainerJFR." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-templates-1024x517.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-templates-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-templates-768x388.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799587" class="wp-caption-text"&gt;Figure 7: Event templates in ContainerJFR.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The Event Types view in Figure 8 displays all of the event types registered with the selected target JVM. You can use this view to search for events by category, keyword, or provider.&lt;/p&gt; &lt;div id="attachment_799567" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-types.png"&gt;&lt;img aria-describedby="caption-attachment-799567" class="wp-image-799567 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-types-1024x517.png" alt="The Event Types view in ContainerJFR." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-types-1024x517.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-types-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-types-768x388.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799567" class="wp-caption-text"&gt;Figure 8: Event types in ContainerJFR.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Editing templates&lt;/h3&gt; &lt;p&gt;You can use ContainerJFR to download a template from a target JVM to your local machine, then open and inspect the template XML document with your favorite text editor. You can even import and edit the template using JDK Mission Control. Figure 9 shows the dialog to download an event template.&lt;/p&gt; &lt;div id="attachment_799607" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-799607" class="size-large wp-image-799607" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-template-download-1024x243.png" alt="The dialog to download an event template." width="640" height="152" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-template-download-1024x243.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-template-download-300x71.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-template-download-768x182.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/event-template-download.png 1599w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-799607" class="wp-caption-text"&gt;Figure 9: Download an event template to your local disk.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Custom templates&lt;/h3&gt; &lt;p&gt;After you have created a custom template or modified an existing one, you can re-upload it to ContainerJFR, where it will be retained for future use. You will be able to apply the template whenever you create new recordings across your JVM applications.&lt;/p&gt; &lt;p&gt;You can open and edit event templates using any plaintext editor. Another option is to use JDK Mission Control&amp;#8217;s graphical template editor to import, edit, and export a template. Figure 10 shows an event template in a plaintext editor.&lt;/p&gt; &lt;div id="attachment_799617" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-in-editor.png"&gt;&lt;img aria-describedby="caption-attachment-799617" class="wp-image-799617 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-in-editor-1024x556.png" alt="An event template in a plaintext editor." width="640" height="348" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-in-editor-1024x556.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-in-editor-300x163.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-in-editor-768x417.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799617" class="wp-caption-text"&gt;Figure 10: Use any editor to modify an event template in XML format.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;When you upload a new or modified template, ContainerJFR validates it, as shown in Figure 11.&lt;/p&gt; &lt;div id="attachment_799627" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-to-upload.png"&gt;&lt;img aria-describedby="caption-attachment-799627" class="wp-image-799627 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-to-upload-1024x456.png" alt="An event template ready for upload." width="640" height="285" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-to-upload-1024x456.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-to-upload-300x133.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-to-upload-768x342.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799627" class="wp-caption-text"&gt;Figure 11: Templates are validated when the server receives them.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Figure 12 shows all of the available templates for a ContainerJFR instance.&lt;/p&gt; &lt;div id="attachment_799637" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-uploaded.png"&gt;&lt;img aria-describedby="caption-attachment-799637" class="wp-image-799637 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-uploaded-1024x233.png" alt="A list of templates available for later use." width="640" height="146" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-uploaded-1024x233.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-uploaded-300x68.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/template-uploaded-768x175.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799637" class="wp-caption-text"&gt;Figure 12: A list of templates available for later use.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;All of these features also work with JDK Flight Recorder’s Custom Events API. You can create application-specific event types while developing your application, then create a custom event template including these events, and tailor your own continuous production recordings.&lt;/p&gt; &lt;h2&gt;Recordings in ContainerJFR&lt;/h2&gt; &lt;p&gt;ContainerJFR offers several ways to capture and preserve recordings, including custom recordings, snapshots, and archives.&lt;/p&gt; &lt;h3&gt;Custom recordings&lt;/h3&gt; &lt;p&gt;Figure 13 shows the configuration properties to be defined when you set up a new custom recording.&lt;/p&gt; &lt;div id="attachment_799647" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/create-custom-recording.png"&gt;&lt;img aria-describedby="caption-attachment-799647" class="wp-image-799647 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/create-custom-recording-1024x517.png" alt="The dialog to create a custom recording." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/create-custom-recording-1024x517.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/create-custom-recording-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/create-custom-recording-768x388.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799647" class="wp-caption-text"&gt;Figure 13: Creating a custom recording.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;First is the name of the recording, which ContainerJFR uses to enforce uniqueness per target. You will also configure the duration before the recording is automatically stopped or if it should run continuously until it is manually stopped. You will need to configure the event specifier string or template for the events you want the recording to capture. Advanced properties include “to disk,&amp;#8221; “max size,&amp;#8221; and “max age.&amp;#8221; See the &lt;a&gt;JDK Flight Recorder documentation&lt;/a&gt; to learn more about these properties.&lt;/p&gt; &lt;h3&gt;Snapshots&lt;/h3&gt; &lt;p&gt;Figure 14 shows the dialog to create a new snapshot recording. A &lt;i&gt;snapshot&lt;/i&gt; is an overview of all of the information captured by other recordings.&lt;/p&gt; &lt;div id="attachment_799677" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/snapshot-recording.png"&gt;&lt;img aria-describedby="caption-attachment-799677" class="wp-image-799677 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/snapshot-recording-1024x291.png" alt="The view to create a snapshot recording." width="640" height="182" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/snapshot-recording-1024x291.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/snapshot-recording-300x85.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/snapshot-recording-768x218.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799677" class="wp-caption-text"&gt;Figure 14: Create a snapshot recording with one click.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;If you have multiple custom recordings running in a target at once, you could use a snapshot to create a new recording file at that point in time. The snapshot contains the merged data from all of your other recordings. Snapshots can also be useful for preserving data from a single, continuous recording at a particular point in time.&lt;/p&gt; &lt;h3&gt;Data flow&lt;/h3&gt; &lt;p&gt;When you create a recording, you ask ContainerJFR to send instructions to your target JVM to start a flight recording. No data is transferred outside of your application at this point, only the name, state, and start time of your recordings, along with other basic metadata. The recording lives only in the memory of your target application, within its container.&lt;/p&gt; &lt;div id="attachment_799657" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/recording-list.png"&gt;&lt;img aria-describedby="caption-attachment-799657" class="wp-image-799657 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/recording-list-1024x517.png" alt="The view shows a list of recordings." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/recording-list-1024x517.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/recording-list-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/recording-list-768x388.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799657" class="wp-caption-text"&gt;Figure 15: ContainerJFR displays all of the recordings present in a selected target JVM.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Archives&lt;/h3&gt; &lt;p&gt;&lt;i&gt;Archiving&lt;/i&gt; streams a snapshot of a recording out of your application and into ContainerJFR. ContainerJFR immediately writes the snapshot to its local disk (or a persistent volume in OpenShift or Kubernetes) and drops it from memory. Even if your application is scaled down or otherwise goes away, you will still be able to access the recording for analysis. If you accidentally delete a &lt;code&gt;.jfr&lt;/code&gt; file, you can re-upload it from your workstation’s local disk into the archives. This also works if you remove ContainerJFR from the cluster and re-install it later.&lt;/p&gt; &lt;p&gt;The archived recording list in Figure 16 displays all of the recordings saved to ContainerJFR&amp;#8217;s persistent storage, which is common across all target JVMs.&lt;/p&gt; &lt;div id="attachment_799667" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/archived-list.png"&gt;&lt;img aria-describedby="caption-attachment-799667" class="wp-image-799667 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/archived-list-1024x517.png" alt="The view shows a list of archived recordings." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/archived-list-1024x517.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/archived-list-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/archived-list-768x388.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799667" class="wp-caption-text"&gt;Figure 16: Recordings saved to ContainerJFR&amp;#8217;s persistent storage.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Automated analysis with ContainerJFR&lt;/h2&gt; &lt;p&gt;ContainerJFR lets you run an automated analysis on your flight recordings within your cloud deployment without ever needing to transfer data to your local machine or outside of the cluster. You can use this feature to check your applications&amp;#8217; health from a hotel with a slow connection or an airport using only your phone or tablet.&lt;/p&gt; &lt;p&gt;Expanding the list of active and archived recordings in Figure 17 reveals an automated analysis generated within the cluster.&lt;/p&gt; &lt;div id="attachment_799687" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/automated-report.png"&gt;&lt;img aria-describedby="caption-attachment-799687" class="wp-image-799687 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/automated-report-1024x517.png" alt="An automated analysis report." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/automated-report-1024x517.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/automated-report-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/automated-report-768x388.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799687" class="wp-caption-text"&gt;Figure 17: An automated analysis report for active and archived recordings.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;When you expand a recording, ContainerJFR uses its JDK Mission Control back end to generate an automated analysis report, alerting you to any apparent or probable issues with your application. You can also save reports in HTML format for future reference.&lt;/p&gt; &lt;h3&gt;Using Grafana for analysis&lt;/h3&gt; &lt;p&gt;If the automated analysis report doesn’t contain enough information for you, or if it points out a problem that you want to inspect more closely, you can send the recording to the &lt;a target="_blank" rel="nofollow" href="https://github.com/rh-jmc-team/jfr-datasource"&gt;jfr-datasource&lt;/a&gt; exporter within the ContainerJFR pod. From there, you can view the data using &lt;a target="_blank" rel="nofollow" href="https://grafana.com"&gt;Grafana&lt;/a&gt;. Figure 18 shows the recording list item action menu, which you can use to send a recording to the Grafana dashboard.&lt;/p&gt; &lt;div id="attachment_799697" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/view-in-grafana.png"&gt;&lt;img aria-describedby="caption-attachment-799697" class="wp-image-799697 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/view-in-grafana-1024x263.png" alt="The Grafana action view." width="640" height="164" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/view-in-grafana-1024x263.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/view-in-grafana-300x77.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/view-in-grafana-768x197.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799697" class="wp-caption-text"&gt;Figure 18: Send a recording to the Grafana dashboard for further analysis.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;ContainerJFR provides a pre-configured dashboard with time-series data, but you are encouraged to create your own dashboards with the metrics that matter to you. Note, again, that none of your data leaves the cluster. The &lt;code&gt;jfr-datasource&lt;/code&gt; that provides the translation from a &lt;code&gt;.jfr&lt;/code&gt; file to Grafana metrics is hidden within the ContainerJFR pod, and the Grafana dashboard instance is secured with generated credentials (stored in an OpenShift or Kubernetes secret) before being exposed to the outside world. It is easy to retrieve those generated credentials using the following commands:&lt;/p&gt; &lt;pre&gt;$ oc get secret containerjfr-grafana-basic -o json | jq -crM .data.GF_SECURITY_ADMIN_USER | base64 -d $ oc get secret containerjfr-grafana-basic -o json | jq -crM .data.GF_SECURITY_ADMIN_PASSWORD | base64 -d &lt;/pre&gt; &lt;p&gt;Once you have the credentials, you can plug them into the Grafana dashboard&amp;#8217;s login page and start viewing your metrics, as shown in Figure 19.&lt;/p&gt; &lt;div id="attachment_799717" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/grafana-dashboard-1.png"&gt;&lt;img aria-describedby="caption-attachment-799717" class="wp-image-799717 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/grafana-dashboard-1-1024x517.png" alt="Viewing metrics in the Grafana dashboard." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/grafana-dashboard-1-1024x517.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/grafana-dashboard-1-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/grafana-dashboard-1-768x388.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799717" class="wp-caption-text"&gt;Figure 19: The preconfigured Grafana dashboard gives more detailed insights into your application&amp;#8217;s performance (batteries included and installed).&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Using JDK Mission Control for analysis&lt;/h3&gt; &lt;p&gt;Finally, if you need even more detail, you can download a recording file from ContainerJFR to your local disk and open it with the full-featured offline JDK Mission Control desktop application. This is the only scenario where your recording actually leaves the cluster.&lt;/p&gt; &lt;div id="attachment_799727" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/jmc.png"&gt;&lt;img aria-describedby="caption-attachment-799727" class="wp-image-799727 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/jmc-1024x556.png" alt="The JDK Mission Control dashboard." width="640" height="348" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/jmc-1024x556.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/jmc-300x163.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/jmc-768x417.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799727" class="wp-caption-text"&gt;Figure 20: Use the JDK Mission Control desktop application for a deep-dive into the data collected from your cloud applications.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The JDK Mission Control desktop application offers a wealth of features and capabilities, but I will leave that discussion for another article.&lt;/p&gt; &lt;h2&gt;Secure authentication with ContainerJFR&lt;/h2&gt; &lt;p&gt;JDK Flight Recorder captures a tremendous amount of data with no significant runtime overhead. Keeping the data secure and ensuring its integrity is vital. As shown in Figure 21, ContainerJFR does not require your application to open its JMX connections to the world—only to connections from inside your OpenShift namespace or your Docker or Podman network.&lt;/p&gt; &lt;div id="attachment_852077" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/graph0.png"&gt;&lt;img aria-describedby="caption-attachment-852077" class="wp-image-852077 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/graph0-1024x867.png" alt="A graph illustrating ContainerJFR deployment and relations between components." width="640" height="542" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/graph0-1024x867.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/graph0-300x254.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/graph0-768x650.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/graph0.png 1137w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-852077" class="wp-caption-text"&gt;Figure 21: Overview of a secure ContainerJFR deployment.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Once ContainerJFR has received a copy of your Java Flight Recorder data—which it does only upon your instruction—that data is accessible only through secured API requests. The secured API requests support JMX authentication to connect to your application and another authentication layer to connect to ContainerJFR.&lt;/p&gt; &lt;p&gt;When running in OpenShift, all sensitive API requests require a user account token for authentication, as shown in Figure 22. Note that requests from the client to ContainerJFR over HTTP or WebSocket and requests from ContainerJFR to targets over JMX all support and enable the Secure Socket Layer or Transport Layer Security (SSL/TLS) protocol by default.&lt;/p&gt; &lt;div id="attachment_799597" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/10/cjfr-login.png"&gt;&lt;img aria-describedby="caption-attachment-799597" class="wp-image-799597 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/10/cjfr-login-1024x517.png" alt="The ContainerJFR login page on OpenShift." width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/10/cjfr-login-1024x517.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/cjfr-login-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/10/cjfr-login-768x388.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-799597" class="wp-caption-text"&gt;Figure 22: ContainerJFR uses the OpenShift cluster&amp;#8217;s authentication server for user authentication.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Future plans for ContainerJFR&lt;/h2&gt; &lt;p&gt;ContainerJFR is still a young project, and the worlds of containers and monitoring are always expanding, so there is a lot on our horizon. In the future, we hope to make the following changes and improvements to ContainerJFR:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Implement better and more flexible ways for ContainerJFR to identify, group, and label target applications. One example is the ability to examine OpenShift or Kubernetes labels and annotations.&lt;/li&gt; &lt;li&gt;Add support for batched operations, used to manage recordings across a group of targets with a single request.&lt;/li&gt; &lt;li&gt;Add a Trigger feature to allow recordings to be automatically started and stopped on a target or group of targets when a predefined event occurs. For example, when a new target appears, automatically start a recording with a predefined template.&lt;/li&gt; &lt;li&gt;Embed Grafana views and other visualizations directly into the ContainerJFR web client.&lt;/li&gt; &lt;li&gt;Provide integration or deep linking to the desktop JDK Mission Control application.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Visit the &lt;a target="_blank" rel="nofollow" href="https://github.com/rh-jmc-team/container-jfr"&gt;ContainerJFR repository&lt;/a&gt; for future updates.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F25%2Fintroduction-to-containerjfr-jdk-flight-recorder-for-containers%2F&amp;#38;linkname=Introduction%20to%20ContainerJFR%3A%20JDK%20Flight%20Recorder%20for%20containers" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F25%2Fintroduction-to-containerjfr-jdk-flight-recorder-for-containers%2F&amp;#38;linkname=Introduction%20to%20ContainerJFR%3A%20JDK%20Flight%20Recorder%20for%20containers" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F25%2Fintroduction-to-containerjfr-jdk-flight-recorder-for-containers%2F&amp;#38;linkname=Introduction%20to%20ContainerJFR%3A%20JDK%20Flight%20Recorder%20for%20containers" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F25%2Fintroduction-to-containerjfr-jdk-flight-recorder-for-containers%2F&amp;#38;linkname=Introduction%20to%20ContainerJFR%3A%20JDK%20Flight%20Recorder%20for%20containers" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F25%2Fintroduction-to-containerjfr-jdk-flight-recorder-for-containers%2F&amp;#38;linkname=Introduction%20to%20ContainerJFR%3A%20JDK%20Flight%20Recorder%20for%20containers" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F25%2Fintroduction-to-containerjfr-jdk-flight-recorder-for-containers%2F&amp;#38;linkname=Introduction%20to%20ContainerJFR%3A%20JDK%20Flight%20Recorder%20for%20containers" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F25%2Fintroduction-to-containerjfr-jdk-flight-recorder-for-containers%2F&amp;#38;linkname=Introduction%20to%20ContainerJFR%3A%20JDK%20Flight%20Recorder%20for%20containers" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F25%2Fintroduction-to-containerjfr-jdk-flight-recorder-for-containers%2F&amp;#038;title=Introduction%20to%20ContainerJFR%3A%20JDK%20Flight%20Recorder%20for%20containers" data-a2a-url="https://developers.redhat.com/blog/2021/01/25/introduction-to-containerjfr-jdk-flight-recorder-for-containers/" data-a2a-title="Introduction to ContainerJFR: JDK Flight Recorder for containers"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/25/introduction-to-containerjfr-jdk-flight-recorder-for-containers/"&gt;Introduction to ContainerJFR: JDK Flight Recorder for containers&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/PPHmWvkzro8" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;OpenJDK has long been a top pick for real-world applications and workloads, chosen for its blend of performance, compatibility, reliability, and observability. For many years, JDK Flight Recorder (JFR) and JDK Mission Control (JMC) have contributed to OpenJDK&amp;#8217;s success. Until recently, both were commercial features, however, available only for certain users and workloads. In 2018, [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/25/introduction-to-containerjfr-jdk-flight-recorder-for-containers/"&gt;Introduction to ContainerJFR: JDK Flight Recorder for containers&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/01/25/introduction-to-containerjfr-jdk-flight-recorder-for-containers/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">798277</post-id><dc:creator>Andrew Azores</dc:creator><dc:date>2021-01-25T08:00:18Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/01/25/introduction-to-containerjfr-jdk-flight-recorder-for-containers/</feedburner:origLink></entry><entry><title type="html">Developping on OpenShift with WildFly bootable jar</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/TUnRnG-StuA/" /><author><name>Emmanuel Hugonnet</name></author><id>https://wildfly.org//news/2021/01/24/odo-bootable-jar/</id><updated>2021-01-24T00:00:00Z</updated><content type="html">With the bootable jar feature of WildFly it is now easier to build applications for the cloud. You can trim the server to reduce its footprint which makes this a perfect candidate to build microservices on the cloud. Let’s discover how to combine this feature to build and deploy applications on OpenShift. USING ODO is a fast, iterative, and straightforward CLI tool for developers who write, build, and deploy applications on Kubernetes and OpenShift. odo abstracts away complex Kubernetes and OpenShift concepts for the developer. INSTALLING ODO Download the binary from according to your target environment and follow the instructions from . Please note that you need at least the version 2.0.3 to use the devfile we will be using in the rest of this article. PREPARING OUR CLOUD ENVIRONEMENT During this article we will use the 'free' OpenShift that you can have with your account on website. Once you have your cloud environment we need to connect to it from odo. odo login https://api.sandbox.x8i5.p1.openshiftapps.com:6443 --token=sha256~################################# Connecting to the OpenShift cluster Logged into "https://api.sandbox.x8i5.p1.openshiftapps.com:6443" as "ehugonne1" using the token provided. You have access to the following projects and can switch between them with 'odo project set &lt;project-name&gt;': * ehugonne1-code ehugonne1-dev ehugonne1-stage Using project "ehugonne1-code". CREATING THE NEW PROJECT First we need to create a namespace in OpenShift: odo project create microprofile-config Now we can create our project using the microprofile-config quickstart sample project. mkdir odo-demo cd odo-demo odo create java-wildfly-bootable-jar --starter=microprofile-config Validation ✓ Checking devfile existence [19047ns] ✓ Creating a devfile component from registry: DefaultDevfileRegistry [31878ns] ✓ Validating devfile component [153099ns] Starter Project ✓ Downloading starter project microprofile-config from https://github.com/wildfly/quickstart.git [1m] Please use `odo push` command to create the component with source deployed This will create the microprofile-config quickstart Apache Maven project with a devfile.yaml that describe how the project will be built and run on OpenShift. This devfile is the entry point of our whole project, you may think of it as the pom.xml for the cloud. They are fully described on . Let’s take a quick look at the devfile and their main entry points. I’ll pass the starterProjects which are the quickstarts you can select when creating your initial project. First we can see that it defines two components: * a jaeger component that will provide an OpenTracing compatible server so that Eclipse MicroProfile OpenTracing applications can send traces to. * a wildfly component which is a simple Java image with Apache Maven where the application will be built and run. It exposes only the 8080 port for HTTP. * a m2-repository component which is a persistent volume that we will be using to avoid losing all the downloaded artefacts between each restart of the wildfly container. Then we have the list of commands available to build, debug and run our application: * build: this will compile and build a bootable jar from the sources. * run: this will start and run the bootable jar. * debug: this will start and run the bootable jar in debug mode. * dev-build: this will compile and build a bootable jar from the sources so that it can be used in developper mode which means the server won’t get rebuilt nor restarted when the application is modified. * dev-run: this will start and run the bootable jar in developper mode which means the server won’t get rebuilt nor restarted when the application is modified. * dev-debug: this will start and run the bootable jar in debug developper mode which means the server won’t get rebuilt nor restarted when the application is modified. * watch-build: this will do nothing except print a nice message. * watch-run: this will start the bootable jar in watch mode. * watch-debug: this will start the bootable jar in watch mode with debug on. BUILDING AND RUNNING THE APPLICATION So let’s just build and start our application odo push Validation ✓ Validating the devfile [290197ns] Creating Kubernetes resources for component java-wildfly-bootable-jar ✓ Waiting for component to start [29s] Applying URL changes ✓ URL tracing-ui: http://tracing-ui-java-wildfly-bootable-jar-ehugonne1-code.apps.sandbox.x8i5.p1.openshiftapps.com/ created ✓ URL http: http://http-java-wildfly-bootable-jar-ehugonne1-code.apps.sandbox.x8i5.p1.openshiftapps.com/ created Syncing to component java-wildfly-bootable-jar ✓ Checking files for pushing [1ms] ✓ Syncing files to the component [4s] Executing devfile commands for component java-wildfly-bootable-jar ✓ Executing watch-build command "echo 'It's watcher mode Baby !!!''" [2s] ✓ Executing watch-run command "mvn ${MVN_ARGS_APPEND} -Dwildfly.bootable.arguments=\"-b=0.0.0.0\" org.wildfly.plugins:wildfly-jar-maven-plugin:dev-watch -e -DskipTests", if not running [2s] Pushing devfile component java-wildfly-bootable-jar ✓ Changes successfully pushed to component You can get the url to access your application with oc get route java-wildfly-bootable-jar Now we can access the application on this URL. BUILDING AND DEBUGGING THE APPLICATION IN DEVELOPPER MODE To develop our application we provide a set of commands in to get feedbacks more quickly than with the default commands. Important The developper mode will only provision the server on the first build. That means that if you want to change the layers or the configuration of the server you will need to delete your application and push it again. So let’s start our server in developper mode with debug enabled. odo push --debug --build-command dev-build --debug-command dev-debug Validation ✓ Validating the devfile [165733ns] Creating Kubernetes resources for component java-jboss-eap-xp-bootable-jar ✓ Waiting for component to start [15s] Applying URL changes ✓ URL tracing-ui: http://tracing-ui-java-jboss-eap-xp-bootable-jar-microprofile-config.apps-crc.testing/ created ✓ URL http: http://http-java-jboss-eap-xp-bootable-jar-microprofile-config.apps-crc.testing/ created Syncing to component java-jboss-eap-xp-bootable-jar ✓ Checking files for pushing [2ms] ✓ Syncing files to the component [825ms] Executing devfile commands for component java-jboss-eap-xp-bootable-jar ✓ Executing dev-build command "mvn -Pbootable-jar -Dinsecure.repositories=WARN -Dmaven.repo.local=/home/jboss/.m2/repository -Dmaven.test.skip=true -Ddev package" [11m] ✓ Executing dev-debug command "mvn -Pbootable-jar -Dinsecure.repositories=WARN -Dwildfly.bootable.arguments=\"-b=0.0.0.0\" -Dwildfly.bootable.jvmArguments=\"-agentlib:jdwp=transport=dt_socket,address=0.0.0.0:${DEBUG_PORT},server=y,suspend=n\" -Dmaven.repo.local=/home/jboss/.m2/repository wildfly-jar:dev", if not running [1s] Pushing devfile component java-jboss-eap-xp-bootable-jar ✓ Changes successfully pushed to component If we edit the source code and push our changes you can see that the deployment is quicker. Now let’s try to debug our application. First we need to create a tunnel to access the listening debug port on our application, so in a new terminal we need to execute: odo debug port-forward -l 8787 Started port forwarding at ports - 8787:5858 Now we can connect to debug our application on port 8787 with our IDE and debug as usual. Quite simple is’nt it ? USING THE WATCH MODE Now that we managed to build, run and debug our application on OpenShift we still need to execute commands to push our changes to the cloud. It would be nice to just have things updated automatically. odo provides a nice watch command that will push changes to OpenShift. But the bootable maven plugin offers also a watch mode that will have it recompile the application and redeploy it automatically when the code change. So let’s take advantage of those two modes. First we need to start our application in debug and watch mode: odo push --debug --build-command watch-build --debug-command watch-debug Validation ✓ Validating the devfile [34305ns] Creating Kubernetes resources for component java-wildfly-bootable-jar ✓ Waiting for component to start [21s] Applying URL changes ✓ URLs are synced with the cluster, no changes are required. Syncing to component java-wildfly-bootable-jar ✓ Checking file changes for pushing [1ms] ✓ Syncing files to the component [4s] Executing devfile commands for component java-wildfly-bootable-jar ✓ Executing watch-build command "echo 'It's watcher mode Baby !!!''" [812ms] ✓ Executing watch-debug command "mvn ${MVN_ARGS_APPEND} -Dwildfly.bootable.arguments=\"-b=0.0.0.0\" -Dwildfly.bootable.jvmArguments=\"-agentlib:jdwp=transport=dt_socket,address=0.0.0.0:${DEBUG_PORT},server=y,suspend=n\" org.wildfly.plugins:wildfly-jar-maven-plugin:dev-watch -e", if not running [2s] Pushing devfile component java-wildfly-bootable-jar ✓ Changes successfully pushed to component Now we can set odo in watch mode too: odo watch Component is running in debug mode Please start port-forwarding in a different terminal Waiting for something to change in /home/ehsavoie/tmp/test When you edit a file like src/main/resources/META-INF/microprofile-config.properties, you can see the following on the console: File /home/ehsavoie/tmp/test/src/main/resources/META-INF/microprofile-config.properties changed Pushing files... Validation ✓ Validating the devfile [145787ns] Creating Kubernetes resources for component java-wildfly-bootable-jar ✓ Waiting for component to start [132ms] Applying URL changes ✓ URLs are synced with the cluster, no changes are required. Syncing to component java-wildfly-bootable-jar ✓ Checking file changes for pushing [1ms] ✓ Syncing files to the component [994ms] Executing devfile commands for component java-wildfly-bootable-jar ✓ Executing watch-build command "echo 'It's watcher mode Baby !!!''" [808ms] ✓ Executing watch-debug command "mvn ${MVN_ARGS_APPEND} -Dwildfly.bootable.arguments=\"-b=0.0.0.0\" -Dwildfly.bootable.jvmArguments=\"-agentlib:jdwp=transport=dt_socket,address=0.0.0.0:${DEBUG_PORT},server=y,suspend=n\" org.wildfly.plugins:wildfly-jar-maven-plugin:dev-watch -e", if not running [851ms] Component is running in debug mode Please start port-forwarding in a different terminal Waiting for something to change in /home/ehsavoie/tmp/test And of course since we used a debug command, you can connect your IDE on port 8787 and debug as usual. So as we have seen, developping on OpenShift is now very easy and simple and almost as slick as local development. All the more so as you can add several containers on your pod. In the sample devfile that is provided you have a Jaeger Server that is running. Connecting to its web interface (exposed throught a route too), you can see the traces produced by our application.&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/TUnRnG-StuA" height="1" width="1" alt=""/&gt;</content><dc:creator>Emmanuel Hugonnet</dc:creator><feedburner:origLink>https://wildfly.org//news/2021/01/24/odo-bootable-jar/</feedburner:origLink></entry><entry><title>Knowledge meets machine learning for smarter decisions, Part 2</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/PKjN8oeydLw/" /><category term="Big Data" /><category term="Java" /><category term="Machine Learning" /><category term="Python" /><category term="AI/ML" /><category term="DMN" /><category term="Drools" /><category term="JPMML" /><category term="machine learning model" /><author><name>Donato Marrazzo</name></author><id>https://developers.redhat.com/blog/?p=815677</id><updated>2021-01-22T08:00:34Z</updated><published>2021-01-22T08:00:34Z</published><content type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/products/red-hat-decision-manager/overview"&gt;Red Hat Decision Manager&lt;/a&gt; helps organizations introduce the benefits of &lt;a href="https://developers.redhat.com/topics/ai-ml"&gt;artificial intelligence&lt;/a&gt; to their daily operations. It is based on Drools, a popular open source project known for its powerful rules engine.&lt;/p&gt; &lt;p&gt;In &lt;a href="https://developers.redhat.com/blog/2021/01/14/knowledge-meets-machine-learning-for-smarter-decisions-part-1/"&gt;Part 1 of this article&lt;/a&gt;, we built a machine learning algorithm and stored it in a &lt;a target="_blank" rel="nofollow" href="http://dmg.org/pmml/v4-1/GeneralStructure.html"&gt;Predictive Model Markup Language&lt;/a&gt; (PMML) file. In Part 2, we&amp;#8217;ll combine the machine learning logic with deterministic knowledge defined using a &lt;a target="_blank" rel="nofollow" href="https://www.omg.org/dmn/"&gt;Decision Model and Notation (DMN) model&lt;/a&gt;. DMN is a recent standard introduced by the Object Management Group. It provides a common notation to capture an application&amp;#8217;s decision logic so that business users can understand it.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: Examples in this article build on the discussion in Part 1. If you have not already done so, please &lt;a href="https://developers.redhat.com/blog/2021/01/14/knowledge-meets-machine-learning-for-smarter-decisions-part-1/"&gt;read the first half of this article&lt;/a&gt; before continuing.&lt;/p&gt; &lt;h2&gt;The PMML advantage&lt;/h2&gt; &lt;p&gt;The end goal of a machine learning algorithm is to predict a value given a certain input. As I discussed in Part 1, there are many different machine learning algorithms, and each one has its own structure, training options, and logical execution. Most of the time, end users don&amp;#8217;t need to know &lt;i&gt;how&lt;/i&gt; an algorithm obtains its results; we only need to know that the results are accurate.&lt;/p&gt; &lt;p&gt;PMML hides the implementation details. It also gives us a common-language descriptor that we can use to combine predictive models created with different tools. The &lt;a target="_blank" rel="nofollow" href="https://pypi.org/project/sklearn-pmml-model/"&gt;sklearn-pmml-model&lt;/a&gt; project integrates PMML with &lt;code&gt;scikit-learn&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;PMML also separates the machine learning domain from the knowledge engineering domain. This separation makes it easier for specialists to manage each domain&amp;#8217;s details, then use the common-language descriptor to integrate them.&lt;/p&gt; &lt;h3&gt;JPMML&lt;/h3&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/jpmml/jpmml-transpiler"&gt;JPMML&lt;/a&gt; is a well established &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt; implementation of PMML provided by &lt;a target="_blank" rel="nofollow" href="https://openscoring.io/"&gt;Openscoring.io&lt;/a&gt;. Drools and Red Hat Decision Manager use JPMML for PMML execution inside the same process that executes the DMN logic, making the whole execution extremely efficient.&lt;/p&gt; &lt;p&gt;Drools and JPMML are released with different open source licenses, and JPMML is not packaged with the Drools binaries nor with Red Hat Decision Manager. As a user, you will need to download the JPMML libraries and place them in the &lt;code&gt;lib&lt;/code&gt; folder of the KIE Server and Business Central repository associated with your Red Hat Decision Manager instance.&lt;/p&gt; &lt;p&gt;Our &lt;a target="_blank" rel="nofollow" href="https://github.com/dmarrazzo/rhdm-dmn-pmml-order"&gt;example project&amp;#8217;s source code&lt;/a&gt; comes with a Maven configuration that copies all the project dependencies to the dependency folder. Here is the command to download the dependencies:&lt;/p&gt; &lt;pre&gt;mvn dependency:copy-dependencies &lt;/pre&gt; &lt;p&gt;You will need to copy the following libraries:&lt;/p&gt; &lt;pre&gt;pmml-evaluator-1.4.9.jar pmml-agent-1.4.11.jar pmml-model-1.4.11.jar pmml-evaluator-extension-1.4.9.jar kie-dmn-jpmml-7.33.0.Final-redhat-00003.jar &lt;/pre&gt; &lt;p&gt;The last entry is a Drools library that enables JPMML within the DMN runtime.&lt;/p&gt; &lt;h3&gt;Using PMML and DMN with machine learning&lt;/h3&gt; &lt;p&gt;The only drawback to using PMML is that it’s more focused on data science than machine learning. As a result, the specification doesn&amp;#8217;t include all of the available machine learning algorithms. You can still use DMN combined with machine learning, but it might be less comfortable in terms of user experience.&lt;/p&gt; &lt;p&gt;In fact, DMN can use externally-defined functions to execute Java code. This approach lets you leverage machine learning implementations that are not included with the specification, whether they are Java libraries or other technologies. It&amp;#8217;s even possible to call a remote evaluation that isolates the machine learning execution in a separate microservice.&lt;/p&gt; &lt;h2&gt;Knowledge engineering meets machine learning&lt;/h2&gt; &lt;p&gt;A machine learning algorithm delivers a prediction. How to handle the result is a &lt;i&gt;decision&lt;/i&gt;, which is based on the &lt;i&gt;knowledge context&lt;/i&gt;. The simple case study I introduced in Part 1 includes a reference price table for different product types. The table changes over time as prices are adjusted, and those changes influence the decision outcome.&lt;/p&gt; &lt;p&gt;Now, let&amp;#8217;s say that we want to introduce a business requirement that supply orders must be directed to a manager for any expense exceeding $1,500. The policy will let us know upfront what to do with larger expense requests, but how should we implement it?&lt;/p&gt; &lt;p&gt;We could train the algorithm to reject any order over $1,500, but that would be a bad choice. We shouldn&amp;#8217;t rely on a prediction when we have access to certainty. To say it differently, if you have a clear policy, use knowledge engineering, not machine learning.&lt;/p&gt; &lt;h2&gt;The example project&lt;/h2&gt; &lt;p&gt;To use PMML in a decision, we have to import it in Business Central (also known as Decision Central). The diagram in Figure 1 shows how the output from &lt;code&gt;scikit-learn&lt;/code&gt; feeds into Red Hat Decision Manager and Decision Central.&lt;/p&gt; &lt;div id="attachment_815687" style="width: 619px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa263e78039f.png"&gt;&lt;img aria-describedby="caption-attachment-815687" class="wp-image-815687 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa263e78039f.png" alt="A block diagram showing how output from Figure 1: Output from Scikit-learn feeds Red Hat Decision Manager. feeds the Decision Manager project" width="609" height="241" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa263e78039f.png 609w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa263e78039f-300x119.png 300w" sizes="(max-width: 609px) 100vw, 609px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-815687" class="wp-caption-text"&gt;Figure 1: Output from Scikit-learn feeds Red Hat Decision Manager.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;We can import the &lt;a target="_blank" rel="nofollow" href="https://github.com/dmarrazzo/rhdm-dmn-pmml-order"&gt;GitHub repository for this project&lt;/a&gt; directly into Decision Central: The PMML file is already imported, and the DMN file includes it by reference.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: If you need a quick introduction to DMN, see &lt;em&gt;&lt;a target="_blank" rel="nofollow" href="http://learn-dmn-in-15-minutes.com/"&gt;Learn DMN in 15 minutes&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt; &lt;h3&gt;The DMN logic&lt;/h3&gt; &lt;p&gt;For this example, we&amp;#8217;ve tried to keep the DMN logic minimal to focus on the PMML integration, but a few features are worth exploring. To start, consider the decision requirement diagram in Figure 2.&lt;/p&gt; &lt;div id="attachment_815697" style="width: 467px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2641fede87.png"&gt;&lt;img aria-describedby="caption-attachment-815697" class="wp-image-815697 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2641fede87.png" alt="A block diagram showing how an order moves from input to approval." width="457" height="478" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2641fede87.png 457w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2641fede87-287x300.png 287w" sizes="(max-width: 457px) 100vw, 457px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-815697" class="wp-caption-text"&gt;Figure 2: A decision requirement diagram for automatic approval.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Figure 3 is a closer look at the &lt;code&gt;OrderInfo&lt;/code&gt; datatype.&lt;/p&gt; &lt;div id="attachment_815707" style="width: 283px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa26429a6449.png"&gt;&lt;img aria-describedby="caption-attachment-815707" class="wp-image-815707 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa26429a6449.png" alt="The OrderInfo data type includes productType, price, category, and urgency." width="273" height="361" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa26429a6449.png 273w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa26429a6449-227x300.png 227w" sizes="(max-width: 273px) 100vw, 273px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-815707" class="wp-caption-text"&gt;Figure 3: The structure of the OrderInfo data type.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Notice the following:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The input data categories are product type, price, category, and urgency.&lt;/li&gt; &lt;li&gt;The Target Price is computed and used with the other data to get a Prediction.&lt;/li&gt; &lt;li&gt;A Prediction triggers a machine learning call (ML call). The box with the clipped corner is the business knowledge model and represents the machine learning algorithm&amp;#8217;s execution.&lt;/li&gt; &lt;li&gt;Finally, Auto Approve is based on the Prediction plus additional logic.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The Target Price decision shown in Figure 4 captures the company policy for asset reference prices with a simple decision table.&lt;/p&gt; &lt;div id="attachment_815727" style="width: 479px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2643375095.png"&gt;&lt;img aria-describedby="caption-attachment-815727" class="wp-image-815727 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2643375095.png" alt="The decision table captures the product type and target price for each request." width="469" height="348" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2643375095.png 469w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2643375095-300x223.png 300w" sizes="(max-width: 469px) 100vw, 469px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-815727" class="wp-caption-text"&gt;Figure 4: The decision table for Target Price.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The Prediction decision node, shown in Figure 5, calls the machine learning execution (ML call). This node might seem complex. Really, it translates the category and urgency of a decision to numbers. The machine learning algorithm returns a prediction of &lt;i&gt;true&lt;/i&gt; (&lt;code&gt;probability(true)&lt;/code&gt;) when the probability is over the threshold of 0.5.&lt;/p&gt; &lt;div id="attachment_815747" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa264471075d.png"&gt;&lt;img aria-describedby="caption-attachment-815747" class="wp-image-815747" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa264471075d.png" alt="The Prediction node translates the category and urgency of a decision to numbers." width="640" height="578" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa264471075d.png 894w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa264471075d-300x271.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa264471075d-768x694.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-815747" class="wp-caption-text"&gt;Figure 5: The implementation of the Prediction decision node.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;The business knowledge model&lt;/h3&gt; &lt;p&gt;The project&amp;#8217;s business knowledge model is straightforward, as shown in Figure 6.&lt;/p&gt; &lt;div id="attachment_815757" style="width: 463px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2645597879.png"&gt;&lt;img aria-describedby="caption-attachment-815757" class="wp-image-815757 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2645597879.png" alt="When a user chooses the PMML document and model from a drop-down list, PMML introspection automatically infers the input parameters." width="453" height="268" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2645597879.png 453w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2645597879-300x177.png 300w" sizes="(max-width: 453px) 100vw, 453px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-815757" class="wp-caption-text"&gt;Figure 6: The business knowledge model calls the machine learning model.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;A user chooses the PMML document and model from a drop-down list. The PMML introspection automatically infers the input parameters.&lt;/p&gt; &lt;h3&gt;Invoking the machine learning algorithm&lt;/h3&gt; &lt;p&gt;From a decision expert&amp;#8217;s perspective, invoking a machine learning algorithm is simple: The information contract is defined by the PMML file and automatically imported. If a decision expert needs to understand a rule&amp;#8217;s semantics (for example, that “low” urgency translates to 0), they can speak to the data scientists.&lt;/p&gt; &lt;p&gt;For a slightly less obvious rule, consider how the model result is mapped in DMN. We can find those lines in the PMML file:&lt;/p&gt; &lt;pre&gt;       &amp;#60;Output&amp;#62;            &amp;#60;OutputField name="probability(false)" optype="continuous" dataType="double" feature="probability" value="false"/&amp;#62;            &amp;#60;OutputField name="probability(true)" optype="continuous" dataType="double" feature="probability" value="true"/&amp;#62;        &amp;#60;/Output&amp;#62; &lt;/pre&gt; &lt;p&gt;They are translated in the following &lt;a target="_blank" rel="nofollow" href="https://docs.camunda.org/manual/7.14/reference/dmn/feel/"&gt;Friendly Enough Expression Language&lt;/a&gt; (FEEL) context:&lt;/p&gt; &lt;pre&gt;{    “probability(true)” : &lt;i&gt;number&lt;/i&gt;,   “probability(false)”: &lt;i&gt;number&lt;/i&gt; } &lt;/pre&gt; &lt;p&gt;The top node is used to make the final decision of whether or not to auto-approve an order. Remember from Part 1 that this decision includes a simple company policy: &lt;i&gt;Automatic approval can happen when the expense is less than $1,500&lt;/i&gt;. Here is how to implement that policy with a FEEL expression:&lt;/p&gt; &lt;pre&gt;&lt;b&gt;if&lt;/b&gt; order info.price &amp;#60; 1500 &lt;b&gt;then&lt;/b&gt;    Prediction &lt;b&gt;else&lt;/b&gt;   &lt;b&gt;false&lt;/b&gt; &lt;/pre&gt; &lt;p&gt;Figure 7 shows the decision lifecycle at a high level. Note that the design phase is split between Python and Decision Central. The runtime is the KIE Server (also known as Decision Central).&lt;/p&gt; &lt;div id="attachment_815767" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2647888bf2.png"&gt;&lt;img aria-describedby="caption-attachment-815767" class="wp-image-815767 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2647888bf2-1024x213.png" alt="A block diagram showing the toolchain progression from Scikit-learn to Decision Central, to Kie Server." width="640" height="133" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2647888bf2-1024x213.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2647888bf2-300x62.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2647888bf2-768x160.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa2647888bf2.png 1159w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-815767" class="wp-caption-text"&gt;Figure 7: The toolchain progresses from Scikit-learn to Decision Central, to Kie Server.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Trust automatic decisions&lt;/h2&gt; &lt;p&gt;The more critical a decision is, the more you need to trust the system that determines its outcome. A suboptimal product suggestion might be acceptable, but what about a decision to reject a loan or decisions concerning medical findings? Additionally, ethics and legislation expect accountability in we use personal data is used to make decisions. (As an example, see the European Union&amp;#8217;s &lt;a target="_blank" rel="nofollow" href="https://gdpr-info.eu/"&gt;General Data Protection Regulation&lt;/a&gt;.)&lt;/p&gt; &lt;h3&gt;Inspection&lt;/h3&gt; &lt;p&gt;When an automatic decision-making system is introduced in an enterprise context, it is crucial to keep it under control by monitoring the decisions made over time. You should be able to use tools in your decision-management technology to investigate specific cases and highlight the features that influenced any given decision.&lt;/p&gt; &lt;p&gt;With Red Hat Decision Manager, users can use the common monitoring stack from Prometheus and Grafana to track decisions. By analyzing DMN execution results, you can inspect your intermediate outcomes and correlate them with the enterprise policy captured in a specific decision node.&lt;/p&gt; &lt;p&gt;Machine learning algorithms are more opaque: You get the input data and the output. In this sense, a machine learning model is a black box, providing no clues about how it works. An expert will understand from the algorithm parameters how it behaves, but most business users don&amp;#8217;t have access to that information.&lt;/p&gt; &lt;h3&gt;Using the knowledge context&lt;/h3&gt; &lt;p&gt;In our order approval example, the knowledge-based elements are key to understanding the final decision. If you can see that the price of a phone is far from the reference price in the model, you can use that information to interpret the decision outcome for your request. Our model is simple, so the conclusion is obvious. Surrounding a machine learning algorithm with a knowledge context is even more valuable for complex models. Having the context helps end users better understand decision outcomes.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: In the future, Red Hat Decision Manager&amp;#8217;s development team will extend its inspection features to better cope with the &lt;a target="_blank" rel="nofollow" href="https://blog.kie.org/2020/06/trusty-ai-introduction.html"&gt;TrustyAI&lt;/a&gt; challenge.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;In this two-part article, we have seen that artificial intelligence is more than just machine learning. By combining multiple techniques, we can increase the intelligence of a machine learning model. Moreover, this approach could increase an organization&amp;#8217;s overall confidence in machine learning outcomes. Business users and end users benefit from the transparency provided by a knowledge context.&lt;/p&gt; &lt;p&gt;We crafted a machine learning model for our example project, which we then consumed from a DMN model. The result was an &amp;#8220;AI-augmented&amp;#8221; decision. However, we only scratched the surface of what is possible with artificial intelligence. If you want to go further, I suggest this free course from Harvard University: &lt;a target="_blank" rel="nofollow" href="https://cs50.harvard.edu/ai/2020/"&gt;CS50&amp;#8217;s Introduction to Artificial Intelligence with Python&lt;/a&gt;. The Python example we used in this article is based on a similar example from the course.&lt;/p&gt; &lt;p&gt;I also found the &lt;a target="_blank" rel="nofollow" href="https://www.linkedin.com/learning/learning-xai-explainable-artificial-intelligence"&gt;explainable AI (XAI) course&lt;/a&gt; on LinkedIn Learning (formerly Lynda) very useful.&lt;/p&gt; &lt;h2&gt;Acknowledgments&lt;/h2&gt; &lt;p&gt;A special thanks to my colleagues in the engineering team: Edson Tirelli, Matteo Mortari, and Gabriele Cardosi, for their suggestions and ideas to improve this article. Gabriele also wrote the &amp;#8220;PMML advantage&amp;#8221; section for this article.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F22%2Fknowledge-meets-machine-learning-for-smarter-decisions-part-2%2F&amp;#38;linkname=Knowledge%20meets%20machine%20learning%20for%20smarter%20decisions%2C%20Part%202" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F22%2Fknowledge-meets-machine-learning-for-smarter-decisions-part-2%2F&amp;#38;linkname=Knowledge%20meets%20machine%20learning%20for%20smarter%20decisions%2C%20Part%202" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F22%2Fknowledge-meets-machine-learning-for-smarter-decisions-part-2%2F&amp;#38;linkname=Knowledge%20meets%20machine%20learning%20for%20smarter%20decisions%2C%20Part%202" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F22%2Fknowledge-meets-machine-learning-for-smarter-decisions-part-2%2F&amp;#38;linkname=Knowledge%20meets%20machine%20learning%20for%20smarter%20decisions%2C%20Part%202" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F22%2Fknowledge-meets-machine-learning-for-smarter-decisions-part-2%2F&amp;#38;linkname=Knowledge%20meets%20machine%20learning%20for%20smarter%20decisions%2C%20Part%202" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F22%2Fknowledge-meets-machine-learning-for-smarter-decisions-part-2%2F&amp;#38;linkname=Knowledge%20meets%20machine%20learning%20for%20smarter%20decisions%2C%20Part%202" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F22%2Fknowledge-meets-machine-learning-for-smarter-decisions-part-2%2F&amp;#38;linkname=Knowledge%20meets%20machine%20learning%20for%20smarter%20decisions%2C%20Part%202" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F22%2Fknowledge-meets-machine-learning-for-smarter-decisions-part-2%2F&amp;#038;title=Knowledge%20meets%20machine%20learning%20for%20smarter%20decisions%2C%20Part%202" data-a2a-url="https://developers.redhat.com/blog/2021/01/22/knowledge-meets-machine-learning-for-smarter-decisions-part-2/" data-a2a-title="Knowledge meets machine learning for smarter decisions, Part 2"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/22/knowledge-meets-machine-learning-for-smarter-decisions-part-2/"&gt;Knowledge meets machine learning for smarter decisions, Part 2&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/PKjN8oeydLw" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Red Hat Decision Manager helps organizations introduce the benefits of artificial intelligence to their daily operations. It is based on Drools, a popular open source project known for its powerful rules engine. In Part 1 of this article, we built a machine learning algorithm and stored it in a Predictive Model Markup Language (PMML) file. [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/22/knowledge-meets-machine-learning-for-smarter-decisions-part-2/"&gt;Knowledge meets machine learning for smarter decisions, Part 2&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/01/22/knowledge-meets-machine-learning-for-smarter-decisions-part-2/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">815677</post-id><dc:creator>Donato Marrazzo</dc:creator><dc:date>2021-01-22T08:00:34Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/01/22/knowledge-meets-machine-learning-for-smarter-decisions-part-2/</feedburner:origLink></entry><entry><title type="html">Planned Security Features for WildFly</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/lJ8A0O9RaCc/" /><author><name>Farah Juma</name></author><id>https://wildfly-security.github.io/wildfly-elytron/blog/planned-security-features-for-wildfly-23/</id><updated>2021-01-22T00:00:00Z</updated><dc:creator>Farah Juma</dc:creator><summary type="html">&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/lJ8A0O9RaCc" height="1" width="1" alt=""/&gt;</summary><feedburner:origLink>https://wildfly-security.github.io/wildfly-elytron/blog/planned-security-features-for-wildfly-23/</feedburner:origLink></entry><entry><title>Introducing the Red Hat build of Eclipse Vert.x 4.0</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/PcEgqD9cg-M/" /><category term="Containers" /><category term="Java" /><category term="Kubernetes" /><category term="Modern App Dev" /><category term="distributed tracing" /><category term="Jkube" /><category term="openshift" /><category term="reactive programming" /><category term="vert.x" /><author><name>Syed M Shaaf</name></author><id>https://developers.redhat.com/blog/?p=855807</id><updated>2021-01-21T08:00:28Z</updated><published>2021-01-21T08:00:28Z</published><content type="html">&lt;p&gt;If you are interested in reactive, non-blocking, and asynchronous Java development, you are likely familiar with &lt;a target="_blank" rel="nofollow" href="https://vertx.io/"&gt;Eclipse Vert.x&lt;/a&gt;. The project started in 2011 and successfully moved to the Eclipse Foundation in 2013. Since then, Vert.x has undergone nine years of rigorous development and grown into a thriving community. It is one of the most widely used reactive frameworks, with support for multiple extensions, including extensions for messaging or streaming with &lt;a href="https://developers.redhat.com/topics/kafka-kubernetes"&gt;Kafka&lt;/a&gt; or Artemis, developing applications with gRPC and GraphQL, and &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/articles/3348731"&gt;so much more&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_build_of_eclipse_vert.x/4.0/html/release_notes_for_eclipse_vert.x_4.0/index"&gt;Red Hat build of Eclipse Vert.x 4.0&lt;/a&gt; is now generally available. This release improves Vert.x&amp;#8217;s core APIs and handling. Developers who migrate can expect enhancements to futures and promises, distributed tracing, and deployment on &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt;. In this article, I introduce these updates and offer tips for migrating and deploying your Eclipse Vert.x 4.0 applications on OpenShift.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: Please see the &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_build_of_eclipse_vert.x/4.0/html/eclipse_vert.x_4.0_migration_guide/"&gt;Red Hat build of Eclipse Vert.x 4.0 migration guide&lt;/a&gt; for a detailed introduction to migrating from Vert.x 3.x to Vert.x 4.0.&lt;/p&gt; &lt;h2&gt;The &amp;#60;Future&amp;#62; is here!&lt;/h2&gt; &lt;p&gt;&lt;code&gt;Future&lt;/code&gt; is an &lt;code&gt;AsyncResult&amp;#60;T&amp;#62;&lt;/code&gt; that you can use to create asynchronous operations in Vert.x 4.0. Every asynchronous method returns a &lt;code&gt;Future&lt;/code&gt; object, &lt;code&gt;success&lt;/code&gt; or &lt;code&gt;failure&lt;/code&gt;, as the result of a call:&lt;/p&gt; &lt;pre&gt;FileSystem fs = vertx.fileSystem(); Future&amp;#60;FileProps&amp;#62; future = fs.props("/my_file.txt"); future.onComplete((AsyncResult&amp;#60;FileProps&amp;#62; ar) -&amp;#62; { if (ar.succeeded()) { FileProps props = ar.result(); System.out.println("File size = " + props.size()); } else { System.out.println("Failure: " + ar.cause().getMessage()); } }); &lt;/pre&gt; &lt;p&gt;If you prefer to use callbacks and get a &lt;code&gt;Handler&lt;/code&gt; back, Vert.x 4.0 still implements &lt;code&gt;props&lt;/code&gt;, as shown here:&lt;/p&gt; &lt;pre&gt;&lt;a target="_blank" rel="nofollow" href="https://vertx.io/docs/apidocs/io/vertx/core/file/FileSystem.html"&gt;FileSystem&lt;/a&gt; props(&lt;a target="_blank" rel="nofollow" href="https://docs.oracle.com/javase/7/docs/api/java/lang/String.html?is-external=true"&gt;String&lt;/a&gt; path,&lt;a target="_blank" rel="nofollow" href="https://vertx.io/docs/apidocs/io/vertx/core/Handler.html"&gt;Handler&lt;/a&gt;&amp;#60;&lt;a target="_blank" rel="nofollow" href="https://vertx.io/docs/apidocs/io/vertx/core/AsyncResult.html"&gt;AsyncResult&lt;/a&gt;&amp;#60;&lt;a target="_blank" rel="nofollow" href="https://vertx.io/docs/apidocs/io/vertx/core/file/FileProps.html"&gt;FileProps&lt;/a&gt;&amp;#62;&amp;#62; handler) &lt;/pre&gt; &lt;p&gt;Developers migrating from Vert.x 3.x to Vert.x 4.0 can also use &lt;code&gt;Future&lt;/code&gt; with callbacks:&lt;/p&gt; &lt;pre&gt;WebClient client = WebClient.create(vertx); HttpRequest request = client.get("/resource"); Future&amp;#60;HttpResponse&amp;#62; response = request.send(); response.onComplete(ar -&amp;#62; { if (ar.succeeded()) { HttpResponse response = ar.result(); } else { Throwable failure = ar.cause(); } }); &lt;/pre&gt; &lt;p&gt;Error handling is more straightforward with futures than with callbacks. You don&amp;#8217;t need to track yourself back into each callback, and you can handle a failure just once, at the end of a composition. Futures also let you compose asynchronous events in parallel or sequentially. All in all, this feature greatly simplifies application programming with Vert.x.&lt;/p&gt; &lt;h2&gt;Promises&lt;/h2&gt; &lt;p&gt;A &lt;i&gt;promise&lt;/i&gt; represents the writable side of an action that may or may not have yet occurred. Each promise has a &lt;a target="_blank" rel="nofollow" href="https://vertx.io/docs/apidocs/io/vertx/core/Promise.html#future--"&gt;future()&lt;/a&gt; method, which returns a &lt;code&gt;Future&lt;/code&gt; for the given promise. You can use promises and futures together to get a notification of completion. The following example shows &lt;code&gt;HttpServerVerticle&lt;/code&gt; using a promise.&lt;/p&gt; &lt;pre&gt;package com.example.starter; import io.vertx.core.AbstractVerticle; import io.vertx.core.Promise; public class MainVerticle extends AbstractVerticle { @Override public void start(Promise&amp;#60;Void&amp;#62; startPromise) throws Exception { vertx.createHttpServer().requestHandler(req -&amp;#62; { req.response() .putHeader("content-type", "text/plain") .end("Hello from Vert.x!"); }).listen(8888, http -&amp;#62; { if (http.succeeded()) { startPromise.complete(); System.out.println("HTTP server started on port 8888"); } else { startPromise.fail(http.cause()); } }); } } &lt;/pre&gt; &lt;p&gt;In this case, the method returns the &lt;a target="_blank" rel="nofollow" href="https://vertx.io/docs/apidocs/io/vertx/core/Future.html"&gt;Future&lt;/a&gt; associated with a promise. We use the &lt;code&gt;Future&lt;/code&gt; to send a notification when the promise has been completed and retrieve its value. Furthermore, a promise extends &lt;code&gt;Handler&amp;#60;AsyncResult&amp;#60;T&amp;#62;&amp;#62; &lt;/code&gt;so that we can use it as a callback.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: Before migrating your applications to Eclipse Vert.x 4.0, check for deprecations and removals. The compiler will generate a warning when you use a deprecated API.&lt;/p&gt; &lt;h2&gt;Distributed tracing&lt;/h2&gt; &lt;p&gt;Many components in a modern, distributed software application have their own operations lifecycle. The challenge is to trace various events and correlate that information across components. Tracing lets us understand the state of the system and how well the system adheres to key performance indicator metrics (KPIs). To find out how many people are getting help in a disaster-rescue effort, for example, we must correlate and trace data in a distributed software system. We can use that information to evaluate whether the software is meeting our business requirements.&lt;/p&gt; &lt;p&gt;Distributed tracing lets us visualize and understand the chain of events and flows in an interaction between software applications. For distributed tracing in microservices environments, we can use Vert.x 4.0 with &lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/en/topics/microservices/what-is-jaeger"&gt;Jaeger&lt;/a&gt;, an &lt;a target="_blank" rel="nofollow" href="https://opentracing.io"&gt;OpenTracing&lt;/a&gt; client that is part of the Cloud Native Computing Foundation.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: See the Red Hat OpenShift &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.6/jaeger/jaeger_install/rhbjaeger-deploying.html"&gt;guide to configuring and deploying Jaeger&lt;/a&gt; for instructions to install Jaeger.&lt;/p&gt; &lt;p&gt;Once we have Jaeger installed, we can use the following Vert.x components to log traces:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;HTTP server and HTTP client&lt;/li&gt; &lt;li&gt;Eclipse Vert.x SQL client&lt;/li&gt; &lt;li&gt;Eclipse Vert.x Kafka client&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Each of these components implements the following &lt;code&gt;TracingPolicy&lt;/code&gt;:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://vertx.io/docs/apidocs/io/vertx/core/tracing/TracingPolicy.html#PROPAGATE"&gt;PROPAGATE&lt;/a&gt;: The component reports a span in the active trace.&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://vertx.io/docs/apidocs/io/vertx/core/tracing/TracingPolicy.html#ALWAYS"&gt;ALWAYS&lt;/a&gt;: The component reports a span in the active trace or creates a new active trace.&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://vertx.io/docs/apidocs/io/vertx/core/tracing/TracingPolicy.html#IGNORE"&gt;IGNORE&lt;/a&gt;: Ignores tracing for the component in question.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Here&amp;#8217;s an example of a simple tracing policy implementation:&lt;/p&gt; &lt;pre&gt;HttpServer server = vertx.createHttpServer(new HttpServerOptions() .setTracingPolicy(TracingPolicy.IGNORE) ); &lt;/pre&gt; &lt;p&gt;See the &lt;a target="_blank" rel="nofollow" href="https://github.com/vert-x3/vertx-examples/tree/4.x/opentracing-examples"&gt;Vert.x Opentracing examples&lt;/a&gt; repository for a more detailed tracing example with Vert.x and Jaeger.&lt;/p&gt; &lt;h2&gt;Metering labels for OpenShift&lt;/h2&gt; &lt;p&gt;You can now add metering labels to your Eclipse Vert.x applications running on OpenShift. Customers use the labels to track deployments they have subscribed to follow. Eclipse Vert.x uses the following metering labels:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;com.redhat.component-name: Vert.x&lt;/li&gt; &lt;li&gt;com.redhat.component-type: application&lt;/li&gt; &lt;li&gt;com.redhat.component-version: 4.0.0&lt;/li&gt; &lt;li&gt;com.redhat.product-name: &amp;#8220;Red_Hat_Runtimes&amp;#8221;&lt;/li&gt; &lt;li&gt;com.redhat.product-version: 2021/Q1&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;See the OpenShift 4.6 documentation for &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.6/html/metering/index"&gt;more about metering labels&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Deploying Eclipse Vert.x applications to OpenShift&lt;/h2&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/eclipse/jkube"&gt;Eclipse JKube&lt;/a&gt; is a collection of plug-ins and libraries for building container images using Docker, Jib, or source-to-image (S2I) build strategies. Unlike its predecessor, Fabric8, Eclipse JKube eases Java development on &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; and OpenShift. Developers can focus on creating applications without getting into details, such as creating manifests.&lt;/p&gt; &lt;p&gt;Eclipse JKube includes manifests as part of the Maven build, then generates and deploys them at compile time. The JKube plug-in generates resource manifests for you automatically, which you can apply afterward. Here&amp;#8217;s an example of how to run an application on OpenShift with Eclipse JKube:&lt;/p&gt; &lt;pre&gt;# The following commmands will create your OpenShift resource descriptors. mvn clean oc:resource -Popenshift # Starting the S2I build mvn package oc:build -Popenshift   # Deploying to OpenShift mvn oc:deploy -Popenshift &lt;/pre&gt; &lt;p&gt;See this &lt;a target="_blank" rel="nofollow" href="https://github.com/eclipse/jkube/tree/master/quickstarts/maven/vertx/"&gt;sample project using Eclipse JKube plug-ins&lt;/a&gt; for more details.&lt;/p&gt; &lt;h2&gt;Packaging and deployment&lt;/h2&gt; &lt;p&gt;You can now package and deploy your applications to OpenShift with Open Container Initiative (OCI)-compliant &lt;a href="https://developers.redhat.com/articles/ubi-faq"&gt;Universal Base Images&lt;/a&gt; for &lt;a href="https://developers.redhat.com/products/openjdk/overview"&gt;Red Hat OpenJDK 8 and 11&lt;/a&gt; on &lt;a href="https://developers.redhat.com/topics/linux"&gt;Red Hat Enterprise Linux 8&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Additionally, the Vert.x &lt;code&gt;vertx-web-client.js&lt;/code&gt; is now published in the NPM repository and no longer available as a Maven artifact. You can access the client from &lt;a target="_blank" rel="nofollow" href="https://www.npmjs.com/package/@vertx/eventbus-bridge-client.js"&gt;@vertx/eventbus-bridge-client.js&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;New to reactive programming?&lt;/h2&gt; &lt;p&gt;If you are new to reactive programming, you can use &lt;a target="_blank" rel="nofollow" href="https://learn.openshift.com/middleware/courses/middleware-vertx/"&gt;self-paced scenarios&lt;/a&gt; to learn and experiment with Vert.x or learn about other technologies within Red Hat Runtimes. Each scenario provides a preconfigured Red Hat OpenShift instance that is accessible from your browser without any downloads or configuration.&lt;/p&gt; &lt;p&gt;For developers who prefer to dive deep, I recommend reading &lt;a target="_blank" rel="nofollow" href="https://www.manning.com/books/vertx-in-action"&gt;&lt;em&gt;Vert.x in Action&lt;/em&gt;&lt;/a&gt; by &lt;a href="https://developers.redhat.com/blog/author/jponge/"&gt;Julien Ponge&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Get the Red Hat build of Vert.x 4.0&lt;/h2&gt; &lt;p&gt;Support for Eclipse Vert.x is available to Red Hat customers through a &lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/en/products/runtimes"&gt;Red Hat Runtimes&lt;/a&gt; subscription. Red Hat&amp;#8217;s runtime support is scheduling according to the &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/support/policy/updates/jboss_notes/"&gt;Red Hat product update and support lifecycle&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;If you are new to Eclipse Vert.x and would like to learn more, go to our live learning portal for a guided &lt;a target="_blank" rel="nofollow" href="https://learn.openshift.com/middleware/courses/middleware-vertx/"&gt;tutorial&lt;/a&gt;, or see the &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_build_of_eclipse_vert.x/4.0/"&gt;product documentation&lt;/a&gt; for technical details. You can also check the &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/articles/3985941"&gt;supported configurations&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/articles/3348731"&gt;component details&lt;/a&gt; for Eclipse Vert.x on Red Hat Runtimes, and see the &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_build_of_eclipse_vert.x/4.0/html/eclipse_vert.x_4.0_migration_guide/"&gt;migration guide&lt;/a&gt; for a detailed introduction to migrating from Eclipse Vert.x 3.x to Vert.x 4.0.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F21%2Fintroducing-the-red-hat-build-of-eclipse-vert-x-4-0%2F&amp;#38;linkname=Introducing%20the%20Red%20Hat%20build%20of%20Eclipse%20Vert.x%204.0" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F21%2Fintroducing-the-red-hat-build-of-eclipse-vert-x-4-0%2F&amp;#38;linkname=Introducing%20the%20Red%20Hat%20build%20of%20Eclipse%20Vert.x%204.0" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F21%2Fintroducing-the-red-hat-build-of-eclipse-vert-x-4-0%2F&amp;#38;linkname=Introducing%20the%20Red%20Hat%20build%20of%20Eclipse%20Vert.x%204.0" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F21%2Fintroducing-the-red-hat-build-of-eclipse-vert-x-4-0%2F&amp;#38;linkname=Introducing%20the%20Red%20Hat%20build%20of%20Eclipse%20Vert.x%204.0" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F21%2Fintroducing-the-red-hat-build-of-eclipse-vert-x-4-0%2F&amp;#38;linkname=Introducing%20the%20Red%20Hat%20build%20of%20Eclipse%20Vert.x%204.0" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F21%2Fintroducing-the-red-hat-build-of-eclipse-vert-x-4-0%2F&amp;#38;linkname=Introducing%20the%20Red%20Hat%20build%20of%20Eclipse%20Vert.x%204.0" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F21%2Fintroducing-the-red-hat-build-of-eclipse-vert-x-4-0%2F&amp;#38;linkname=Introducing%20the%20Red%20Hat%20build%20of%20Eclipse%20Vert.x%204.0" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F21%2Fintroducing-the-red-hat-build-of-eclipse-vert-x-4-0%2F&amp;#038;title=Introducing%20the%20Red%20Hat%20build%20of%20Eclipse%20Vert.x%204.0" data-a2a-url="https://developers.redhat.com/blog/2021/01/21/introducing-the-red-hat-build-of-eclipse-vert-x-4-0/" data-a2a-title="Introducing the Red Hat build of Eclipse Vert.x 4.0"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/21/introducing-the-red-hat-build-of-eclipse-vert-x-4-0/"&gt;Introducing the Red Hat build of Eclipse Vert.x 4.0&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/PcEgqD9cg-M" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;If you are interested in reactive, non-blocking, and asynchronous Java development, you are likely familiar with Eclipse Vert.x. The project started in 2011 and successfully moved to the Eclipse Foundation in 2013. Since then, Vert.x has undergone nine years of rigorous development and grown into a thriving community. It is one of the most widely [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/21/introducing-the-red-hat-build-of-eclipse-vert-x-4-0/"&gt;Introducing the Red Hat build of Eclipse Vert.x 4.0&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/01/21/introducing-the-red-hat-build-of-eclipse-vert-x-4-0/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">855807</post-id><dc:creator>Syed M Shaaf</dc:creator><dc:date>2021-01-21T08:00:28Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/01/21/introducing-the-red-hat-build-of-eclipse-vert-x-4-0/</feedburner:origLink></entry><entry><title type="html">Apache Camel 3.8 and Java Flight Recorder</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/gS5qIFb9BGc/apache-camel-38-and-java-flight-recorder.html" /><author><name>Claus Ibsen</name></author><id>http://feedproxy.google.com/~r/ApacheCamel/~3/MAojxhqbNc0/apache-camel-38-and-java-flight-recorder.html</id><updated>2021-01-20T11:35:00Z</updated><content type="html">In the upcoming 3.8 release we have a new Camel component to integrate with Java Flight Recorder. Camel is now capable of capturing "work steps" during startup that can be recorded with Java Flight Recorder. This can be used to better diagnose and find where your Camel applications may be slow to startup, for example due to a misbehaving component or custom user code. The screenshot below shows a recording that has captured a Camel application that takes about 3 seconds to startup. Its a very tiny application so we expected it to be faster.  If we sort the events by duration in the JDK mission control, we can see that there are 4 events that take over 2 seconds. The sequence is a sequence of the following step (sub step): Initializing context -&gt; Initializing routes -&gt; Creating route (route2) -&gt; Creating Bean processor (bean1) What we can see is that the step with the highest depth is "Creating Bean processor" which takes about 2 seconds. This is the culprit of the bottleneck. If we check the Camel route for where bean1 is in use, its in route2 at:         from("direct:slow")             .to("log:slow?level=OFF")             .bean(MyBean.class, "hello"); Here we can see the bean is using MyBean class, which we can then look at next:     public MyBean() {         // force slow startup         try {             LOG.warn("Forcing 2 sec delay to have slow startup");             Thread.sleep(2000);         } catch (Exception e) {             // ignore         }     } Ah okay here is the problem. The bean is sleeping for 2 seconds. Yes of course this is a made up example, but it does affect the recording and allow us to find it via the JDK mission control tool. We also offer a logging recorder where you can "see" some of the same information as in JDK mission control. However when using JDK mission control, you have the entire JFR recording that also captures alot of JVM information about CPU and memory use and whatnot. To use Java Flight Recorder with Camel, all you have to do is to add camel-jfr on the classpath. Then Camel will auto-detect this and enable it. You can configure the recorder with various options which will be documented as part of the . But for quickly finding startup bottlenecks for Camel applications then the logging recorder is a good start. The screenshot below shows the logging output, and as you can see from the red square we have identified where the "2 second" problem is. The logging recorder comes out of the box in camel-core, and you can just use it by configuring: camel.main.startup-recorder = logging If you are using Camel Main, Camel Quarkus etc. And for Spring Boot, you can enable it with camel.springboot.startup-recorder = logging You can also set a custom recorder, or one of the out of the box implementation via Java code: camelContext.adapt(ExtendedCamelContext.class)   .setStartupStepRecorder(...); You can try this example () from the Camel Examples git repository. From command line you can run  mvn camel:run And Camel will automatic capture a JFR recording and save to disk. The output of the file is shown in the log, which you can then open from JDK mission control.  &lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/gS5qIFb9BGc" height="1" width="1" alt=""/&gt;</content><dc:creator>Claus Ibsen</dc:creator><feedburner:origLink>http://feedproxy.google.com/~r/ApacheCamel/~3/MAojxhqbNc0/apache-camel-38-and-java-flight-recorder.html</feedburner:origLink></entry><entry><title type="html">Quarkus 1.11 released - RESTEasy Reactive, Dev UI, and more!</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Cd7IOlusvD8/" /><author><name /></author><id>https://quarkus.io/blog/quarkus-1-11-0-final-released/</id><updated>2021-01-20T00:00:00Z</updated><content type="html">For each Quarkus release, it’s the same story: it comes with a ton of exciting new features and enhancements… But believe it or not, it’s true. 1.11 is an important milestone as it marks the beginning of two amazing new features: RESTEasy Reactive, Our Dev UI. But it also comes...&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Cd7IOlusvD8" height="1" width="1" alt=""/&gt;</content><dc:creator /><feedburner:origLink>https://quarkus.io/blog/quarkus-1-11-0-final-released/</feedburner:origLink></entry></feed>
